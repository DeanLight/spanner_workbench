{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Passes\n",
    "> passes over the AST of a statement to do semantic checks and register state in the session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp micro_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import pytest\n",
    "\n",
    "# from lark import Transformer, Token\n",
    "# from lark import Tree as LarkNode\n",
    "# from lark.visitors import Interpreter, Visitor_Recursive, Visitor\n",
    "from pathlib import Path\n",
    "from typing import no_type_check, Set, Sequence, Any,Optional,List,Callable,Dict,Union\n",
    "from pydantic import BaseModel\n",
    "import networkx as nx\n",
    "\n",
    "# from spannerlib.ast_node_types import (Assignment, ReadAssignment, AddFact, RemoveFact, Query, Rule, IERelation, RelationDeclaration, Relation)\n",
    "from spannerlib.primitive_types import Span, DataTypes, DataTypeMapping\n",
    "# from spannerlib.engine import RESERVED_RELATION_PREFIX\n",
    "# # from spannerlib.graphs import NetxStateGraph\n",
    "# from spannerlib.symbol_table import SymbolTableBase\n",
    "# from spannerlib.general_utils import (get_free_var_names, get_output_free_var_names, get_input_free_var_names, fixed_point, check_properly_typed_relation, type_check_rule_free_vars)\n",
    "# from spannerlib.passes_utils import assert_expected_node_structure, unravel_lark_node,ParseNodeType\n",
    "\n",
    "from graph_rewrite import draw, draw_match, rewrite, rewrite_iter\n",
    "\n",
    "from spannerlib.grammar import parse_spannerlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_tree(g):\n",
    "    root = next(nx.topological_sort(g))\n",
    "    return nx.tree_data(g,root) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummySession():\n",
    "    def __init__(self,passes=None):\n",
    "        if passes is None:\n",
    "            passes = []\n",
    "        self.passes = passes\n",
    "        # self.term_graph = nx.DiGraph()\n",
    "        # self.symbol_table = dict() # {var_name:(type,value)}\n",
    "        # self.ie_functions = dict() # {ie_func_name: {\n",
    "        #                             #     'in_schema': ...,\n",
    "        #                             #     'out_schema': ...,\n",
    "        #                             #     'func': function,\n",
    "        #                             #     'func_type': ... # per row, bulk, aggregation in the future etc\n",
    "        #                             #     }\n",
    "        #                             # }\n",
    "        # #self.db # db entry points # TODO maybe this shouldnt belong here\n",
    "\n",
    "    def run_query(self, query):\n",
    "        statements = parse_spannerlog(query,split_statements=True)\n",
    "        clean_asts = []\n",
    "        for statement in statements:\n",
    "            ast = statement\n",
    "            for pass_ in self.passes:\n",
    "                pass_(ast,self)\n",
    "            clean_asts.append(ast)\n",
    "        \n",
    "        return clean_asts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3N0cmluZyNxdW90OyJdCjNbIjMKdHlwZT0jcXVvdDtkZWNsX3Rlcm1fbGlzdCNxdW90OyJdCjRbIjQKdmFsPSNxdW90O2RlY2xfc3RyaW5nI3F1b3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjEgLS0+fCJpZHg9MCJ8IDIKMyAtLT58ImlkeD0wInwgNAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3N0cmluZyNxdW90OyJdCjNbIjMKdHlwZT0jcXVvdDtjb25zdF90ZXJtX2xpc3QjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KNVsiNQp2YWw9I3F1b3Q7I3F1b3Q7YSNxdW90OyNxdW90OyJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwoxIC0tPnwiaWR4PTAifCAyCjMgLS0+fCJpZHg9MCJ8IDQKNCAtLT58ImlkeD0wInwgNQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDsiXQoyWyIyCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjNbIjMKdmFsPSNxdW90O3N0cmluZ19sZW5ndGgjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZV9saXN0I3F1b3Q7Il0KNVsiNQp0eXBlPSNxdW90O2ZyZWVfdmFyX25hbWUjcXVvdDsiXQo2WyI2CnZhbD0jcXVvdDtTdHIjcXVvdDsiXQo3WyI3CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OyJdCjhbIjgKdmFsPSNxdW90O0xlbiNxdW90OyJdCjlbIjkKdHlwZT0jcXVvdDtydWxlX2JvZHlfcmVsYXRpb25fbGlzdCNxdW90OyJdCjEwWyIxMAp0eXBlPSNxdW90O3JlbGF0aW9uI3F1b3Q7Il0KMTFbIjExCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjEyWyIxMgp2YWw9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KMTNbIjEzCnR5cGU9I3F1b3Q7dGVybV9saXN0I3F1b3Q7Il0KMTRbIjE0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OyJdCjE1WyIxNQp2YWw9I3F1b3Q7U3RyI3F1b3Q7Il0KMTZbIjE2CnR5cGU9I3F1b3Q7aWVfcmVsYXRpb24jcXVvdDsiXQoxN1siMTcKdHlwZT0jcXVvdDtyZWxhdGlvbl9uYW1lI3F1b3Q7Il0KMThbIjE4CnZhbD0jcXVvdDtMZW5ndGgjcXVvdDsiXQoxOVsiMTkKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoyMFsiMjAKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7Il0KMjFbIjIxCnZhbD0jcXVvdDtTdHIjcXVvdDsiXQoyMlsiMjIKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoyM1siMjMKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7Il0KMjRbIjI0CnZhbD0jcXVvdDtMZW4jcXVvdDsiXQowIC0tPnwiaWR4PTAifCAxCjAgLS0+fCJpZHg9MSJ8IDkKMSAtLT58ImlkeD0wInwgMgoxIC0tPnwiaWR4PTEifCA0CjIgLS0+fCJpZHg9MCJ8IDMKNCAtLT58ImlkeD0wInwgNQo0IC0tPnwiaWR4PTEifCA3CjUgLS0+fCJpZHg9MCJ8IDYKNyAtLT58ImlkeD0wInwgOAo5IC0tPnwiaWR4PTAifCAxMAo5IC0tPnwiaWR4PTEifCAxNgoxMCAtLT58ImlkeD0wInwgMTEKMTAgLS0+fCJpZHg9MSJ8IDEzCjExIC0tPnwiaWR4PTAifCAxMgoxMyAtLT58ImlkeD0wInwgMTQKMTQgLS0+fCJpZHg9MCJ8IDE1CjE2IC0tPnwiaWR4PTAifCAxNwoxNiAtLT58ImlkeD0xInwgMTkKMTYgLS0+fCJpZHg9MiJ8IDIyCjE3IC0tPnwiaWR4PTAifCAxOAoxOSAtLT58ImlkeD0wInwgMjAKMjAgLS0+fCJpZHg9MCJ8IDIxCjIyIC0tPnwiaWR4PTAifCAyMwoyMyAtLT58ImlkeD0wInwgMjQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO from here make uniq node names start from 0 every time\n",
    "# Todo make a util to compare nx to json, not tree and change grammar to use it.\n",
    "sess = DummySession()\n",
    "\n",
    "#TODO from here, figure out why 'decl_string' has a val string while being a leaf\n",
    "\n",
    "asts = sess.run_query(\"\"\"\n",
    "            new string(str)\n",
    "            string(\"a\")\n",
    "            string_length(Str, Len) <- string(Str), Length(Str) -> (Len)\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "from pydantic import ConfigDict\n",
    "\n",
    "class Span(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "    def __lt__(self, other: Span) -> bool:\n",
    "        if self.start == other.start:\n",
    "            return self.end < other.end\n",
    "\n",
    "        return self.start < other.start\n",
    "\n",
    "    # # used for sorting `Span`s in dataframes\n",
    "    # def __hash__(self) -> int:\n",
    "    #     return hash((self.start, self.end))\n",
    "\n",
    "class Var(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class FreeVar(BaseModel):\n",
    "    name: str\n",
    "\n",
    "PrimitiveType=Union[str,int,Span]\n",
    "Type = Union[PrimitiveType,Var,FreeVar]\n",
    "\n",
    "class RelationDefinition(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    scheme: List[type]\n",
    "\n",
    "class Relation(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    terms: List[Type]\n",
    "\n",
    "class IEFunction(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    in_schema: List[type]\n",
    "    out_schema: List[type]\n",
    "    func: Callable\n",
    "\n",
    "class IERelation(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    in_terms: List[Type]\n",
    "    out_terms: List[Type]\n",
    "\n",
    "class Rule(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    head: Relation\n",
    "    body: List[Union[Relation,IERelation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelationDefinition(name='x', scheme=[<class 'str'>, <class 'int'>, <class '__main__.Span'>])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RelationDefinition(name='x',scheme=[str,int,Span])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_primitive_values_to_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_primitive_values_to_objects(ast,session):\n",
    "\n",
    "    # primitive values\n",
    "    def cast_new_value(match):\n",
    "        val_type = match['var']['type']\n",
    "        value = match['val_node']['val']\n",
    "        if val_type == 'integer':\n",
    "            value = int(value)\n",
    "        elif val_type == 'var_name':\n",
    "            value = Var(name=value)\n",
    "        elif val_type == 'free_var_name':\n",
    "            value = FreeVar(name=value)\n",
    "        else:#str\n",
    "            value = str(value)\n",
    "        return value\n",
    "    \n",
    "    rewrite(ast,\n",
    "        lhs='var[type]->val_node[val]',\n",
    "        p='var[type]',\n",
    "        rhs='var[type,val={{new_val}}]',\n",
    "        condition= lambda match: match['var']['type'] in ['string','integer','var_name','relation_name','free_var_name'],\n",
    "        render_rhs={'new_val': cast_new_value},\n",
    "        # display_matches=True\n",
    "        )\n",
    "\n",
    "    # span object from 2 integers\n",
    "    for match in rewrite_iter(ast,\n",
    "        lhs='u[type=\"span\"]-[idx=0]->v;u-[idx=1]->w',\n",
    "        p='u[type]'):\n",
    "        match['u']['val']=Span(start=match['v']['val'],end=match['w']['val'])\n",
    "\n",
    "    # schema types into class types\n",
    "    decl_type_to_class = {\n",
    "        'decl_string':str,\n",
    "        'decl_int':int,\n",
    "        'decl_span':Span,\n",
    "    }\n",
    "\n",
    "    for decl_type,decl_class in decl_type_to_class.items():\n",
    "        for match in rewrite_iter(ast,lhs=f'x[val=\"{decl_type}\"]'):\n",
    "            match['x']['val']=decl_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3gjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KNFsiNAp2YWw9I3F1b3Q7I3F1b3Q7YSNxdW90OyNxdW90OyJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwoxIC0tPnwiaWR4PTAifCAyCjMgLS0+fCJpZHg9MCJ8IDQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "  # convert_primitive_values_to_objects\n",
    "  ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            x=\"a\"\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OywgdmFsPVZhcihuYW1lPSNxdW90O3gjcXVvdDspIl0KM1siMwp0eXBlPSNxdW90O2ludGVnZXIjcXVvdDssIHZhbD0xIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7Y29uc3RfdGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90OyNxdW90O2EjcXVvdDsjcXVvdDsiXQo2WyI2CnR5cGU9I3F1b3Q7aW50ZWdlciNxdW90OywgdmFsPTEiXQo4WyI4CnR5cGU9I3F1b3Q7c3BhbiNxdW90OywgdmFsPVNwYW4oc3RhcnQ9NCwgZW5kPTUpIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjMgLS0+fCJpZHg9MCJ8IDQKMyAtLT58ImlkeD0xInwgNgozIC0tPnwiaWR4PTIifCA4Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7ZGVjbF90ZXJtX2xpc3QjcXVvdDsiXQo0WyI0CnZhbD0jbHQ7Y2xhc3MgI3F1b3Q7aW50I3F1b3Q7I2d0OyJdCjVbIjUKdmFsPSNsdDtjbGFzcyAjcXVvdDtzdHIjcXVvdDsjZ3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjMgLS0+fCJpZHg9MCJ8IDQKMyAtLT58ImlkeD0xInwgNQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cXVlcnkjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7dGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3Zhcl9uYW1lI3F1b3Q7LCB2YWw9VmFyKG5hbWU9I3F1b3Q7eCNxdW90OykiXQo2WyI2CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwozIC0tPnwiaWR4PTAifCA0CjMgLS0+fCJpZHg9MSJ8IDYK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDsiXQoyWyIyCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZV9saXN0I3F1b3Q7Il0KNVsiNQp0eXBlPSNxdW90O2ZyZWVfdmFyX25hbWUjcXVvdDssIHZhbD1GcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OykiXQo3WyI3CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSJdCjlbIjkKdHlwZT0jcXVvdDtydWxlX2JvZHlfcmVsYXRpb25fbGlzdCNxdW90OyJdCjEwWyIxMAp0eXBlPSNxdW90O3JlbGF0aW9uI3F1b3Q7Il0KMTFbIjExCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQoxM1siMTMKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoxNFsiMTQKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7LCB2YWw9RnJlZVZhcihuYW1lPSNxdW90O1gjcXVvdDspIl0KMTZbIjE2CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgOQoxIC0tPnwiaWR4PTAifCAyCjEgLS0+fCJpZHg9MSJ8IDQKNCAtLT58ImlkeD0wInwgNQo0IC0tPnwiaWR4PTEifCA3CjkgLS0+fCJpZHg9MCJ8IDEwCjEwIC0tPnwiaWR4PTAifCAxMQoxMCAtLT58ImlkeD0xInwgMTMKMTMgLS0+fCJpZHg9MCJ8IDE0CjEzIC0tPnwiaWR4PTEifCAxNgo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[convert_primitive_values_to_objects])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            x=1\n",
    "            S(\"a\",1,[4,5))\n",
    "            new R(int,str)\n",
    "            ?R(x,X)\n",
    "            R(X,Y)<-S(X,Y)\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert ([serialize_tree(ast) for ast in asts] ==  [{'type': 'assignment',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 1},\n",
    "   {'type': 'integer', 'val': 1, 'id': 3}]},\n",
    " {'type': 'add_fact',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'S', 'id': 1},\n",
    "   {'type': 'const_term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'type': 'string', 'val': '\"a\"', 'id': 4},\n",
    "     {'type': 'integer', 'val': 1, 'id': 6},\n",
    "     {'type': 'span', 'val': Span(start=4, end=5), 'id': 8}]}]},\n",
    " {'type': 'relation_declaration',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'R', 'id': 1},\n",
    "   {'type': 'decl_term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'val': int, 'id': 4}, {'val': str, 'id': 5}]}]},\n",
    " {'type': 'query',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'R', 'id': 1},\n",
    "   {'type': 'term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 4},\n",
    "     {'type': 'free_var_name', 'val': FreeVar(name='X'), 'id': 6}]}]},\n",
    " {'type': 'rule',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'rule_head',\n",
    "    'id': 1,\n",
    "    'children': [{'type': 'relation_name', 'val': 'R', 'id': 2},\n",
    "     {'type': 'free_var_name_list',\n",
    "      'id': 4,\n",
    "      'children': [{'type': 'free_var_name',\n",
    "        'val': FreeVar(name='X'),\n",
    "        'id': 5},\n",
    "       {'type': 'free_var_name', 'val': FreeVar(name='Y'), 'id': 7}]}]},\n",
    "   {'type': 'rule_body_relation_list',\n",
    "    'id': 9,\n",
    "    'children': [{'type': 'relation',\n",
    "      'id': 10,\n",
    "      'children': [{'type': 'relation_name', 'val': 'S', 'id': 11},\n",
    "       {'type': 'term_list',\n",
    "        'id': 13,\n",
    "        'children': [{'type': 'free_var_name',\n",
    "          'val': FreeVar(name='X'),\n",
    "          'id': 14},\n",
    "         {'type': 'free_var_name', 'val': FreeVar(name='Y'), 'id': 16}]}]}]}]}] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove newlines from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_new_lines_from_strings(ast,sess):\n",
    "    for match in rewrite_iter(ast,\n",
    "        lhs='v[type=\"string\",val]'):\n",
    "        # TODO we also remove the starting and ending quotes, TODO make them disapear in the parsing stage\n",
    "        match['v']['val'] = match['v']['val'].replace('\\\\\\n','')[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OywgdmFsPVZhcihuYW1lPSNxdW90O3gjcXVvdDspIl0KM1siMwp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90O2hlbGxvIHdvcmxkI3F1b3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "x=\"hello \\\n",
    "world\"\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "ast = asts[0]\n",
    "assert serialize_tree(ast) == {'type': 'assignment',\n",
    " 'id': 0,\n",
    " 'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 1},\n",
    "  {'type': 'string', 'val': 'hello world', 'id': 3}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check reserved relation names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckReservedRelationNames():\n",
    "    def __init__(self,reserved_prefix):\n",
    "        self.reserved_prefix = reserved_prefix\n",
    "    def __call__(self,ast,sess):\n",
    "        for match in rewrite_iter(ast,lhs='X[type=\"relation_name\",val]'):\n",
    "            relation_name = match['X']['val']\n",
    "            if relation_name.startswith(self.reserved_prefix):\n",
    "                raise ValueError(f\"Relation name '{relation_name}' starts with reserved prefix '{self.reserved_prefix}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation name 'spanner_S' starts with reserved prefix 'spanner_'\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            S(\"a\",1)\n",
    "            R(X,Y)<-S(X,Y),T(X,Y)\n",
    "            \"\"\")\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "            spanner_S(\"a\",1)\n",
    "            \"\"\")\n",
    "print(exc_info.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7Y29uc3RfdGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90O2EjcXVvdDsiXQo2WyI2CnR5cGU9I3F1b3Q7aW50ZWdlciNxdW90OywgdmFsPTEiXQowIC0tPnwiaWR4PTAifCAxCjAgLS0+fCJpZHg9MSJ8IDMKMyAtLT58ImlkeD0wInwgNAozIC0tPnwiaWR4PTEifCA2Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(asts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check read assignments got existing path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def check_referenced_paths_exist(ast,sess):\n",
    "    for match in rewrite_iter(ast,\n",
    "    lhs='X[type=\"read_assignment\"]-[idx=1]->PathNode[val]',\n",
    "    # display_matches=True\n",
    "    ):\n",
    "        path = Path(match['PathNode']['val'])\n",
    "        if not path.exists():\n",
    "            raise ValueError(f'path {path} was not found in {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path not_existing_file.txt was not found in /Users/dean/tdk/spannerlib/nbs\n"
     ]
    }
   ],
   "source": [
    "# check that read assignments got a string which is an existing path\n",
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    ])\n",
    "\n",
    "file = Path(\"file.txt\")\n",
    "file.touch()\n",
    "\n",
    "# TODO figure out why this doesnt work\n",
    "asts = sess.run_query(f\"\"\"\n",
    "            x=read(\"file.txt\")\n",
    "            \"\"\")\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "            x=read(\"not_existing_file.txt\")\n",
    "            \"\"\")\n",
    "print(exc_info.value)\n",
    "\n",
    "file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check reference vars are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_referenced_vars_exist(ast,sess):\n",
    "\n",
    "    # first rename all left hand sign variables \n",
    "    # as type \"var_name_lhs\"\n",
    "    # so we can seperate them from reference variables\n",
    "    for assignment_type in [\"assignment\",\"read_assignment\"]:\n",
    "        for match in rewrite_iter(ast,\n",
    "                lhs=f\"\"\"X[type=\"{assignment_type}\"]-[idx=0]->LHS[type=\"var_name\",val]\"\"\"\n",
    "                ):\n",
    "            match['LHS']['type'] = \"var_name_lhs\"\n",
    "\n",
    "    # now for each reference variable check if it is in the symbol table\n",
    "    for match in rewrite_iter(ast,lhs=f\"\"\"X[type=\"var_name\",val]\"\"\"):\n",
    "        var_name = match['X']['val'].name\n",
    "        if not var_name in sess.symbol_table:\n",
    "            raise ValueError(f'Variable {var_name} is not defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable z is not defined\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    ])\n",
    "\n",
    "sess.symbol_table={'y':(int,1),'x':(str,\"hello\")}\n",
    "\n",
    "asts = sess.run_query(f\"\"\"\n",
    "            z=1\n",
    "            x=y\n",
    "            R(x,y)\n",
    "            \"\"\")\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(x,z)\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "\n",
    "# for ast in asts:\n",
    "#     draw(ast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast relations to python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relations_to_dataclasses(ast,sess):\n",
    "\n",
    "   # regular relations\n",
    "   #TODO another example where i need to edit the graph imperatively because i dont have horizontal recursion in LHS\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type]->name[type=\"relation_name\",val];\n",
    "         statement->terms[type]\n",
    "         ''',\n",
    "         #TODO i expect to be able to put an rhs here only, and if a p is not given, assume it is the identity over nodes in LHS\n",
    "         p='statement[type]',\n",
    "         condition=lambda match: (match['statement']['type'] in ['add_fact','remove_fact','relation','rule_head','query']\n",
    "                                   and match['terms']['type'] in ['const_term_list','term_list','free_var_name_list'])\n",
    "         ):\n",
    "      term_nodes = list(ast.successors(match.mapping['terms']))\n",
    "      #TODO check we iterate in order on the children\n",
    "      match['statement']['val'] = Relation(name=match['name']['val'],terms=[ast.nodes[term_node]['val'] for term_node in term_nodes])\n",
    "      ast.remove_nodes_from(term_nodes)\n",
    "   # relation declerations\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"relation_declaration\"]->name[type=\"relation_name\",val];\n",
    "         statement->terms[type=\"decl_term_list\"]\n",
    "         ''',\n",
    "         p='statement[type]'):\n",
    "      term_nodes = list(ast.successors(match.mapping['terms']))\n",
    "      match['statement']['val'] = RelationDefinition(name=match['name']['val'],scheme=[ast.nodes[term_node]['val'] for term_node in term_nodes])\n",
    "      ast.remove_nodes_from(term_nodes)\n",
    "\n",
    "   # ie relations\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"ie_relation\"]->name[type=\"relation_name\",val];\n",
    "         statement-[idx=1]->in_terms[type=\"term_list\"];\n",
    "         statement-[idx=2]->out_terms[type=\"term_list\"]\n",
    "      ''',p='statement[type]'):\n",
    "      in_term_nodes = list(ast.successors(match.mapping['in_terms']))\n",
    "      out_term_nodes = list(ast.successors(match.mapping['out_terms']))\n",
    "\n",
    "      match['statement']['val'] = IERelation(name=match['name']['val'],\n",
    "                                             in_terms=[ast.nodes[term_node]['val'] for term_node in in_term_nodes],\n",
    "                                             out_terms=[ast.nodes[term_node]['val'] for term_node in out_term_nodes]\n",
    "                                             )\n",
    "      ast.remove_nodes_from(in_term_nodes+out_term_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgNl0pIl0K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgU3BhbihzdGFydD00LCBlbmQ9NSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVtb3ZlX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgU3BhbihzdGFydD00LCBlbmQ9NSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbkRlZmluaXRpb24obmFtZT0jcXVvdDtSI3F1b3Q7LCBzY2hlbWU9WyNsdDtjbGFzcyAjcXVvdDtzdHIjcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7X19tYWluX18uU3BhbiNxdW90OyNndDssICNsdDtjbGFzcyAjcXVvdDtpbnQjcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7aW50I3F1b3Q7I2d0O10pIl0K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cXVlcnkjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSkiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KOVsiOQp0eXBlPSNxdW90O3J1bGVfYm9keV9yZWxhdGlvbl9saXN0I3F1b3Q7Il0KMTBbIjEwCnR5cGU9I3F1b3Q7cmVsYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1MjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KMThbIjE4CnR5cGU9I3F1b3Q7aWVfcmVsYXRpb24jcXVvdDssIHZhbD1JRVJlbGF0aW9uKG5hbWU9I3F1b3Q7VCNxdW90OywgaW5fdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSwgb3V0X3Rlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WSNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtaI3F1b3Q7KV0pIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCA5CjkgLS0+fCJpZHg9MCJ8IDEwCjkgLS0+fCJpZHg9MSJ8IDE4Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(\"hello\",6)\n",
    "R(\"hello\",[4,5))<-True\n",
    "R(\"hello\",[4,5))<-False\n",
    "new R(str,span,int,int)\n",
    "?R(\"hello\",Y)\n",
    "R(X,Y)<-S(X,Y),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert  [serialize_tree(ast) for ast in asts] == [{'type': 'add_fact',\n",
    "  'val': Relation(name='R', terms=['hello', 6]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'add_fact',\n",
    "  'val': Relation(name='R', terms=['hello', Span(start=4, end=5)]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'remove_fact',\n",
    "  'val': Relation(name='R', terms=['hello', Span(start=4, end=5)]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'relation_declaration',\n",
    "  'val': RelationDefinition(name='R', scheme=[str,Span,int,int]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'query',\n",
    "  'val': Relation(name='R', terms=['hello', FreeVar(name='Y')]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'rule',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'rule_head',\n",
    "    'val': Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    'id': 1},\n",
    "   {'type': 'rule_body_relation_list',\n",
    "    'id': 9,\n",
    "    'children': [{'type': 'relation',\n",
    "      'val': Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "      'id': 10},\n",
    "     {'type': 'ie_relation',\n",
    "      'val': IERelation(name='T', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "      'id': 18}]}]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation referencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check that referenced relations and ie relations:\n",
    "  * exist in the symbol table \n",
    "  * are called with the correct arity\n",
    "  * are called with correct constants or vars types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_referenced_relations(ast,sess):\n",
    "\n",
    "    def schema_match(types,vals):\n",
    "        for type_,val in zip(types,vals):\n",
    "            if isinstance(val,FreeVar):\n",
    "                continue # free vars can be anything\n",
    "            elif isinstance(val,Var):\n",
    "                var_type = sess.symbol_table[val.name][0]\n",
    "                if not type_ == var_type:\n",
    "                    return False\n",
    "            elif not isinstance(val,type_):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    for match in rewrite_iter(ast,\n",
    "            lhs='''rel[type]''',\n",
    "            condition=lambda match: match['rel']['type'] in ['add_fact','remove_fact','relation','query'],\n",
    "            ):\n",
    "        rel:Relation = match['rel']['val']\n",
    "        if not rel.name in sess.relation_schemas:\n",
    "            raise ValueError(f\"Relation '{rel.name}' is not defined\")\n",
    "        expected_len = len(sess.relation_schemas[rel.name].scheme)\n",
    "        if len(rel.terms) != expected_len:\n",
    "            raise ValueError(f\"Relation '{rel.name}' was called with {len(rel.terms)} terms but it was defined with {expected_len} terms\")\n",
    "        if not schema_match(sess.relation_schemas[rel.name].scheme,rel.terms):\n",
    "            raise ValueError(f\"Relation '{rel.name}' expected schema {sess.relation_schemas[rel.name].scheme} but got called with {rel.terms}\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation 'Z' is not defined\n",
      "Relation 'R' was called with 3 terms but it was defined with 2 terms\n",
      "Relation 'R' expected schema [<class 'str'>, <class 'int'>] but got called with [4, 4]\n",
      "Relation 'R' expected schema [<class 'str'>, <class 'int'>] but got called with ['hello', Var(name='b')]\n",
      "Relation 'R' expected schema [<class 'str'>, <class 'int'>] but got called with [4, FreeVar(name='Y')]\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations\n",
    "    ])\n",
    "\n",
    "sess.symbol_table ={\n",
    "    'a':(int,1),\n",
    "    'b':(str,\"hello\"),\n",
    "}\n",
    "\n",
    "sess.relation_schemas = {\n",
    "    'R':RelationDefinition(name='R',scheme=[str,int]),\n",
    "    'S':RelationDefinition(name='S',scheme=[str,int,int]),\n",
    "                         }\n",
    "\n",
    "sess.ie_funcs = {\n",
    "    'T':IEFunction(name='T',in_schema=[str,int],out_schema=[int,str],func=lambda x,y:(y,x))\n",
    "}\n",
    "\n",
    "\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(\"hello\",6)\n",
    "R(\"hello\",a)\n",
    "?R(\"hello\",Y)\n",
    "NewRel(X,Y)<-S(X,Y,3),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "\n",
    "# for ast in asts:\n",
    "#     draw(ast)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                Z(\"hello\",4)\n",
    "                \"\"\")\n",
    "assert \"Relation 'Z' is not defined\" in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(\"hello\",4,[4,5))\n",
    "                \"\"\")\n",
    "assert \"Relation 'R' was called with 3 terms but it was defined with 2 terms\" in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(4,4)\n",
    "                \"\"\")\n",
    "assert \"Relation 'R' expected schema [<class 'str'>, <class 'int'>]\" in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(\"hello\",b)\n",
    "                \"\"\")\n",
    "assert \"Relation 'R' expected schema [<class 'str'>, <class 'int'>]\" in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                ?R(4,Y)\n",
    "                \"\"\")\n",
    "assert \"Relation 'R' expected schema [<class 'str'>, <class 'int'>]\" in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "# assert  [serialize_tree(ast) for ast in asts] \n",
    "# [serialize_tree(ast) for ast in asts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cast rules to data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rules_to_dataclasses(ast,sess):\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"rule\"]->head[type=\"rule_head\",val];\n",
    "         statement->body[type=\"rule_body_relation_list\"]\n",
    "      ''',p='statement[type]'):\n",
    "      body_nodes = list(ast.successors(match.mapping['body']))\n",
    "      head = match['head']['val']\n",
    "      match['statement']['val'] = Rule(head=match['head']['val'],body=[ast.nodes[body_node]['val'] for body_node in body_nodes])\n",
    "      ast.remove_nodes_from(body_nodes)\n",
    "   return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OywgdmFsPVJ1bGUoaGVhZD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSksIGJvZHk9W1JlbGF0aW9uKG5hbWU9I3F1b3Q7UyNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSksIFJlbGF0aW9uKG5hbWU9I3F1b3Q7VCNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OywgdmFsPVJ1bGUoaGVhZD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSksIGJvZHk9W1JlbGF0aW9uKG5hbWU9I3F1b3Q7UyNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSksIElFUmVsYXRpb24obmFtZT0jcXVvdDtUI3F1b3Q7LCBpbl90ZXJtcz1bRnJlZVZhcihuYW1lPSNxdW90O1gjcXVvdDspLCBGcmVlVmFyKG5hbWU9I3F1b3Q7WSNxdW90OyldLCBvdXRfdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    # verify_referenced_relations,\n",
    "    rules_to_dataclasses\n",
    "    ])\n",
    "\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(X,Y,Z)<-S(X,Y),T(X,Y)\n",
    "R(X,Y,Z)<-S(X,Y),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert  [serialize_tree(ast) for ast in asts] == [{'type': 'rule',\n",
    "  'val': Rule(head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]), body=[Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]), Relation(name='T', terms=[FreeVar(name='X'), FreeVar(name='Y')])]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'rule',\n",
    "  'val': Rule(head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]), body=[Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]), IERelation(name='T', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')])]),\n",
    "  'id': 0,\n",
    "  'children': []}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistent Free Var types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Performs semantic checks on rules using a Lark tree to ensure their safety. <br>\n",
    "    A rule is considered \"safe\" when it meets certain conditions.\n",
    "\n",
    "\n",
    "    * [Rule Safety Conditions](#rule-safety-conditions)\n",
    "        * [Free Variable in Rule Head](#free-variable-in-rule-head)\n",
    "        * [Bound Free Variable](#bound-free-variable)\n",
    "    * [Examples](#examples)\n",
    "    * [Safe Relations](#safe-relations)\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Rule Safety Conditions\n",
    "\n",
    "    For a rule to be considered safe, the following two conditions must be met:\n",
    "\n",
    "    ### 1. Free Variable in Rule Head\n",
    "\n",
    "    Every free variable that appears in the rule head must occur at least once in the body as an output term of a relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `parent(X,Y) <- son(X)` is not a safe rule because the free variable `Y` only appears in the rule head.  \n",
    "    * `parent(X,Z) <- parent(X,Y), parent(Y,Z)` is a safe rule since both `X` and `Z` appear in the rule body.\n",
    "\n",
    "    ### 2. Bound Free Variable\n",
    "\n",
    "    A free variable is considered \"bound\" if it is constrained in a manner that limits the range of values it can take.\n",
    "\n",
    "    To ensure that every free variable is bound, we must ensure that every relation in the rule body is a safe relation.\n",
    "\n",
    "    ### Safe Relations\n",
    "\n",
    "    A safe relation adheres to the following:\n",
    "\n",
    "    * Its input relation is safe, meaning all its input's free variables are bound. Normal relations are always considered safe as they don't have input relations.  \n",
    "    * A bound variable is one that exists in the output of a safe relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `rel2(X,Y) <- rel1(X,Z), ie1<X>(Y)` is a safe rule as the only input free variable, `X`, exists in the output of the safe relation `rel1(X, Z)`.  \n",
    "    * `rel2(Y) <- ie1<Z>(Y)` is not safe as the input free variable `Z` does not exist in the output of any safe relation.\n",
    "\n",
    "    ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CheckRuleSafety(VisitorRecursivePass):\n",
    "    \"\"\"\n",
    "    Performs semantic checks on rules using a Lark tree to ensure their safety. <br>\n",
    "    A rule is considered \"safe\" when it meets certain conditions.\n",
    "\n",
    "\n",
    "    * [Rule Safety Conditions](#rule-safety-conditions)\n",
    "        * [Free Variable in Rule Head](#free-variable-in-rule-head)\n",
    "        * [Bound Free Variable](#bound-free-variable)\n",
    "    * [Examples](#examples)\n",
    "    * [Safe Relations](#safe-relations)\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Rule Safety Conditions\n",
    "\n",
    "    For a rule to be considered safe, the following two conditions must be met:\n",
    "\n",
    "    ### 1. Free Variable in Rule Head\n",
    "\n",
    "    Every free variable that appears in the rule head must occur at least once in the body as an output term of a relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `parent(X,Y) <- son(X)` is not a safe rule because the free variable `Y` only appears in the rule head.  \n",
    "    * `parent(X,Z) <- parent(X,Y), parent(Y,Z)` is a safe rule since both `X` and `Z` appear in the rule body.\n",
    "\n",
    "    ### 2. Bound Free Variable\n",
    "\n",
    "    A free variable is considered \"bound\" if it is constrained in a manner that limits the range of values it can take.\n",
    "\n",
    "    To ensure that every free variable is bound, we must ensure that every relation in the rule body is a safe relation.\n",
    "\n",
    "    ### Safe Relations\n",
    "\n",
    "    A safe relation adheres to the following:\n",
    "\n",
    "    * Its input relation is safe, meaning all its input's free variables are bound. Normal relations are always considered safe as they don't have input relations.  \n",
    "    * A bound variable is one that exists in the output of a safe relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `rel2(X,Y) <- rel1(X,Z), ie1<X>(Y)` is a safe rule as the only input free variable, `X`, exists in the output of the safe relation `rel1(X, Z)`.  \n",
    "    * `rel2(Y) <- ie1<Z>(Y)` is not safe as the input free variable `Z` does not exist in the output of any safe relation.\n",
    "\n",
    "    ---\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Resolve Vars\n",
    "* Register Vars\n",
    "* Register new Relations\n",
    "* Add/remove facts\n",
    "* Add rules\n",
    "* Run Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "note that after using this pass, non statement nodes will no longer appear in the tree, so passes that\n",
    "should work on said nodes need to be used before this pass in the passes pipeline (e.g. `FixString`).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenced vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move all micropasses that have to do with assignment here\n",
    "#| export\n",
    "class CheckDefinedReferencedVariables(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark tree semantic check. <br>\n",
    "    checks whether each variable reference refers to a defined variable.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    def _assert_var_defined(self, var_name: str) -> None:\n",
    "        \"\"\"\n",
    "        A utility function that checks if a variable is a defined variable in the symbol table.\n",
    "        if not, raises an exception\n",
    "\n",
    "        @param var_name: the name of the variable that will be checked\n",
    "        \"\"\"\n",
    "        if not self.symbol_table.contains_variable(var_name):\n",
    "            raise Exception(f'variable \"{var_name}\" is not defined')\n",
    "\n",
    "    def _assert_var_terms_defined(self, term_list: Sequence[DataTypeMapping.term], type_list: Sequence[DataTypes]) -> None:\n",
    "        \"\"\"\n",
    "        A utility function that checks if the non free variables in a term list are defined\n",
    "        if one of them is not defined, raises an exception.\n",
    "\n",
    "        @param term_list: a list of terms.\n",
    "        @param type_list: the type of terms in term_list.\n",
    "        \"\"\"\n",
    "        for term, term_type in zip(term_list, type_list):\n",
    "            if term_type is DataTypes.var_name:\n",
    "                # found a variable, check if it is defined\n",
    "                assert isinstance(term, str), \"a var_name must be of type str\"\n",
    "                self._assert_var_defined(term)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def assignment(self, assignment: Assignment) -> None:\n",
    "        if assignment.value_type is DataTypes.var_name:\n",
    "            # the assigned expression is a variable, check if it is defined\n",
    "            assert isinstance(assignment.value, str), \"a var_name must be of type str\"\n",
    "            self._assert_var_defined(assignment.value)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def read_assignment(self, assignment: ReadAssignment) -> None:\n",
    "        if assignment.read_arg_type is DataTypes.var_name:\n",
    "            # a variable is used as the argument for read(), check if it is defined\n",
    "            assert isinstance(assignment.read_arg, str), \"a var_name must be of type str\"\n",
    "            self._assert_var_defined(assignment.read_arg)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def add_fact(self, fact: AddFact) -> None:\n",
    "        self._assert_var_terms_defined(fact.term_list, fact.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def remove_fact(self, fact: RemoveFact) -> None:\n",
    "        self._assert_var_terms_defined(fact.term_list, fact.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def query(self, query: Query) -> None:\n",
    "        self._assert_var_terms_defined(query.term_list, query.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "\n",
    "        # for each relation in the rule body, check if its variable terms are defined\n",
    "        for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "            if isinstance(relation, Relation):\n",
    "                self._assert_var_terms_defined(relation.term_list, relation.type_list)\n",
    "            elif isinstance(relation, IERelation):\n",
    "                # ie relations have input terms and output terms, check them both\n",
    "                self._assert_var_terms_defined(relation.input_term_list, relation.input_type_list)\n",
    "                self._assert_var_terms_defined(relation.output_term_list, relation.output_type_list)\n",
    "            else:\n",
    "                raise Exception(f'unexpected relation type: {relation_type}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## referenced relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CheckReferencedRelationsExistenceAndArity(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark tree semantic check. <br>\n",
    "    Checks whether each normal relation (that is not an ie relation) reference refers to a defined relation.\n",
    "    Also checks if the relation reference uses the correct arity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    def _assert_relation_exists_and_correct_arity(self, relation: Relation) -> None:\n",
    "        \"\"\"\n",
    "        A utility function that checks if a relation exists in the symbol table\n",
    "        and if the correct arity was used.\n",
    "\n",
    "        @param relation: the relation that will be checked.\n",
    "        \"\"\"\n",
    "\n",
    "        # get the relation name and the arity that was used by the user\n",
    "        relation_name = relation.relation_name\n",
    "        used_arity = len(relation.term_list)\n",
    "\n",
    "        # check if the relation exists using the symbol table\n",
    "        if not self.symbol_table.contains_relation(relation_name):\n",
    "            raise Exception(f'relation \"{relation_name}\" is not defined')\n",
    "\n",
    "        # at this point we know the relation exists but we still need to check that the correct arity was used\n",
    "        # get the correct arity\n",
    "        relation_schema = self.symbol_table.get_relation_schema(relation_name)\n",
    "        correct_arity = len(relation_schema)\n",
    "\n",
    "        # check if that arity that was used is correct\n",
    "        if used_arity != correct_arity:\n",
    "            raise Exception(f'relation \"{relation_name}\" was referenced with an incorrect arity: {used_arity}. The '\n",
    "                            f'correct arity is: {correct_arity}')\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def query(self, query: Query) -> None:\n",
    "        # a query is defined by a relation reference, so we can simply use the utility function\n",
    "        self._assert_relation_exists_and_correct_arity(query)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def add_fact(self, fact: AddFact) -> None:\n",
    "        # a fact is defined by a relation reference, so we can simply use the utility function\n",
    "        self._assert_relation_exists_and_correct_arity(fact)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def remove_fact(self, fact: RemoveFact) -> None:\n",
    "        # a fact is defined by a relation reference, so we can simply use the utility function\n",
    "        self._assert_relation_exists_and_correct_arity(fact)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "        \"\"\"\n",
    "        A rule is a definition of the relation in the rule head. Therefore the rule head reference does not\n",
    "        need to be checked.\n",
    "        The rule body references relations that should already exist. Those will be checked in this method.\n",
    "        \"\"\"\n",
    "\n",
    "        # check that each normal relation in the rule body exists and that the correct arity was used\n",
    "        for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "            if isinstance(relation, Relation):\n",
    "                self._assert_relation_exists_and_correct_arity(relation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CheckReferencedIERelationsExistenceAndArity(VisitorRecursivePass):\n",
    "    \"\"\"\n",
    "    A lark tree semantic check. <br>\n",
    "    Checks whether each ie relation reference refers to a defined ie function. <br>\n",
    "    Also checks if the correct input arity and output arity for the ie function were used.\n",
    "\n",
    "    Currently, an ie relation can only be found in a rule's body, so this is the only place where this\n",
    "    check will be performed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "\n",
    "        # for each ie relation in the rule body, check its existence and arity\n",
    "        for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "            if isinstance(relation, IERelation):\n",
    "\n",
    "                # get the name of the ie function, it is the same as the name of the ie relation\n",
    "                ie_func_name = relation.relation_name\n",
    "\n",
    "                # assert that the ie function exists\n",
    "                if not self.symbol_table.contains_ie_function(ie_func_name):\n",
    "                    raise Exception(f'the information extraction function \"{ie_func_name}\" does not exist')\n",
    "\n",
    "                # the ie function exists, gets its data\n",
    "                ie_func_data = self.symbol_table.get_ie_func_data(ie_func_name)\n",
    "\n",
    "                # check if the correct input arity was used\n",
    "                used_input_arity = len(relation.input_term_list)\n",
    "                correct_input_arity = len(ie_func_data.get_input_types())\n",
    "                if used_input_arity != correct_input_arity:\n",
    "                    raise Exception(f'used incorrect input arity for ie function \"{ie_func_name}\":'\n",
    "                                    f' {used_input_arity} (should be {correct_input_arity})')\n",
    "\n",
    "                # check if the correct output arity was used\n",
    "                used_output_arity = len(relation.output_term_list) + len(relation.input_term_list)\n",
    "                correct_output_arity = len(ie_func_data.get_output_types(used_output_arity))\n",
    "                if used_output_arity != correct_output_arity:\n",
    "                    raise Exception(f'used incorrect output arity for ie function {ie_func_name}:'\n",
    "                                    f' {used_output_arity} (should be {correct_output_arity})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CheckRuleSafety(VisitorRecursivePass):\n",
    "    \"\"\"\n",
    "    Performs semantic checks on rules using a Lark tree to ensure their safety. <br>\n",
    "    A rule is considered \"safe\" when it meets certain conditions.\n",
    "\n",
    "\n",
    "    * [Rule Safety Conditions](#rule-safety-conditions)\n",
    "        * [Free Variable in Rule Head](#free-variable-in-rule-head)\n",
    "        * [Bound Free Variable](#bound-free-variable)\n",
    "    * [Examples](#examples)\n",
    "    * [Safe Relations](#safe-relations)\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Rule Safety Conditions\n",
    "\n",
    "    For a rule to be considered safe, the following two conditions must be met:\n",
    "\n",
    "    ### 1. Free Variable in Rule Head\n",
    "\n",
    "    Every free variable that appears in the rule head must occur at least once in the body as an output term of a relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `parent(X,Y) <- son(X)` is not a safe rule because the free variable `Y` only appears in the rule head.  \n",
    "    * `parent(X,Z) <- parent(X,Y), parent(Y,Z)` is a safe rule since both `X` and `Z` appear in the rule body.\n",
    "\n",
    "    ### 2. Bound Free Variable\n",
    "\n",
    "    A free variable is considered \"bound\" if it is constrained in a manner that limits the range of values it can take.\n",
    "\n",
    "    To ensure that every free variable is bound, we must ensure that every relation in the rule body is a safe relation.\n",
    "\n",
    "    ### Safe Relations\n",
    "\n",
    "    A safe relation adheres to the following:\n",
    "\n",
    "    * Its input relation is safe, meaning all its input's free variables are bound. Normal relations are always considered safe as they don't have input relations.  \n",
    "    * A bound variable is one that exists in the output of a safe relation.\n",
    "\n",
    "    #### Examples\n",
    "\n",
    "    * `rel2(X,Y) <- rel1(X,Z), ie1<X>(Y)` is a safe rule as the only input free variable, `X`, exists in the output of the safe relation `rel1(X, Z)`.  \n",
    "    * `rel2(Y) <- ie1<Z>(Y)` is not safe as the input free variable `Z` does not exist in the output of any safe relation.\n",
    "\n",
    "    ---\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "        head_relation = rule.head_relation\n",
    "        body_relation_list = rule.body_relation_list\n",
    "        body_relation_type_list = rule.body_relation_type_list\n",
    "\n",
    "        # check condition 1:\n",
    "        # every free variable in the head occurs at least once in the body as an output term of a relation.\n",
    "\n",
    "        # get the free variables in the rule head\n",
    "        rule_head_free_vars = get_free_var_names(head_relation.term_list, head_relation.type_list)\n",
    "\n",
    "        # get the free variables in the rule body that serve as output terms.\n",
    "        rule_body_output_free_var_sets = [get_output_free_var_names(relation) for relation in body_relation_list]\n",
    "        rule_body_output_free_vars = set.union(*rule_body_output_free_var_sets)\n",
    "\n",
    "        # make sure that every free variable in the rule head appears at least once as an output term\n",
    "        # in the rule body\n",
    "        bad_rule_head_free_vars = rule_head_free_vars.difference(rule_body_output_free_vars)\n",
    "        if bad_rule_head_free_vars:\n",
    "            raise Exception(f'The rule \"{rule}\" \\n'\n",
    "                            f'is not safe because the following free variables appear in the '\n",
    "                            'rule head but not as output terms in the rule body:\\n'\n",
    "                            f'{bad_rule_head_free_vars}')\n",
    "\n",
    "        # check condition 2:\n",
    "        # every free variable is bound.\n",
    "\n",
    "        # use a fix point iteration algorithm to find if all the free variables are bound:\n",
    "        # a. iterate over all of the rule body relations and check if they are safe, meaning all their input\n",
    "        # free variable terms are bound.\n",
    "        # b. if a relation is safe, mark its output free variables as bound.\n",
    "        # c. repeat step 'a' until no new bound free variables are found.\n",
    "\n",
    "        def get_size_difference(set1: Set, set2: Set) -> int:\n",
    "            \"\"\"\n",
    "            A utility function to be used as the distance function of the fixed point algorithm.\n",
    "\n",
    "            @return: the size difference of set1 and set2.\n",
    "            \"\"\"\n",
    "            size_difference = abs(len(set1) - len(set2))\n",
    "            return size_difference\n",
    "\n",
    "        def get_bound_free_vars(known_bound_free_vars: Set[str]) -> Set[str]:\n",
    "            \"\"\"\n",
    "            a utility function to be used as the step function of the fixed point algorithm.\n",
    "            this function iterates over all of the rule body relations, checking if each one of them is safe.\n",
    "            if a rule is found to be safe, this function will mark its output free variables as bound.\n",
    "\n",
    "            @param known_bound_free_vars: a set of the free variables in the rule that are known to be bound.\n",
    "            @return: a union of 'known_bound_free_vars' with the bound free variables that were found.\n",
    "            \"\"\"\n",
    "\n",
    "            for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "                # check if all of its input free variable terms of the relation are bound\n",
    "                input_free_vars = get_input_free_var_names(relation)\n",
    "                unbound_input_free_vars = input_free_vars.difference(known_bound_free_vars)\n",
    "                if len(unbound_input_free_vars) == 0:\n",
    "                    # all input free variables are bound, mark the relation's output free variables as bound\n",
    "                    output_free_vars = get_output_free_var_names(relation)\n",
    "                    known_bound_free_vars = known_bound_free_vars.union(output_free_vars)\n",
    "\n",
    "            return known_bound_free_vars\n",
    "\n",
    "        # get the bound free variables\n",
    "        bound_free_vars = fixed_point(start=set(), step=get_bound_free_vars, distance=get_size_difference, thresh=0)\n",
    "\n",
    "        # get all of the input free variables that were used in the rule body\n",
    "        rule_body_input_free_var_sets = [get_input_free_var_names(relation)\n",
    "                                         for relation, relation_type in\n",
    "                                         zip(body_relation_list, body_relation_type_list)]\n",
    "        rule_body_input_free_vars = set.union(*rule_body_input_free_var_sets)\n",
    "\n",
    "        # assert there aren't any unbound free variables\n",
    "        unbound_free_vars = rule_body_input_free_vars.difference(bound_free_vars)\n",
    "        if unbound_free_vars:\n",
    "            # condition 2 check failed, get all of the unbound free variables and pass them in an exception\n",
    "            raise Exception(f'The rule \"{rule}\" \\n'\n",
    "                            f'is not safe because the following free variables are not bound:\\n'\n",
    "                            f'{unbound_free_vars}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type check assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TypeCheckAssignments(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark semantic check <br>\n",
    "    performs type checking for `Assignments` <br>\n",
    "    in the current version of lark, this type checking is only required for read assignments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def read_assignment(self, assignment: ReadAssignment) -> None:\n",
    "\n",
    "        # get the type of the argument for the read() function\n",
    "        if assignment.read_arg_type is DataTypes.var_name:\n",
    "            read_arg_var_name = assignment.read_arg\n",
    "            read_arg_type = self.symbol_table.get_variable_type(read_arg_var_name)\n",
    "        else:\n",
    "            read_arg_type = assignment.read_arg_type\n",
    "\n",
    "        # if the argument is not of type string, raise and exception\n",
    "        if read_arg_type is not DataTypes.string:\n",
    "            raise Exception(f'type checking failed for the read assignment {assignment}\\n'\n",
    "                            f'because the argument type for read() was {read_arg_type} (must be a string)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type check relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TypeCheckRelations(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A Lark Tree Semantic Check\n",
    "\n",
    "    ### Assumptions\n",
    "\n",
    "    This pass operates under the following assumptions. Failure to meet these may lead to incorrect results:\n",
    "\n",
    "    1. References to relations and IE (Information Extraction) relations, as well as their arity, have been properly checked.\n",
    "    2. Variable references have been verified.\n",
    "    3. The pass only processes a single statement as input.\n",
    "\n",
    "    ### Semantic Checks\n",
    "\n",
    "    The pass performs the following specific checks:\n",
    "\n",
    "    #### 1. Typed Relation References\n",
    "\n",
    "    It verifies if the relation references in the rule are correctly typed.\n",
    "\n",
    "    #### 2. Typed IE Relations\n",
    "\n",
    "    It verifies if the IE relations in the rule are correctly typed.\n",
    "\n",
    "    #### 3. Conflicting Types in Free Variables\n",
    "\n",
    "    Checks if free variables within rules have conflicting types. This is crucial to ensure that the rules are logically coherent.\n",
    "\n",
    "    ### Example\n",
    "\n",
    "    Here is an example that illustrates how a semantic check may fail on the third type of check:\n",
    "\n",
    "    ```prolog\n",
    "    new A(str)\n",
    "    new B(int)\n",
    "    C(X) <- A(X), B(X)  # Error: X is expected to be both an int and a string.\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def add_fact(self, fact: AddFact) -> None:\n",
    "        # a fact is defined by a relation, check if that relation is properly typed\n",
    "        type_check_passed = check_properly_typed_relation(fact, self.symbol_table)\n",
    "        if not type_check_passed:\n",
    "            raise Exception(f'type check failed for fact: \"{fact}\"')\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def remove_fact(self, fact: RemoveFact) -> None:\n",
    "        # a fact is defined by a relation, check if that relation is properly typed\n",
    "        type_check_passed = check_properly_typed_relation(fact, self.symbol_table)\n",
    "        if not type_check_passed:\n",
    "            raise Exception(f'type check failed for fact: \"{fact}\"')\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def query(self, query: Query) -> None:\n",
    "        # a query is defined by a relation, check if that relation is properly typed\n",
    "        type_check_passed = check_properly_typed_relation(query, self.symbol_table)\n",
    "        if not type_check_passed:\n",
    "            raise Exception(f'type check failed for query: \"{query}\"')\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "\n",
    "        # for each relation in the rule body, check if it is properly typed, raise an exception if it isn't\n",
    "        for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "            relation_is_properly_typed = check_properly_typed_relation(relation, self.symbol_table)\n",
    "            if not relation_is_properly_typed:\n",
    "                raise Exception(f'type check failed for rule \"{rule}\"\\n'\n",
    "                                f'because the relation \"{relation}\"\\n'\n",
    "                                f'is not properly typed')\n",
    "\n",
    "        # check for free variables with conflicting type in the rule, raise an exception if there are any\n",
    "        _, conflicted_free_vars = type_check_rule_free_vars(rule, self.symbol_table)\n",
    "        if conflicted_free_vars:\n",
    "            raise Exception(f'type check failed for rule \"{rule}\"\\n'\n",
    "                            f'because the following free variables have conflicting types:\\n'\n",
    "                            f'{conflicted_free_vars}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacvedeclared relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveDeclaredRelationsSchemas(InterpreterPass):\n",
    "    \"\"\"\n",
    "    This pass writes the relation schemas that it finds in relation declarations and rule heads* to the\n",
    "    symbol table.\n",
    "\n",
    "    This pass assumes that type checking was already performed on its input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def relation_declaration(self, relation_decl: RelationDeclaration) -> None:\n",
    "        self.symbol_table.add_relation_schema(relation_decl.relation_name, relation_decl.type_list, False)\n",
    "\n",
    "    @no_type_check\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "        # a rule head relation only contains free variable terms, meaning its schema is defined exclusively by the\n",
    "        # types of said free variables. a free variable type in a rule can be found using the schemas of relations\n",
    "        # in the rule body\n",
    "        # get a mapping from a free variable in this rule to its type\n",
    "        free_var_to_type, _ = type_check_rule_free_vars(rule, self.symbol_table)\n",
    "\n",
    "        # get the schema of the rule head relation and add it to the symbol table\n",
    "        head_relation = rule.head_relation\n",
    "        term_list = head_relation.term_list\n",
    "        rule_head_schema = [free_var_to_type[term] for term in term_list]\n",
    "        self.symbol_table.add_relation_schema(head_relation.relation_name, rule_head_schema, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Note that a rule is a relation declaration of the rule head relation and a definition of its contents\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resovle var references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResolveVariablesReferences(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark execution pass, <br>\n",
    "    this pass replaces variable references with their literal values. <br>\n",
    "    also replaces `DataTypes.var_name` types with the real type of the variable.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def assignment(self, assignment: Assignment) -> None:\n",
    "        # if the assigned value is a variable, replace it with its literal value\n",
    "        if assignment.value_type is DataTypes.var_name:\n",
    "            assigned_value = assignment.value\n",
    "            assignment.value = self.symbol_table.get_variable_value(assigned_value)\n",
    "            assignment.value_type = self.symbol_table.get_variable_type(assigned_value)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def read_assignment(self, assignment: ReadAssignment) -> None:\n",
    "        # if the read() argument is a variable, replace it with its literal value\n",
    "        if assignment.read_arg_type is DataTypes.var_name:\n",
    "            read_arg_var_name = assignment.read_arg\n",
    "            assignment.read_arg = self.symbol_table.get_variable_value(read_arg_var_name)\n",
    "            assignment.read_arg_type = self.symbol_table.get_variable_type(read_arg_var_name)\n",
    "\n",
    "    @no_type_check\n",
    "    def _resolve_var_terms(self, term_list: Sequence[DataTypeMapping.term], type_list: Sequence[DataTypes]) -> None:\n",
    "        \"\"\"\n",
    "        A utility function for resolving variables in term lists\n",
    "        for each variable term in term_list, replace its value in term_list with its literal value, and\n",
    "        its DataTypes.var_name type in type_list with its real type\n",
    "        the changes to the lists are done in-place.\n",
    "\n",
    "        @param term_list: a list of terms.\n",
    "        @param type_list: the type of terms in term_list.\n",
    "        \"\"\"\n",
    "\n",
    "        # get the list of terms with resolved variable values\n",
    "        resolved_var_values_term_list = [\n",
    "            self.symbol_table.get_variable_value(term) if term_type is DataTypes.var_name\n",
    "            else term\n",
    "            for term, term_type in zip(term_list, type_list)]\n",
    "\n",
    "        # get the list of types with resolved variable types\n",
    "        resolved_var_types_type_list = [\n",
    "            self.symbol_table.get_variable_type(term) if term_type is DataTypes.var_name\n",
    "            else term_type\n",
    "            for term, term_type in zip(term_list, type_list)]\n",
    "\n",
    "        # replace the lists with the resolved lists. use slicing to do it in-place.\n",
    "        term_list[:] = resolved_var_values_term_list\n",
    "        type_list[:] = resolved_var_types_type_list\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def query(self, query: Query) -> None:\n",
    "        self._resolve_var_terms(query.term_list, query.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def add_fact(self, fact: AddFact) -> None:\n",
    "        self._resolve_var_terms(fact.term_list, fact.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def remove_fact(self, fact: RemoveFact) -> None:\n",
    "        self._resolve_var_terms(fact.term_list, fact.type_list)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "        # resolve the variables of each relation in the rule body relation list\n",
    "        for relation, relation_type in zip(rule.body_relation_list, rule.body_relation_type_list):\n",
    "            if isinstance(relation, Relation):\n",
    "                self._resolve_var_terms(relation.term_list, relation.type_list)\n",
    "            elif isinstance(relation, IERelation):\n",
    "                # ie relations have two term lists (input and output), resolve them both\n",
    "                self._resolve_var_terms(relation.input_term_list, relation.input_type_list)\n",
    "                self._resolve_var_terms(relation.output_term_list, relation.output_type_list)\n",
    "            else:\n",
    "                raise Exception(f'unexpected relation type: {relation_type}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ExecuteAssignments(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark execution pass, <br>\n",
    "    executes assignments by saving variables' values and types in the symbol table <br>\n",
    "    should be used only after variable references are resolved, meaning the assigned values and read() arguments\n",
    "    are guaranteed to be literals.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, symbol_table: SymbolTableBase, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.symbol_table = symbol_table\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def assignment(self, assignment: Assignment) -> None:\n",
    "        # perform the assignment by saving the variable attributes in the symbol table\n",
    "        self.symbol_table.set_var_value_and_type(assignment.var_name, assignment.value, assignment.value_type)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def read_assignment(self, assignment: ReadAssignment) -> None:\n",
    "        # try to read the file and get its content as a single string. this string is the assigned value.\n",
    "        try:\n",
    "            assigned_value = Path(assignment.read_arg).read_text()\n",
    "        except Exception:\n",
    "            raise Exception(f'could not open file \"{assignment.read_arg}\"')\n",
    "\n",
    "        # perform the assignment by saving the variable attributes in the symbol table\n",
    "        # note that since this is a read assignment, the type of the variable will always be a string\n",
    "        self.symbol_table.set_var_value_and_type(assignment.var_name, assigned_value, DataTypes.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add statement to netxparse graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clue why we need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#TODO agg - rewrite this to not exist? and if it exist use a naive netx graph\n",
    "class AddStatementsToNetxParseGraph(InterpreterPass):\n",
    "    \"\"\"\n",
    "    A lark execution pass. <br>\n",
    "    This pass adds each statement in the input parse tree to the parse graph. <br>\n",
    "    This pass is made to work with execution.naive_execution as the execution function and\n",
    "    `term_graph.NetxStateGraph` as the parse graph.\n",
    "\n",
    "    Each statement in the parse graph will be a child of the parse graph's root.\n",
    "\n",
    "    Each statement in the parse graph will have a type attribute that contains the statement's name in the\n",
    "    spannerlog grammar.\n",
    "\n",
    "    Some nodes in the parse graph will contain a value attribute that would contain a relation that describes\n",
    "    that statement.\n",
    "    e.g. a `add_fact` node would have a value which is a `structured_nodes.AddFact` instance\n",
    "    (which inherits from `structured_nodes.Relation`) that describes the fact that will be added.\n",
    "\n",
    "    Some statements are more complex and will be described by more than a single node, e.g. a rule node.\n",
    "    The reason for this is that we want a single netx node to not contain more than one Relation\n",
    "    (or `IERelation`) instance. This will make the parse graph a \"graph of relation nodes\", allowing\n",
    "    for flexibility for optimization in the future.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parse_graph, **kw: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.parse_graph = parse_graph\n",
    "\n",
    "    def _add_statement_to_parse_graph(self, statement_type: ParseNodeType, statement_value: Any) -> None:\n",
    "        \"\"\"\n",
    "        A utility function that adds a statement to the parse graph, meaning it adds a node that\n",
    "        represents the statement to the parse graph, then attach the node to the parse graph's root.\n",
    "        Should only be used for simple statements (i.e. can be described by a single node).\n",
    "\n",
    "        @param statement_type: the type of the statement, (e.g. add_fact). should be the same as the statement's\n",
    "                               name in the grammar. Will be set as the node's type attribute.\n",
    "        @param statement_value: will be set as the value attribute of the node.\n",
    "        \"\"\"\n",
    "        new_statement_node = self.parse_graph.add_node(type=statement_type, value=statement_value)\n",
    "        self.parse_graph.add_edge(self.parse_graph.get_root_id(), new_statement_node)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def add_fact(self, fact: AddFact) -> None:\n",
    "        self._add_statement_to_parse_graph(ParseNodeType.ADD_FACT, fact)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def remove_fact(self, fact: RemoveFact) -> None:\n",
    "        self._add_statement_to_parse_graph(ParseNodeType.REMOVE_FACT, fact)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def query(self, query: Query) -> None:\n",
    "        self._add_statement_to_parse_graph(ParseNodeType.QUERY, query)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def relation_declaration(self, relation_decl: RelationDeclaration) -> None:\n",
    "        self._add_statement_to_parse_graph(ParseNodeType.RELATION_DECLARATION, relation_decl)\n",
    "\n",
    "    @unravel_lark_node\n",
    "    def rule(self, rule: Rule) -> None:\n",
    "        self._add_statement_to_parse_graph(ParseNodeType.RULE, rule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
