{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tests.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spannerlib.primitive_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraph_rewrite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspannerlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_df\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspannerlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Session\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/session.py:54\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspannerlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmicro_passes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     convert_primitive_values_to_objects,\n\u001b[1;32m     39\u001b[0m     remove_new_lines_from_strings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     execute_statement,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# %% ../nbs/030_session.ipynb 4\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mie_func\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonPath, JsonPathFull\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mie_func\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment, TrueCase)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mie_func\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython_regex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PYRGX, PYRGX_STRING\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/ie_func/json_path.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjsonpath_ng\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprimitive_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataTypes\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# %% ../../nbs/ie_func/04a_json_path.ipynb 4\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_match\u001b[39m(match: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spannerlib.primitive_types'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| output: false\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Iterable, Dict, no_type_check, Type\n",
    "import pandas as pd\n",
    "\n",
    "from graph_rewrite import draw\n",
    "from spannerlib.utils import assert_df\n",
    "from spannerlib.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def test_session(\n",
    "    context,\n",
    "    queries,\n",
    "    expected_outputs,# either a set of tuples or (set of tuples,list of columns)\n",
    "    ie_funcs=None,# List of [name,func,in_scheme,out_scheme]\n",
    "    csvs=None,# List of [name,df]\n",
    "    debug=False,\n",
    "    ):\n",
    "    sess=Session()\n",
    "    # init session with context\n",
    "\n",
    "    # add csvs\n",
    "\n",
    "    # register functions\n",
    "\n",
    "    for query,expected in zip(queries,expected_outputs):\n",
    "        if debug:\n",
    "            print(query)\n",
    "            q,root = sess.plan_query(query)\n",
    "            draw(q)\n",
    "            res = sess.execute_plan(q)\n",
    "        else:\n",
    "            res = context.export(query)\n",
    "        if isinstance(expected,tuple):\n",
    "            values,columns = expected\n",
    "            assert_df(res,values,columns)\n",
    "        else:\n",
    "            assert_df(res,expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_equal_stripped_sorted_tables(result_text: str, expected_text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Compares all lines in between two strings, ignoring the order of the lines.\n",
    "\n",
    "    @param result_text: first string to compare, usually the output of a test.\n",
    "    @param expected_text: second string to compare, usually the expected output of a test.\n",
    "    @return: True if equal, else False.\n",
    "    \"\"\"\n",
    "    sorted_result_text = sorted([line.strip() for line in result_text.splitlines() if line.strip()])\n",
    "    sorted_expected_text = sorted([line.strip() for line in expected_text.splitlines() if line.strip()])\n",
    "    return sorted_result_text == sorted_expected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_equal_dataframes_ignore_order(result_df: DataFrame, expected_df: DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Similarly to `is_equal_stripped_sorted_tables`, compares two dataframes while ignoring the order of the rows.\n",
    "\n",
    "    @param result_df: first dataframe to compare.\n",
    "    @param expected_df: second dataframe to compare.\n",
    "    @return: True if equal, else False.\n",
    "    \"\"\"\n",
    "    result_df_sorted = DataFrame(np.sort(result_df.values, axis=0), index=result_df.index, columns=result_df.columns)\n",
    "    expected_df_sorted = DataFrame(np.sort(expected_df.values, axis=0), index=expected_df.index,\n",
    "                                   columns=expected_df.columns)\n",
    "    return result_df_sorted.equals(expected_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def table_to_query_free_vars_tuples(table: str) -> Iterable:\n",
    "    \"\"\"\n",
    "    Parses the string table into a nicer format.\n",
    "\n",
    "    @param table: the string that represents a table.\n",
    "    @return: the clean format (see comments above return statements).\n",
    "    \"\"\"\n",
    "    # split string into lines and ignore white spaces.\n",
    "    # tuple[0] is always the print statement.\n",
    "    tuples = [line.strip() for line in table.split(\"\\n\") if len(line.strip()) != 0]\n",
    "    if len(tuples) < 2:\n",
    "        raise ValueError(\"illegal output received: \\n\\\"\" + '\\n'.join(tuples) + '\"')\n",
    "    # if table is empty (which means it contains one value of true/false) we return tuple.\n",
    "    # tuple[0] is the print statement, tuple[1] is true/false.\n",
    "    if tuples[1] in [\"[()]\", \"[]\"]:\n",
    "        return tuples\n",
    "    # if table is not empty, then: tuple[0] is the print statement, tuple[1] are the free vars and tuple[3:] contains\n",
    "    # all the tuples inside the table .\n",
    "    else:  # query   |free vars|     tuples\n",
    "        return tuples[0], tuples[1], set(tuples[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_to_tables(result: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    @param result: spannerlog's output.\n",
    "    @return: List of strings, each string represents a table.\n",
    "    \"\"\"\n",
    "\n",
    "    # in spannerlog's output, all tables are separated by two consecutive \\n.\n",
    "    return result.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compare_strings(expected: str, output: str) -> bool:\n",
    "    \"\"\"\n",
    "    @param expected: expected output.\n",
    "    @param output: actual output.\n",
    "    @return: True if output and expected represent the same result, False otherwise.\n",
    "    \"\"\"\n",
    "    expected = \"\\n\".join([line.strip() for line in expected.splitlines()])\n",
    "    output = \"\\n\".join([line.strip() for line in output.splitlines()])\n",
    "\n",
    "    expected_tables, output_tables = split_to_tables(expected), split_to_tables(output)\n",
    "    # if there are different number of tables than false\n",
    "    if len(expected_tables) != len(output_tables):\n",
    "        return False\n",
    "\n",
    "    # check that all the tables are equal\n",
    "    for expected_table, output_table in zip(expected_tables, output_tables):\n",
    "        if table_to_query_free_vars_tuples(expected_table) != table_to_query_free_vars_tuples(output_table):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@no_type_check\n",
    "def run_test(commands: str, expected_output: Optional[str] = None, functions_to_import: Iterable[Dict] = (),\n",
    "             session: Optional[Session] = None) -> Session:\n",
    "    \"\"\"\n",
    "    A function that executes a test.\n",
    "\n",
    "    @param commands: the commands to run.\n",
    "    @param expected_output: the expected output of the commands. if it has value of None, than we won't check the output.\n",
    "    @param functions_to_import: an iterable of functions we want to import to the session.\n",
    "    @param session: the session in which we run the commands.\n",
    "    @return: the session it created or got as an argument.\n",
    "    \"\"\"\n",
    "    # if session wasn't passed as an arg than we create it\n",
    "    if session is None:\n",
    "        session = Session()\n",
    "\n",
    "    # import all ie functions\n",
    "    for ie_function in functions_to_import:\n",
    "        session.register(**ie_function)\n",
    "    commands_result = session.run_commands(commands, print_results=True)\n",
    "\n",
    "    if expected_output is not None:\n",
    "        commands_result_string = queries_to_string(commands_result)\n",
    "        assert compare_strings(expected_output, commands_result_string), \"expected string != result string\"\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_unordered_dataframes_equal(df1: pd.DataFrame, df2: pd.DataFrame) -> bool:\n",
    "    if set(df1.columns) != set(df2.columns):\n",
    "        print(\"Columns do not match.\")\n",
    "        return False\n",
    "    \n",
    "    df1 = df1.sort_values(by=list(df1.columns)).reset_index(drop=True)\n",
    "    df2 = df2.sort_values(by=list(df2.columns)).reset_index(drop=True)\n",
    "\n",
    "    return df1.equals(df2)\n",
    "\n",
    "@no_type_check\n",
    "def run_test_df_compare(commands: str, expected_output: Optional[pd.DataFrame] = None, functions_to_import: Iterable[Dict] = (),\n",
    "             session: Optional[Session] = None) -> Session:\n",
    "    \"\"\"\n",
    "    A function that executes a test.\n",
    "\n",
    "    @param commands: the commands to run.\n",
    "    @param expected_output: the expected output of the commands (in a format of pd.DataFrame). if it has value of None, than we won't check the output.\n",
    "    @param functions_to_import: an iterable of functions we want to import to the session.\n",
    "    @param session: the session in which we run the commands.\n",
    "    @return: the session it created or got as an argument.\n",
    "    \"\"\"\n",
    "    if session is None:\n",
    "        session = Session()\n",
    "\n",
    "    for ie_function in functions_to_import:\n",
    "        session.register(**ie_function)\n",
    "\n",
    "    command_result = session.send_commands_result_into_df(commands)\n",
    "\n",
    "    if expected_output is not None:\n",
    "        assert check_unordered_dataframes_equal(command_result, expected_output)\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_session_with_optimizations(parse_graph_optimization_passes: Iterable[Type[GenericPass]] = (),\n",
    "                                   term_graph_optimization_passes: Iterable[Type[GenericPass]] = ()) -> Session:\n",
    "    \"\"\"\n",
    "    Creates a session and adds optimization passes to the pass stack.\n",
    "    @param parse_graph_optimization_passes: optimization passes that will be added before AddRulesToComputationTermGraph pass.\n",
    "    @param term_graph_optimization_passes: optimization passes that will be added after AddRulesToComputationTermGraph pass\n",
    "    @return: the session.\n",
    "    \"\"\"\n",
    "    session = Session()\n",
    "    pass_stack = session.get_pass_stack()\n",
    "    term_graph_pass = pass_stack.pop()\n",
    "\n",
    "    pass_stack.extend(parse_graph_optimization_passes)\n",
    "    pass_stack.append(term_graph_pass)\n",
    "    pass_stack.extend(term_graph_optimization_passes)\n",
    "\n",
    "    session.set_pass_stack(pass_stack)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_commands_into_csv_test(expected_longrel: str, im_ex_session: Session, commands: str, query_for_csv: str) -> None:\n",
    "    im_ex_session.run_commands(commands, print_results=False)\n",
    "    # query into csv and compare with old file\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_csv = Path(temp_dir) / TEMP_FILE_NAME\n",
    "        im_ex_session.send_commands_result_into_csv(query_for_csv, temp_csv)\n",
    "        assert Path(temp_csv).is_file(), \"file was not created\"\n",
    "\n",
    "        with open(temp_csv) as f_temp:\n",
    "            assert is_equal_stripped_sorted_tables(f_temp.read(), expected_longrel), \"file was not written properly\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
