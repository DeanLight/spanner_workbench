{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Union, Optional, Callable, Type, Iterable, no_type_check, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from lark.lark import Lark\n",
    "from pandas import DataFrame\n",
    "from tabulate import tabulate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installation NLP failed\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from rgxlog.utils import get_base_file_path\n",
    "from rgxlog.engine import SqliteEngine\n",
    "from rgxlog.ast_node_types import AddFact, RelationDeclaration\n",
    "from rgxlog.primitive_types import Span, DataTypes, DataTypeMapping\n",
    "from rgxlog.engine import FALSE_VALUE, TRUE_VALUE\n",
    "from rgxlog.execution import (Query, FREE_VAR_PREFIX, naive_execution)\n",
    "from rgxlog.adding_inference_rules_to_term_graph import AddRulesToTermGraph\n",
    "from rgxlog.optimizations_passes import RemoveUselessRelationsFromRule\n",
    "from rgxlog.lark_passes import (RemoveTokens, FixStrings, CheckReservedRelationNames,\n",
    "                                              ConvertSpanNodesToSpanInstances, ConvertStatementsToStructuredNodes,\n",
    "                                              CheckDefinedReferencedVariables,\n",
    "                                              CheckReferencedRelationsExistenceAndArity,\n",
    "                                              CheckReferencedIERelationsExistenceAndArity, CheckRuleSafety,\n",
    "                                              TypeCheckAssignments, TypeCheckRelations,\n",
    "                                              SaveDeclaredRelationsSchemas, ResolveVariablesReferences,\n",
    "                                              ExecuteAssignments, AddStatementsToNetxParseGraph, GenericPass)\n",
    "from rgxlog.graphs import TermGraph, NetxStateGraph, GraphBase, TermGraphBase\n",
    "from rgxlog.symbol_table import SymbolTable, SymbolTableBase\n",
    "from rgxlog.general_utils import rule_to_relation_name, string_to_span, SPAN_PATTERN, QUERY_RESULT_PREFIX\n",
    "from rgxlog.passes_utils import LarkNode\n",
    "from rgxlog.ie_func.json_path import JsonPath, JsonPathFull\n",
    "from rgxlog.ie_func.nlp import (Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment, TrueCase)\n",
    "from rgxlog.ie_func.python_regex import PYRGX, PYRGX_STRING\n",
    "from rgxlog.ie_func.rust_spanner_regex import RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE\n",
    "from rgxlog.utils import patch_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "CSV_DELIMITER = \";\"\n",
    "\n",
    "# ordered by rgx, json, nlp, etc.\n",
    "PREDEFINED_IE_FUNCS = [PYRGX, PYRGX_STRING, RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE,\n",
    "                       JsonPath, JsonPathFull,\n",
    "                       Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment,\n",
    "                       TrueCase]\n",
    "\n",
    "STRING_PATTERN = re.compile(r\"^[^\\r\\n]+$\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "GRAMMAR_FILE_NAME = 'grammar.lark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _infer_relation_type(row: Iterable # an iterable of values, extracted from a csv file or a dataframe\n",
    "                        ) -> Sequence[DataTypes]: # Inferred tpye list of the given relation\n",
    "    \"\"\"\n",
    "    Guess the relation type based on the data.\n",
    "    We support both the actual types (e.g. 'Span'), and their string representation ( e.g. `\"[0,8)\"`).\n",
    "\n",
    "    **@raise** ValueError: if there is a cell inside `row` of an illegal type.\n",
    "    \"\"\"\n",
    "    relation_types = []\n",
    "    for cell in row:\n",
    "        try:\n",
    "            int(cell)  # check if the cell can be converted to integer\n",
    "            relation_types.append(DataTypes.integer)\n",
    "        except (ValueError, TypeError):\n",
    "            if isinstance(cell, Span) or re.match(SPAN_PATTERN, cell):\n",
    "                relation_types.append(DataTypes.span)\n",
    "            elif re.match(STRING_PATTERN, cell):\n",
    "                relation_types.append(DataTypes.string)\n",
    "            else:\n",
    "                raise ValueError(f\"value doesn't match any datatype: {cell}\")\n",
    "\n",
    "    return relation_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _verify_relation_types(row: Iterable, expected_types: Iterable[DataTypes]) -> None:\n",
    "    if _infer_relation_type(row) != expected_types:\n",
    "        raise Exception(f\"row:\\n{str(row)}\\ndoes not match the relation's types:\\n{str(expected_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _text_to_typed_data(term_list: Sequence[DataTypeMapping.term], relation_types: Sequence[DataTypes]) -> List[DataTypeMapping.term]:\n",
    "    transformed_term_list: List[DataTypeMapping.term] = []\n",
    "    for str_or_object, rel_type in zip(term_list, relation_types):\n",
    "        if rel_type == DataTypes.span:\n",
    "            if isinstance(str_or_object, Span):\n",
    "                transformed_term_list.append(str_or_object)\n",
    "            else:\n",
    "                assert isinstance(str_or_object, str), \"a span can only be a Span object or a string\"\n",
    "                transformed_span = string_to_span(str_or_object)\n",
    "                if transformed_span is None:\n",
    "                    raise TypeError(f\"expected a Span, found this instead: {str_or_object}\")\n",
    "                transformed_term_list.append(transformed_span)\n",
    "\n",
    "        elif rel_type == DataTypes.integer:\n",
    "            if isinstance(str_or_object, Span):\n",
    "                raise TypeError(f\"expected an int, found Span instead: {str_or_object}\")\n",
    "            transformed_term_list.append(int(str_or_object))\n",
    "        else:\n",
    "            assert rel_type == DataTypes.string, f\"illegal type given: {rel_type}\"\n",
    "            transformed_term_list.append(str_or_object)\n",
    "\n",
    "    return transformed_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def format_query_results(query: Query, # the query that was executed, and outputted `query_results`\n",
    "                         query_results: List # the results after executing the aforementioned query\n",
    "                         ) -> Union[DataFrame, List]: # a false value, a true value, or a dataframe representing the query + its results\n",
    "    \"\"\"\n",
    "    Formats a single result from the engine into a usable format.\n",
    "    \"\"\"\n",
    "    assert isinstance(query_results, list), \"illegal results format\"\n",
    "\n",
    "    # check for the special conditions for which we can't print a table: no results were returned or a single\n",
    "    # empty tuple was returned\n",
    "\n",
    "    if query_results == FALSE_VALUE:  # empty list := false\n",
    "        return FALSE_VALUE\n",
    "    elif query_results == TRUE_VALUE:  # single tuple := true\n",
    "        return TRUE_VALUE\n",
    "    else:\n",
    "        # convert the resulting tuples to a more organized format\n",
    "        results_matrix = []\n",
    "        for result in query_results:\n",
    "            # span tuples are converted to Span objects\n",
    "            converted_span_result = [Span(term[0], term[1]) if (isinstance(term, tuple) and len(term) == 2)\n",
    "                                     else term\n",
    "                                     for term in result]\n",
    "\n",
    "            results_matrix.append(converted_span_result)\n",
    "\n",
    "        # get the free variables of the query, they will be used as headers\n",
    "        query_free_vars = [term for term, term_type in zip(query.term_list, query.type_list)\n",
    "                           if term_type is DataTypes.free_var_name]\n",
    "\n",
    "        return DataFrame(data=results_matrix, columns=query_free_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tabulate_result(result: Union[DataFrame, List] # the query result (free variable names are the dataframe's column names)\n",
    "                    ) -> str: # a tabulated string\n",
    "    \"\"\"\n",
    "    Organizes a query result in a table <br>\n",
    "    for example: <br>\n",
    "    ```prolog\n",
    "    {QUERY_RESULT_PREFIX}'lecturer_of(X, \"abigail\")':\n",
    "       X\n",
    "    -------\n",
    "     linus\n",
    "     walter\n",
    "    ```\n",
    "    There are two cases in which a table won't be printed:\n",
    "\n",
    "    1. **Query returned no results**: This will result in an output of `[]`.\n",
    "\n",
    "    2. **Query returned a single empty tuple**: The output will be `[()]`.\n",
    "    \"\"\"\n",
    "    if isinstance(result, DataFrame):\n",
    "        # query results can be printed as a table\n",
    "        result_string = tabulate(result, headers=\"keys\", tablefmt=\"presto\", stralign=\"center\", showindex=False)\n",
    "    else:\n",
    "        assert isinstance(result, list), \"illegal result format\"\n",
    "        if len(result) == 0:\n",
    "            result_string = \"[]\"\n",
    "        else:\n",
    "            assert len(result) == 1, \"illegal result format\"\n",
    "            result_string = \"[()]\"\n",
    "\n",
    "    return result_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def queries_to_string(query_results: List[Tuple[Query, List]] # List[the Query object used in execution, the execution's results (from engine)]\n",
    "                      ) -> str: # a tabulated string\n",
    "    \"\"\"\n",
    "    Takes in a list of results from the engine and converts them into a single string, which contains\n",
    "    either a table, a false value (=`[]`), or a true value (=`[tuple()]`), for each result.\n",
    "\n",
    "    for example:\n",
    "\n",
    "    ```prolog\n",
    "    {QUERY_RESULT_PREFIX}'lecturer_of(X, \"abigail\")':\n",
    "       X\n",
    "    -------\n",
    "     linus\n",
    "     walter\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    all_result_strings = []\n",
    "    query_results = list(filter(None, query_results))  # remove Nones\n",
    "    for query, results in query_results:\n",
    "        query_result_string = tabulate_result(format_query_results(query, results))\n",
    "        query_title = f\"{QUERY_RESULT_PREFIX}'{query}':\"\n",
    "\n",
    "        # combine the title and table to a single string and save it to the prints buffer\n",
    "        titled_result_string = f'{query_title}\\n{query_result_string}\\n'\n",
    "        all_result_strings.append(titled_result_string)\n",
    "    return \"\\n\".join(all_result_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Session:\n",
    "    def __init__(self, \n",
    "                 symbol_table: Optional[SymbolTableBase] = None, # symbol table to help with all semantic checks\n",
    "                 parse_graph: Optional[GraphBase] = None, # an AST that contains nodes which represent commands\n",
    "                 term_graph: Optional[TermGraphBase] = None): # a graph that holds all the connection between the relations\n",
    "        \"\"\"\n",
    "        A class that serves as the central connection point between various modules in the system.\n",
    "\n",
    "        This class takes input data and coordinates communication between different modules by sending the relevant parts\n",
    "        of the input to each module. It also orchestrates the execution of micro passes and handles engine-related tasks. <br>\n",
    "        Finally, it formats the results before presenting them to the user.\n",
    "\n",
    "        \"\"\"\n",
    "        if symbol_table is None:\n",
    "            self._symbol_table: SymbolTableBase = SymbolTable()\n",
    "            self._symbol_table.register_predefined_ie_functions(PREDEFINED_IE_FUNCS)\n",
    "\n",
    "        else:\n",
    "            self._symbol_table = symbol_table\n",
    "\n",
    "        self._parse_graph = NetxStateGraph() if parse_graph is None else parse_graph\n",
    "        self._term_graph: TermGraphBase = TermGraph() if term_graph is None else term_graph\n",
    "        self._engine = SqliteEngine()\n",
    "        self._execution = naive_execution\n",
    "\n",
    "        self._pass_stack: List[Type[GenericPass]] = [\n",
    "            RemoveTokens,\n",
    "            FixStrings,\n",
    "            CheckReservedRelationNames,\n",
    "            ConvertSpanNodesToSpanInstances,\n",
    "            ConvertStatementsToStructuredNodes,\n",
    "            CheckDefinedReferencedVariables,\n",
    "            CheckReferencedRelationsExistenceAndArity,\n",
    "            CheckReferencedIERelationsExistenceAndArity,\n",
    "            CheckRuleSafety,\n",
    "            TypeCheckAssignments,\n",
    "            TypeCheckRelations,\n",
    "            SaveDeclaredRelationsSchemas,\n",
    "            ResolveVariablesReferences,\n",
    "            ExecuteAssignments,\n",
    "            AddStatementsToNetxParseGraph,\n",
    "            AddRulesToTermGraph\n",
    "        ]\n",
    "\n",
    "        self._grammar = Session._get_grammar_from_file()\n",
    "\n",
    "        self._parser = Lark(self._grammar, parser='lalr')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_grammar_from_file() -> str:\n",
    "        \"\"\"\n",
    "        @return: Grammar from grammar file in string format.\n",
    "        \"\"\"\n",
    "\n",
    "        # Make the grammar_file_path generic no matter if running from notebook or from exported python file\n",
    "        current_dir = get_base_file_path(Path.cwd())\n",
    "\n",
    "        grammar_file_path = current_dir / 'rgxlog'\n",
    "        with open(grammar_file_path / GRAMMAR_FILE_NAME, 'r') as grammar_file:\n",
    "            return grammar_file.read()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"\\n\".join([repr(self._symbol_table), repr(self._parse_graph)])\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f'Symbol Table:\\n{str(self._symbol_table)}\\n\\nTerm Graph:\\n{str(self._parse_graph)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _run_passes(self: Session, lark_tree: LarkNode, pass_list: list) -> None:\n",
    "    \"\"\"\n",
    "    Runs the passes in pass_list on tree, one after another.\n",
    "    \"\"\"\n",
    "    #logger.debug(f\"initial lark tree:\\n{lark_tree.pretty()}\")\n",
    "    #logger.debug(f\"initial term graph:\\n{self._term_graph}\")\n",
    "\n",
    "    for curr_pass in pass_list:\n",
    "        curr_pass_object = curr_pass(parse_graph=self._parse_graph,\n",
    "                                        symbol_table=self._symbol_table,\n",
    "                                        term_graph=self._term_graph)\n",
    "        new_tree = curr_pass_object.run_pass(tree=lark_tree)\n",
    "        if new_tree is not None:\n",
    "            lark_tree = new_tree\n",
    "            #logger.debug(f\"lark tree after {curr_pass.__name__}:\\n{lark_tree.pretty()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def get_pass_stack(self: Session) -> List[Type[GenericPass]]:\n",
    "    \"\"\"\n",
    "    @return: the current pass stack.\n",
    "    \"\"\"\n",
    "\n",
    "    return self._pass_stack.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.get_pass_stack\n",
       "\n",
       ">      Session.get_pass_stack ()\n",
       "\n",
       "@return: the current pass stack."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.get_pass_stack\n",
       "\n",
       ">      Session.get_pass_stack ()\n",
       "\n",
       "@return: the current pass stack."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.get_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def set_pass_stack(self: Session, user_stack: List[Type[GenericPass]] #  a user supplied pass stack\n",
    "                    ) -> List[Type[GenericPass]]: # success message with the new pass stack\n",
    "    \"\"\"\n",
    "    Sets a new pass stack instead of the current one.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(user_stack) is not list:\n",
    "        raise TypeError('user stack should be a list of passes')\n",
    "    for pass_ in user_stack:\n",
    "        if not issubclass(pass_, GenericPass):\n",
    "            raise TypeError('user stack should be a subclass of `GenericPass`')\n",
    "\n",
    "    self._pass_stack = user_stack.copy()\n",
    "    return self.get_pass_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.set_pass_stack\n",
       "\n",
       ">      Session.set_pass_stack\n",
       ">                              (user_stack:List[Type[rgxlog.lark_passes.GenericP\n",
       ">                              ass]])\n",
       "\n",
       "Sets a new pass stack instead of the current one.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| user_stack | List[Type[GenericPass]] | a user supplied pass stack |\n",
       "| **Returns** | **List[Type[GenericPass]]** | **success message with the new pass stack** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.set_pass_stack\n",
       "\n",
       ">      Session.set_pass_stack\n",
       ">                              (user_stack:List[Type[rgxlog.lark_passes.GenericP\n",
       ">                              ass]])\n",
       "\n",
       "Sets a new pass stack instead of the current one.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| user_stack | List[Type[GenericPass]] | a user supplied pass stack |\n",
       "| **Returns** | **List[Type[GenericPass]]** | **success message with the new pass stack** |"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.set_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_all_rules(self: Session, head: Optional[str] = None # if specified it will print only rules with the given head relation name\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Prints all the rules that are registered.\n",
    "    \"\"\"\n",
    "\n",
    "    self._term_graph.print_all_rules(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _remove_rule_relation_from_symbols_and_engine(self: Session, relation_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Removes the relation from the symbol table and the execution tables.\n",
    "\n",
    "    @param relation_name: the name of the relation ot remove.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_rule_relation(relation_name)\n",
    "    self._engine.remove_table(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _add_imported_relation_to_engine(self: Session, relation_table: Iterable, relation_name: str, relation_types: Sequence[DataTypes]) -> None:\n",
    "    symbol_table = self._symbol_table\n",
    "    engine = self._engine\n",
    "    # first make sure the types are legal, then we add them to the engine (to make sure\n",
    "    #  we don't add them in case of an error)\n",
    "    facts = []\n",
    "\n",
    "    for row in relation_table:\n",
    "        _verify_relation_types(row, relation_types)\n",
    "        typed_line = _text_to_typed_data(row, relation_types)\n",
    "        facts.append(AddFact(relation_name, typed_line, relation_types))\n",
    "\n",
    "    # declare relation if it does not exist\n",
    "    if not symbol_table.contains_relation(relation_name):\n",
    "        engine.declare_relation_table(RelationDeclaration(relation_name, relation_types))\n",
    "        symbol_table.add_relation_schema(relation_name, relation_types, False)\n",
    "\n",
    "    for fact in facts:\n",
    "        engine.add_fact(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def import_relation_from_df(self: Session, relation_df: DataFrame, #The DataFrame containing the data to be imported\n",
    "                            relation_name: str #The name to be assigned to the relation. It can be an existing relation or a new one\n",
    "                            ) -> None:\n",
    "    data = relation_df.values.tolist()\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        raise Exception(\"dataframe could not be converted to list\")\n",
    "\n",
    "    if len(data) < 1:\n",
    "        raise Exception(\"dataframe is empty\")\n",
    "\n",
    "    relation_types = _infer_relation_type(data[0])\n",
    "\n",
    "    self._add_imported_relation_to_engine(data, relation_name, relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def send_commands_result_into_df(self: Session, commands: str # the commands to run\n",
    "                                    ) -> Union[DataFrame, List]: # formatted results (possibly a dataframe)\n",
    "    \"\"\"\n",
    "    run commands as usual and output their formatted results into a dataframe (the commands should contain a query)\n",
    "    \"\"\"\n",
    "    commands_results = self.run_commands(commands, print_results=False)\n",
    "    if len(commands_results) != 1:\n",
    "        raise Exception(\"the commands must have exactly one output\")\n",
    "\n",
    "    return format_query_results(*commands_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _relation_name_to_query(self: Session, relation_name: str) -> str:\n",
    "    symbol_table = self._symbol_table\n",
    "    relation_schema = symbol_table.get_relation_schema(relation_name)\n",
    "    relation_arity = len(relation_schema)\n",
    "    query = (f\"?{relation_name}(\" + \", \".join(f\"{FREE_VAR_PREFIX}{i}\" for i in range(relation_arity)) + \")\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def export_relation_into_df(self: Session, relation_name: str) -> Union[DataFrame, List]:\n",
    "    query = self._relation_name_to_query(relation_name)\n",
    "    return self.send_commands_result_into_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def export_relation_into_csv(self: Session, csv_file_name: Path, relation_name: str, delimiter: str = CSV_DELIMITER) -> None:\n",
    "    query = self._relation_name_to_query(relation_name)\n",
    "    self.send_commands_result_into_csv(query, csv_file_name, delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def run_commands(self: Session, query: str, # The user's input\n",
    "                    print_results: bool = True, # whether to print the results to stdout or not\n",
    "                    format_results: bool = False # if this is true, return the formatted result instead of the `[Query, List]` pair\n",
    "                    ) -> (Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]): # the results of every query, in a list\n",
    "    \"\"\"\n",
    "    Generates an AST and passes it through the pass stack.\n",
    "    \"\"\"\n",
    "    query_results = []\n",
    "    parse_tree = self._parser.parse(query)\n",
    "    for statement in parse_tree.children:\n",
    "        self._run_passes(statement, self._pass_stack)\n",
    "        query_result = self._execution(parse_graph=self._parse_graph,\n",
    "                                        symbol_table=self._symbol_table,\n",
    "                                        rgxlog_engine=self._engine,\n",
    "                                        term_graph=self._term_graph)\n",
    "        if query_result is not None:\n",
    "            query_results.append(query_result)\n",
    "            if print_results:\n",
    "                print(queries_to_string([query_result]))\n",
    "\n",
    "    if format_results:\n",
    "        return [format_query_results(*query_result) for query_result in query_results]\n",
    "    else:\n",
    "        return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.run_commands\n",
       "\n",
       ">      Session.run_commands (query:str, print_results:bool=True,\n",
       ">                            format_results:bool=False)\n",
       "\n",
       "Generates an AST and passes it through the pass stack.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | The user's input |\n",
       "| print_results | bool | True | whether to print the results to stdout or not |\n",
       "| format_results | bool | False | if this is true, return the formatted result instead of the `[Query, List]` pair |\n",
       "| **Returns** | **Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]** |  | **the results of every query, in a list** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.run_commands\n",
       "\n",
       ">      Session.run_commands (query:str, print_results:bool=True,\n",
       ">                            format_results:bool=False)\n",
       "\n",
       "Generates an AST and passes it through the pass stack.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | The user's input |\n",
       "| print_results | bool | True | whether to print the results to stdout or not |\n",
       "| format_results | bool | False | if this is true, return the formatted result instead of the `[Query, List]` pair |\n",
       "| **Returns** | **Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]** |  | **the results of every query, in a list** |"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.run_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'GrandParent(X, \"Austin\")':\n",
      "  X\n",
      "-----\n",
      " Sam\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "    ?GrandParent(X, \"Austin\")\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def register(self: Session, ie_function: Callable, ie_function_name: str, in_rel: List[DataTypes],\n",
    "            out_rel: Union[List[DataTypes], Callable[[int], Sequence[DataTypes]]]) -> None:\n",
    "    \"\"\"\n",
    "    Registers an ie function.\n",
    "\n",
    "    @see params in `IEFunction`'s __init__.\n",
    "    \"\"\"\n",
    "    self._symbol_table.register_ie_function(ie_function, ie_function_name, in_rel, out_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.register\n",
       "\n",
       ">      Session.register (ie_function:Callable, ie_function_name:str,\n",
       ">                        in_rel:List[rgxlog.primitive_types.DataTypes], out_rel:\n",
       ">                        Union[List[rgxlog.primitive_types.DataTypes],Callable[[\n",
       ">                        int],Sequence[rgxlog.primitive_types.DataTypes]]])\n",
       "\n",
       "Registers an ie function.\n",
       "\n",
       "@see params in `IEFunction`'s __init__."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.register\n",
       "\n",
       ">      Session.register (ie_function:Callable, ie_function_name:str,\n",
       ">                        in_rel:List[rgxlog.primitive_types.DataTypes], out_rel:\n",
       ">                        Union[List[rgxlog.primitive_types.DataTypes],Callable[[\n",
       ">                        int],Sequence[rgxlog.primitive_types.DataTypes]]])\n",
       "\n",
       "Registers an ie function.\n",
       "\n",
       "@see params in `IEFunction`'s __init__."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'string_length(Str, Len)':\n",
      "  Str  |   Len\n",
      "-------+-------\n",
      "   a   |     1\n",
      "   d   |     1\n",
      "  ab   |     2\n",
      "  abc  |     3\n",
      " abcd  |     4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def length(string: str) -> Iterable[int]:\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield len(string)\n",
    "\n",
    "length_dict = dict(ie_function=length,\n",
    "                ie_function_name='Length',\n",
    "                in_rel=[DataTypes.string],\n",
    "                out_rel=[DataTypes.integer])\n",
    "\n",
    "session = Session()\n",
    "session.register(**length_dict)\n",
    "commands = \"\"\"new string(str)\n",
    "            string(\"a\")\n",
    "            string(\"d\")\n",
    "            string(\"a\")\n",
    "            string(\"ab\")\n",
    "            string(\"abc\")\n",
    "            string(\"abcd\")\n",
    "\n",
    "            string_length(Str, Len) <- string(Str), Length(Str) -> (Len)\n",
    "            ?string_length(Str, Len)\n",
    "            \"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(Session.get_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(Session.set_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_rule(self: Session, rule: str # The rule to be removed\n",
    "                ) -> None:\n",
    "    \"\"\"\n",
    "    Remove a rule from the rgxlog's engine.\n",
    "    \"\"\"\n",
    "    is_last = self._term_graph.remove_rule(rule)\n",
    "    if is_last:\n",
    "        relation_name = rule_to_relation_name(rule)\n",
    "        self._remove_rule_relation_from_symbols_and_engine(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_rule\n",
       "\n",
       ">      Session.remove_rule (rule:str)\n",
       "\n",
       "Remove a rule from the rgxlog's engine.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| rule | str | The rule to be removed |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_rule\n",
       "\n",
       ">      Session.remove_rule (rule:str)\n",
       "\n",
       "Remove a rule from the rgxlog's engine.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| rule | str | The rule to be removed |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    parent(\"James\", \"Lucas\")\n",
    "    parent(\"Noah\", \"Benjamin\")\n",
    "    parent(\"Benjamin\", \"Mason\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing first rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t2. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "session.remove_rule(\"ancestor(X, Y) <- parent(X, Y)\")\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_all_rules(self: Session, rule_head: Optional[str] = None # if rule head is not none we remove all rules with rule_head\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Removes all rules from the engine.\n",
    "    \"\"\"\n",
    "\n",
    "    if rule_head is None:\n",
    "        self._term_graph = TermGraph()\n",
    "        relations_names = self._symbol_table.remove_all_rule_relations()\n",
    "        self._engine.remove_tables(relations_names)\n",
    "    else:\n",
    "        self._term_graph.remove_rules_with_head(rule_head)\n",
    "        self._remove_rule_relation_from_symbols_and_engine(rule_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_all_rules\n",
       "\n",
       ">      Session.remove_all_rules (rule_head:Union[str,NoneType]=None)\n",
       "\n",
       "Removes all rules from the engine.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| rule_head | Optional[str] | None | if rule head is not none we remove all rules with rule_head |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_all_rules\n",
       "\n",
       ">      Session.remove_all_rules (rule_head:Union[str,NoneType]=None)\n",
       "\n",
       "Removes all rules from the engine.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| rule_head | Optional[str] | None | if rule head is not none we remove all rules with rule_head |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_all_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing all rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n"
     ]
    }
   ],
   "source": [
    "session.remove_all_rules()\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def clear_relation(self: Session, relation_name: str # The name of the relation to clear\n",
    "                    ) -> None:\n",
    "    # @raises: Exception if relation does not exist\n",
    "    if not self._engine.is_table_exists(relation_name):\n",
    "        raise Exception(f\"Relation {relation_name} does not exist\")\n",
    "\n",
    "    self._engine.clear_relation(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.clear_relation\n",
       "\n",
       ">      Session.clear_relation (relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_name | str | The name of the relation to clear |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.clear_relation\n",
       "\n",
       ">      Session.clear_relation (relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_name | str | The name of the relation to clear |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.clear_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'parent(X, Y)':\n",
      "  X   |   Y\n",
      "------+--------\n",
      " Liam |  Noah\n",
      " Noah | Oliver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    ?parent(X,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after clearing parent relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'parent(X, Y)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.clear_relation(\"parent\")\n",
    "commands = \"\"\"\n",
    "    ?parent(X,Y)\n",
    "    \"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def send_commands_result_into_csv(self: Session, commands: str, # the commands to run\n",
    "                                    csv_file_name: Path, # the file into which the output will be written\n",
    "                                    delimiter: str = CSV_DELIMITER # a csv separator between values\n",
    "                                    ) -> None:\n",
    "    \"\"\"\n",
    "    run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
    "    \"\"\"\n",
    "    commands_results = self.run_commands(commands, print_results=False)\n",
    "    if len(commands_results) != 1:\n",
    "        raise Exception(\"the commands must have exactly one output\")\n",
    "\n",
    "    formatted_result = format_query_results(*commands_results[0])\n",
    "\n",
    "    if isinstance(formatted_result, DataFrame):\n",
    "        formatted_result.to_csv(csv_file_name, index=False, sep=delimiter)\n",
    "    else:\n",
    "        # true or false\n",
    "        with open(csv_file_name, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f, delimiter=delimiter)\n",
    "            writer.writerows(formatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.send_commands_result_into_csv\n",
       "\n",
       ">      Session.send_commands_result_into_csv (commands:str,\n",
       ">                                             csv_file_name:pathlib.Path,\n",
       ">                                             delimiter:str=';')\n",
       "\n",
       "run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| commands | str |  | the commands to run |\n",
       "| csv_file_name | Path |  | the file into which the output will be written |\n",
       "| delimiter | str | ; | a csv separator between values |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.send_commands_result_into_csv\n",
       "\n",
       ">      Session.send_commands_result_into_csv (commands:str,\n",
       ">                                             csv_file_name:pathlib.Path,\n",
       ">                                             delimiter:str=';')\n",
       "\n",
       "run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| commands | str |  | the commands to run |\n",
       "| csv_file_name | Path |  | the file into which the output will be written |\n",
       "| delimiter | str | ; | a csv separator between values |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.send_commands_result_into_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_registered_ie_functions(self: Session) -> None:\n",
    "    \"\"\"\n",
    "    Prints information about the registered ie functions.\n",
    "    \"\"\"\n",
    "    self._symbol_table.print_registered_ie_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.print_registered_ie_functions\n",
       "\n",
       ">      Session.print_registered_ie_functions ()\n",
       "\n",
       "Prints information about the registered ie functions."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.print_registered_ie_functions\n",
       "\n",
       ">      Session.print_registered_ie_functions ()\n",
       "\n",
       "Prints information about the registered ie functions."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.print_registered_ie_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_ie_function(self: Session, name: str # the name of the ie function to remove\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Removes a function from the symbol table.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_ie_function(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_ie_function\n",
       "\n",
       ">      Session.remove_ie_function (name:str)\n",
       "\n",
       "Removes a function from the symbol table.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| name | str | the name of the ie function to remove |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_ie_function\n",
       "\n",
       ">      Session.remove_ie_function (name:str)\n",
       "\n",
       "Removes a function from the symbol table.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| name | str | the name of the ie function to remove |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_ie_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_all_ie_functions(self: Session) -> None:\n",
    "    \"\"\"\n",
    "    Removes all the ie functions from the symbol table.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_all_ie_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_all_ie_functions\n",
       "\n",
       ">      Session.remove_all_ie_functions ()\n",
       "\n",
       "Removes all the ie functions from the symbol table."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_all_ie_functions\n",
       "\n",
       ">      Session.remove_all_ie_functions ()\n",
       "\n",
       "Removes all the ie functions from the symbol table."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_all_ie_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_all_rules(self: Session, head: Optional[str] = None # if specified it will print only rules with the given head relation name\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Prints all the rules that are registered.\n",
    "    \"\"\"\n",
    "\n",
    "    self._term_graph.print_all_rules(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.print_all_rules\n",
       "\n",
       ">      Session.print_all_rules (head:Union[str,NoneType]=None)\n",
       "\n",
       "Prints all the rules that are registered.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| head | Optional[str] | None | if specified it will print only rules with the given head relation name |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.print_all_rules\n",
       "\n",
       ">      Session.print_all_rules (head:Union[str,NoneType]=None)\n",
       "\n",
       "Prints all the rules that are registered.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| head | Optional[str] | None | if specified it will print only rules with the given head relation name |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.print_all_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def import_relation_from_csv(self: Session, csv_file_name: Path, #The path to the CSV file that is being imported\n",
    "                             relation_name: str = None, #The name of the relation. If not provided, it will be derived from the CSV file name\n",
    "                             delimiter: str = CSV_DELIMITER #The delimiter used in the CSV file\n",
    "                             )-> None: \n",
    "    if not Path(csv_file_name).is_file():\n",
    "        raise IOError(\"csv file does not exist\")\n",
    "\n",
    "    if os.stat(csv_file_name).st_size == 0:\n",
    "        raise IOError(\"csv file is empty\")\n",
    "\n",
    "    # the relation_name is either an argument or the file's name\n",
    "    if relation_name is None:\n",
    "        relation_name = Path(csv_file_name).stem\n",
    "\n",
    "    with open(csv_file_name) as fh:\n",
    "        reader = csv.reader(fh, delimiter=delimiter)\n",
    "\n",
    "        # read first line and go back to start of file - make sure there is no empty line!\n",
    "        relation_types = _infer_relation_type(next(reader))\n",
    "        fh.seek(0)\n",
    "\n",
    "        self._add_imported_relation_to_engine(reader, relation_name, relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.import_relation_from_csv\n",
       "\n",
       ">      Session.import_relation_from_csv (csv_file_name:pathlib.Path,\n",
       ">                                        relation_name:str=None,\n",
       ">                                        delimiter:str=';')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_file_name | Path |  | The path to the CSV file that is being imported |\n",
       "| relation_name | str | None | The name of the relation. If not provided, it will be derived from the CSV file name |\n",
       "| delimiter | str | ; | The delimiter used in the CSV file |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.import_relation_from_csv\n",
       "\n",
       ">      Session.import_relation_from_csv (csv_file_name:pathlib.Path,\n",
       ">                                        relation_name:str=None,\n",
       ">                                        delimiter:str=';')\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| csv_file_name | Path |  | The path to the CSV file that is being imported |\n",
       "| relation_name | str | None | The name of the relation. If not provided, it will be derived from the CSV file name |\n",
       "| delimiter | str | ; | The delimiter used in the CSV file |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.import_relation_from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa(X, Y)':\n",
      "    X    |   Y\n",
      "---------+-----\n",
      " abigail | 100\n",
      " jordan  |  80\n",
      "  gale   |  79\n",
      " howard  |  60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "session.import_relation_from_csv(\"enrolled.csv\", relation_name=\"enrolled\", delimiter=\",\")\n",
    "commands = \"\"\"\n",
    "    enrolled(\"abigail\", \"chemistry\")\n",
    "gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"\n",
    "\n",
    "gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "?gpa(X,Y)\n",
    "\"\"\"\n",
    "x = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def import_relation_from_df(self: Session, relation_df: DataFrame, #The DataFrame containing the data to be imported\n",
    "                            relation_name: str #The name to be assigned to the relation. It can be an existing relation or a new one\n",
    "                            ) -> None:\n",
    "    data = relation_df.values.tolist()\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        raise Exception(\"dataframe could not be converted to list\")\n",
    "\n",
    "    if len(data) < 1:\n",
    "        raise Exception(\"dataframe is empty\")\n",
    "\n",
    "    relation_types = _infer_relation_type(data[0])\n",
    "\n",
    "    self._add_imported_relation_to_engine(data, relation_name, relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.import_relation_from_df\n",
       "\n",
       ">      Session.import_relation_from_df (relation_df:pandas.core.frame.DataFrame,\n",
       ">                                       relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_df | DataFrame | The DataFrame containing the data to be imported |\n",
       "| relation_name | str | The name to be assigned to the relation. It can be an existing relation or a new one |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.import_relation_from_df\n",
       "\n",
       ">      Session.import_relation_from_df (relation_df:pandas.core.frame.DataFrame,\n",
       ">                                       relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_df | DataFrame | The DataFrame containing the data to be imported |\n",
       "| relation_name | str | The name to be assigned to the relation. It can be an existing relation or a new one |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.import_relation_from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'lecturer(X, Y)':\n",
      "   X    |         Y\n",
      "--------+-------------------\n",
      " walter |     chemistry\n",
      " linus  | operating_systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "lecturer_df = DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "session.import_relation_from_df(lecturer_df, relation_name=\"lecturer\")\n",
    "commands = \"\"\" \n",
    "?lecturer(X,Y)\n",
    "\"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'parent(X, Y)':\n",
      "    X    |    Y\n",
      "---------+---------\n",
      "  Jack   |  Alex\n",
      " Michael | Jackson\n",
      "   Van   | Diesel\n",
      "\n",
      "printing results for query 'parent(X, Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'parent(X, Y)':\n",
      "  X   |  Y\n",
      "------+------\n",
      " John | Cena\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if __name__ == \"__main__\":\n",
    "    my_session = Session()\n",
    "    my_session.run_commands(\"\"\"\n",
    "                        new parent(str,str)\n",
    "                        parent(\"Jack\", \"Alex\")\n",
    "                        parent(\"Michael\", \"Jackson\")\n",
    "                        parent(\"Van\", \"Diesel\")\n",
    "                        ?parent(X,Y)\n",
    "            \"\"\")\n",
    "    my_session.clear_relation(\"parent\")\n",
    "    output = my_session.run_commands(\"\"\"\n",
    "                # Expect to see empty relation\n",
    "                ?parent(X,Y)\n",
    "            \"\"\")\n",
    "    assert str(output) == \"[(parent(X, Y), [])]\"\n",
    "    output = my_session.run_commands(\"\"\"\n",
    "                        # Check smooth refilling\n",
    "                        parent(\"John\", \"Cena\")\n",
    "                        ?parent(X,Y)\n",
    "                    \"\"\")\n",
    "    assert str(output) == \"[(parent(X, Y), [('John', 'Cena')])]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
