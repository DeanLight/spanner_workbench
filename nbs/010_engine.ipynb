{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine\n",
    "> Execution spannerlog commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import pytest\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import no_type_check, Set, Sequence, Any,Optional,List,Callable,Dict,Union\n",
    "from pydantic import BaseModel\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from graph_rewrite import draw, draw_match, rewrite, rewrite_iter\n",
    "from spannerlib.utils import serialize_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils TODO move to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _biggest_int_node_name(g:nx.Graph):\n",
    "    return max([n for n in g.nodes if isinstance(n,int)],default=0)\n",
    "\n",
    "def is_node_in_graphs(name,gs):\n",
    "    return any(name in g.nodes for g in gs)\n",
    "\n",
    "def get_new_node_name(g,prefix=None,avoid_names_from=None):\n",
    "    if avoid_names_from is None:\n",
    "        avoid_names_from = []\n",
    "    graphs_to_avoid = [g]+avoid_names_from\n",
    "    # ints\n",
    "    if prefix is None:\n",
    "        max_int = _biggest_int_node_name(g)+1\n",
    "        while is_node_in_graphs(max_int,graphs_to_avoid):\n",
    "            max_int+=1\n",
    "        return max_int\n",
    "    # strings\n",
    "    else: \n",
    "        if not is_node_in_graphs(prefix,graphs_to_avoid):\n",
    "            return prefix\n",
    "        for i in itertools.count():\n",
    "            name = f\"{prefix}_{i}\"\n",
    "            if not is_node_in_graphs(name,graphs_to_avoid):\n",
    "                return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_node(1)\n",
    "g.add_node(2)\n",
    "g.add_node('hello')\n",
    "\n",
    "g2 = nx.Graph()\n",
    "g2.add_node(1)\n",
    "g2.add_node(2)\n",
    "g2.add_node(3)\n",
    "g2.add_node('hello_1')\n",
    "\n",
    "assert _biggest_int_node_name(g) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_node_in_graphs(3,[g,g2])\n",
    "assert not is_node_in_graphs(4,[g,g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_new_node_name(g) == 3\n",
    "assert get_new_node_name(g,'hello') == 'hello_0'\n",
    "g.add_node('hello_0')\n",
    "assert get_new_node_name(g,'hello') == 'hello_1'\n",
    "assert get_new_node_name(g,'hello',avoid_names_from=[g2]) == 'hello_2'\n",
    "assert get_new_node_name(g,'world') == 'world'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "from pydantic import ConfigDict\n",
    "\n",
    "class Span(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "    def __lt__(self, other) -> bool:\n",
    "        if self.start == other.start:\n",
    "            return self.end < other.end\n",
    "\n",
    "        return self.start < other.start\n",
    "\n",
    "    # # used for sorting `Span`s in dataframes\n",
    "    # def __hash__(self) -> int:\n",
    "    #     return hash((self.start, self.end))\n",
    "\n",
    "class Var(BaseModel):\n",
    "    name: str\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "class FreeVar(BaseModel):\n",
    "    name: str\n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "PrimitiveType=Union[str,int,Span]\n",
    "Type = Union[PrimitiveType,Var,FreeVar]\n",
    "\n",
    "class RelationDefinition(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    scheme: List[type]\n",
    "\n",
    "class Relation(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    terms: List[Type]\n",
    "\n",
    "class IEFunction(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    in_schema: List[type]\n",
    "    out_schema: List[type]\n",
    "    func: Callable\n",
    "\n",
    "\n",
    "class IERelation(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    name: str\n",
    "    in_terms: List[Type]\n",
    "    out_terms: List[Type]\n",
    "    def __hash__(self):\n",
    "        hash_str = f'''{self.name}_in_{'_'.join([str(x) for x in self.in_terms])}_out_{'_'.join([str(x) for x in self.out_terms])}'''\n",
    "        return hash(hash_str)\n",
    "class Rule(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    head: Relation\n",
    "    body: List[Union[Relation,IERelation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pretty(obj):\n",
    "    \"\"\"pretty printing dataclasses for user messages,\n",
    "    making them look like spannerlog code instead of python code\"\"\"\n",
    "    \n",
    "    if isinstance(obj,Span):\n",
    "        return f\"[{obj.start},{obj.end})\"\n",
    "    elif isinstance(obj,(Var,FreeVar)):\n",
    "        return obj.name\n",
    "    elif isinstance(obj,RelationDefinition):\n",
    "        return f\"{obj.name}({','.join(pretty(o) for o in obj.scheme)})\"\n",
    "    elif isinstance(obj,Relation):\n",
    "        return f\"{obj.name}({','.join(pretty(o) for o in obj.terms)})\"\n",
    "    elif isinstance(obj,IERelation):\n",
    "        return f\"{obj.name}({','.join(pretty(o) for o in obj.in_terms)}) -> ({','.join(pretty(o) for o in obj.out_terms)})\"\n",
    "    elif isinstance(obj,IEFunction):\n",
    "        return f\"{obj.name}({','.join(pretty(o) for o in obj.in_schema)}) -> ({','.join(pretty(o) for o in obj.out_schema)})\"\n",
    "    elif isinstance(obj,Rule):\n",
    "        return f\"{pretty(obj.head)} <- {','.join(pretty(o) for o in obj.body)}\"\n",
    "    elif isinstance(obj,type):\n",
    "        return obj.__name__\n",
    "    else:\n",
    "        return str(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "    body=[\n",
    "        Relation(name='S', terms=[FreeVar(name='X'), Span(start=1,end=4)]),\n",
    "        IERelation(name='T', in_terms=[FreeVar(name='X'), 1], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')])\n",
    "    ])\n",
    "assert pretty(rule) == 'R(X,Y,Z) <- S(X,[1,4)),T(X,1) -> (Y,Z)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = RelationDefinition(name='R', scheme=[int, str, Span])\n",
    "assert pretty(schema) == 'R(int,str,Span)'\n",
    "ie_func_schema = IEFunction(name='f', in_schema=[int, str], out_schema=[str, Span],func=lambda x,y: (y,Span(1,2)))\n",
    "assert pretty(ie_func_schema) == 'f(int,str) -> (str,Span)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have functions for manipulating rules into term graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_bounding_order(rule:Rule)->List[Union[Relation,IERelation]]:\n",
    "    \"\"\"Get an order of evaluation for the body of a rule\n",
    "    this is a very naive ordering that can be heavily optimized\"\"\"\n",
    "\n",
    "    # we start with all relations since they can be bound at once\n",
    "    order = list()\n",
    "    bounded_vars = set()\n",
    "    for rel in rule.body:\n",
    "        if isinstance(rel,Relation):\n",
    "            order.append(rel)\n",
    "            for term in rel.terms:\n",
    "                if isinstance(term,FreeVar):\n",
    "                    bounded_vars.add(term)\n",
    "\n",
    "    unordered_ierelations = {rel for rel in rule.body if isinstance(rel,IERelation)}\n",
    "    while len(unordered_ierelations) > 0:\n",
    "        for ie_rel in unordered_ierelations:\n",
    "            in_free_vars = {term for term in ie_rel.in_terms if isinstance(term,FreeVar)}\n",
    "            if in_free_vars.issubset(bounded_vars):\n",
    "                order.append(ie_rel)\n",
    "                out_free_vars = {term for term in ie_rel.out_terms if isinstance(term,FreeVar)}\n",
    "                bounded_vars = bounded_vars.union(out_free_vars)\n",
    "                unordered_ierelations.remove(ie_rel)\n",
    "                break\n",
    "\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relation(name='S', terms=[FreeVar(name='X'), Span(start=1, end=4)]),\n",
       " Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'), FreeVar(name='B')]),\n",
       " IERelation(name='T', in_terms=[FreeVar(name='X'), 1], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')]),\n",
       " IERelation(name='T2', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='W'), FreeVar(name='Z')])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "    body=[\n",
    "        IERelation(name='T2', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='W'), FreeVar(name='Z')]),\n",
    "        IERelation(name='T', in_terms=[FreeVar(name='X'), 1], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "        Relation(name='S', terms=[FreeVar(name='X'), Span(start=1,end=4)]),\n",
    "        Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'),FreeVar(name='B')]),\n",
    "\n",
    "    ])\n",
    "\n",
    "order = _get_bounding_order(r)\n",
    "assert [o.name for o in order ] == ['S','S2', 'T', 'T2']\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _name_node(counter,op,rule_id,rel_idx,rel_name):\n",
    "    return next(counter)\n",
    "    # return f'{op}_{rel_name}_rule_{rule_id}_rel_{rel_idx}'\n",
    "\n",
    "def _select_if_needed(g,node_counter,source_node,terms,rel,rel_idx,rule_id):\n",
    "    \"\"\"add a project node as a father of source_node if the terms are not all free variables\n",
    "    returns the source_node if no project is needed, or the project node if it is needed\n",
    "    the name of the project node should be supplied\n",
    "    \"\"\"\n",
    "\n",
    "    need_select = any(not isinstance(term,FreeVar) for term in terms)\n",
    "    if not need_select:\n",
    "        return source_node\n",
    "    \n",
    "    select_pos_val = list()\n",
    "    for i,term in enumerate(terms):\n",
    "        if not isinstance(term,FreeVar):\n",
    "            select_pos_val.append((i,term))\n",
    "    \n",
    "    select_name = _name_node(node_counter,'select',rule_id,rel_idx,rel.name)\n",
    "    g.add_node(select_name, op='select',theta=select_pos_val)\n",
    "    g.add_edge(select_name,source_node)\n",
    "    return select_name\n",
    "\n",
    "def _product_if_needed(g,node_counter,source_node,terms,rel,rel_idx,rule_id):\n",
    "    \"\"\"add a product node as a father of source_node if the terms are not all free variables\n",
    "    returns the source_node if no product is needed, or the product node if it is needed\n",
    "    the name of the product node should be supplied\n",
    "    \"\"\"\n",
    "\n",
    "    need_product = any(not isinstance(term,FreeVar) for term in terms)\n",
    "    if not need_product:\n",
    "        return source_node\n",
    "    \n",
    "    product_pos_val = list()\n",
    "    for i,term in enumerate(terms):\n",
    "        if not isinstance(term,FreeVar):\n",
    "            product_pos_val.append((i,term))\n",
    "    \n",
    "    product_name = _name_node(node_counter,'product',rule_id,rel_idx,rel.name)\n",
    "    g.add_node(product_name, op='product',theta=product_pos_val)\n",
    "    g.add_edge(product_name,source_node)\n",
    "    return product_name\n",
    "\n",
    "# TODO from here, iteratively build the joins each time using _project_if_needed on the outrel and inrel of the relations/ierelaitons\n",
    "def _rule_to_term_graph(rule:Rule,rule_id) -> nx.DiGraph:\n",
    "    \"\"\"Convert a rule to a directed RA+IE term graph\"\"\"\n",
    "    node_counter = itertools.count()\n",
    "    G = nx.DiGraph()\n",
    "    # add nodes for all relations\n",
    "    body_term_connectors = list()\n",
    "    body_rels = _get_bounding_order(rule)\n",
    "\n",
    "    # create derivation for each rel in the body\n",
    "    for rel_idx,rel in enumerate(body_rels):\n",
    "        if isinstance(rel,Relation):\n",
    "            G.add_node(rel.name, op='get_rel',rel=rel.name)\n",
    "            rename_node = _name_node(node_counter,'rename',rule_id,rel_idx,rel.name)\n",
    "            G.add_node(rename_node, op='rename',names=[(i,term.name) for i,term in enumerate(rel.terms) if isinstance(term,FreeVar)])\n",
    "            G.add_edge(rename_node,rel.name)\n",
    "            top_rel_node = _select_if_needed(G,node_counter,rename_node,rel.terms,rel,rel_idx,rule_id)\n",
    "            \n",
    "            body_term_connectors.append((None,top_rel_node))\n",
    "\n",
    "        elif isinstance(rel,IERelation):\n",
    "            get_input_node_name =_name_node(node_counter,'get_input',rule_id,rel_idx,rel.name)\n",
    "            calc_node_name = _name_node(node_counter,'calc_ie',rule_id,rel_idx,rel.name)\n",
    "            G.add_node(get_input_node_name, op='project', on=[term.name for term in rel.in_terms if isinstance(term,FreeVar)])\n",
    "            G.add_node(calc_node_name, op='calc',func=rel.name)\n",
    "\n",
    "            product_name = _name_node(node_counter,'product_input',rule_id,rel_idx,rel.name)\n",
    "            calc_son = _product_if_needed(G,node_counter,get_input_node_name,rel.in_terms,rel,rel_idx,rule_id)\n",
    "            G.add_edge(calc_node_name,calc_son)\n",
    "            select_name = _name_node(node_counter,'select_output',rule_id,rel_idx,rel.name)\n",
    "            top_rel_node = _select_if_needed(G,node_counter,calc_node_name,rel.out_terms,rel,rel_idx,rule_id)\n",
    "            body_term_connectors.append((get_input_node_name,top_rel_node))\n",
    "\n",
    "    # connect outputs of different rels via joins\n",
    "    # and connect input of ie functons into the join\n",
    "    for i,(connectors,rel) in enumerate(zip(body_term_connectors,body_rels)):\n",
    "        if i == 0:\n",
    "            prev_top = connectors[1]\n",
    "            continue\n",
    "\n",
    "        current_top = connectors[1]\n",
    "\n",
    "        join_node_name = _name_node(node_counter,'join',rule_id,i,rel.name)\n",
    "        G.add_node(join_node_name, op='join')\n",
    "        G.add_edge(join_node_name,prev_top)\n",
    "        G.add_edge(join_node_name,current_top)\n",
    "\n",
    "        if isinstance(rel,IERelation):\n",
    "            ie_bottom = connectors[0]\n",
    "            G.add_edge(ie_bottom,prev_top)\n",
    "\n",
    "\n",
    "        prev_top = join_node_name\n",
    "\n",
    "    # project all assignments into the head\n",
    "    head_project_name = _name_node(node_counter,'project',rule_id,'head',rule.head.name)\n",
    "    G.add_node(head_project_name, op='project', on=[term.name for term in rule.head.terms],rel=f'_{rule.head.name}_{rule_id}')\n",
    "    G.add_edge(head_project_name,prev_top)\n",
    "\n",
    "    # add a union for each rule for the given head\n",
    "    G.add_node(rule.head.name,op='union',rel=rule.head.name)\n",
    "    G.add_edge(rule.head.name,head_project_name)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyldIl0KMVsiMQpvcD0jcXVvdDtzZWxlY3QjcXVvdDssIHRoZXRhPVsoMSwgU3BhbihzdGFydD0xLCBlbmQ9NCkpXSJdClMyWyJTMgpvcD0jcXVvdDtnZXRfcmVsI3F1b3Q7LCByZWw9I3F1b3Q7UzIjcXVvdDsiXQoyWyIyCm9wPSNxdW90O3JlbmFtZSNxdW90OywgbmFtZXM9WygwLCAjcXVvdDtYI3F1b3Q7KSwgKDEsICNxdW90O0EjcXVvdDspLCAoMiwgI3F1b3Q7QiNxdW90OyldIl0KM1siMwpvcD0jcXVvdDtwcm9qZWN0I3F1b3Q7LCBvbj1bI3F1b3Q7WCNxdW90O10iXQo0WyI0Cm9wPSNxdW90O2NhbGMjcXVvdDssIGZ1bmM9I3F1b3Q7VCNxdW90OyJdCjZbIjYKb3A9I3F1b3Q7cHJvZHVjdCNxdW90OywgdGhldGE9WygxLCAxKV0iXQo4WyI4Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSJdCjlbIjkKb3A9I3F1b3Q7Y2FsYyNxdW90OywgZnVuYz0jcXVvdDtUMiNxdW90OyJdCjEyWyIxMgpvcD0jcXVvdDtqb2luI3F1b3Q7Il0KMTNbIjEzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQoxNFsiMTQKb3A9I3F1b3Q7am9pbiNxdW90OyJdCjE1WyIxNQpvcD0jcXVvdDtwcm9qZWN0I3F1b3Q7LCBvbj1bI3F1b3Q7WCNxdW90OywgI3F1b3Q7WSNxdW90OywgI3F1b3Q7WiNxdW90O10sIHJlbD0jcXVvdDtfUl8wI3F1b3Q7Il0KUlsiUgpvcD0jcXVvdDt1bmlvbiNxdW90OywgcmVsPSNxdW90O1IjcXVvdDsiXQowIC0tPiBTCjEgLS0+IDAKMiAtLT4gUzIKMyAtLT4gMTIKNCAtLT4gNgo2IC0tPiAzCjggLS0+IDEzCjkgLS0+IDgKMTIgLS0+IDEKMTIgLS0+IDIKMTMgLS0+IDEyCjEzIC0tPiA0CjE0IC0tPiAxMwoxNCAtLT4gOQoxNSAtLT4gMTQKUiAtLT4gMTUK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO FROM HERE add labels to nodes we can labels\n",
    "# add HEAD projection node \n",
    "# maybe add free vars\n",
    "g = _rule_to_term_graph(r,0)\n",
    "draw(g)\n",
    "serialize_graph(g)\n",
    "assert serialize_graph(g) == ([('S', {'op': 'get_rel', 'rel': 'S'}),\n",
    "  (0, {'op': 'rename', 'names': [(0, 'X')]}),\n",
    "  (1, {'op': 'select', 'theta': [(1, Span(start=1, end=4))]}),\n",
    "  ('S2', {'op': 'get_rel', 'rel': 'S2'}),\n",
    "  (2, {'op': 'rename', 'names': [(0, 'X'), (1, 'A'), (2, 'B')]}),\n",
    "  (3, {'op': 'project', 'on': ['X']}),\n",
    "  (4, {'op': 'calc', 'func': 'T'}),\n",
    "  (6, {'op': 'product', 'theta': [(1, 1)]}),\n",
    "  (8, {'op': 'project', 'on': ['X', 'Y']}),\n",
    "  (9, {'op': 'calc', 'func': 'T2'}),\n",
    "  (12, {'op': 'join'}),\n",
    "  (13, {'op': 'join'}),\n",
    "  (14, {'op': 'join'}),\n",
    "  (15, {'op': 'project', 'on': ['X', 'Y', 'Z'], 'rel': '_R_0'}),\n",
    "  ('R', {'op': 'union', 'rel': 'R'})],\n",
    " [(0, 'S', {}),\n",
    "  (1, 0, {}),\n",
    "  (2, 'S2', {}),\n",
    "  (3, 12, {}),\n",
    "  (4, 6, {}),\n",
    "  (6, 3, {}),\n",
    "  (8, 13, {}),\n",
    "  (9, 8, {}),\n",
    "  (12, 1, {}),\n",
    "  (12, 2, {}),\n",
    "  (13, 12, {}),\n",
    "  (13, 4, {}),\n",
    "  (14, 13, {}),\n",
    "  (14, 9, {}),\n",
    "  (15, 14, {}),\n",
    "  ('R', 15, {})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R(X,Y) <- S(X,Y),S2(X,A,1)\n",
      "R(X,Y) <- S(X,Y)\n",
      "R2(X,Y) <- S3(X,Y),S2(X,A,1)\n"
     ]
    }
   ],
   "source": [
    "r1 = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "        Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'),1]),\n",
    "    ])\n",
    "\n",
    "r2 = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "r3 = Rule(\n",
    "    head=Relation(name='R2', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S3', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "        Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'),1]),\n",
    "    ])\n",
    "rules = [r1,r2,r3]\n",
    "for r in rules:\n",
    "    print(pretty(r))\n",
    "t1,t2,t3 = [_rule_to_term_graph(r,i) for i,r in enumerate(rules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def graph_compose(g1,g2,mapping_dict,debug=False):\n",
    "    \"\"\"compose two graphs with a mapping dict\"\"\"\n",
    "    # if there is a node in g2 that is renamed but has a name collision with an existing node that is not renamed, we will rename the existing node to a uniq name\n",
    "    # making new names into a digraph is a dirty hack, TODO resolve this\n",
    "    save_new_names= nx.DiGraph()\n",
    "    for u2 in g2.nodes():\n",
    "        if u2 not in mapping_dict and u2 in g1.nodes():\n",
    "            mapping_dict[u2] = get_new_node_name(g2,avoid_names_from=[g1,save_new_names])\n",
    "            save_new_names.add_node(mapping_dict[u2])\n",
    "    if debug:\n",
    "        return mapping_dict\n",
    "    g2 = nx.relabel_nodes(g2,mapping_dict,copy=True)\n",
    "    return nx.compose(g1,g2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzAjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdCjAgLS0+IFMKMSAtLT4gUzIKMiAtLT4gMQozIC0tPiAwCjMgLS0+IDIKNCAtLT4gMwpSIC0tPiA0Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQoxWyIxCm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzEjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdCjAgLS0+IFMKMSAtLT4gMApSIC0tPiAxCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTM1siUzMKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MzI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SMl8yI3F1b3Q7Il0KUjJbIlIyCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UjIjcXVvdDsiXQowIC0tPiBTMwoxIC0tPiBTMgoyIC0tPiAxCjMgLS0+IDAKMyAtLT4gMgo0IC0tPiAzClIyIC0tPiA0Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(t1)\n",
    "draw(t2)\n",
    "draw(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert graph_compose(t1,t3,{\n",
    "    'S':'S',0:0,1:1,\n",
    "},debug=True) == {'S': 'S', 0: 0, 1: 1, 'S2': 5, 2: 6, 3: 7, 4: 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert graph_compose(t1,t2,\n",
    "    mapping_dict = {'S':'S','R':'R',0:0}\n",
    "    ,debug=True) == {'S': 'S', 'R': 'R', 0: 0, 1: 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzAjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdCjVbIjUKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X1JfMSNxdW90OyJdCjAgLS0+IFMKMSAtLT4gUzIKMiAtLT4gMQozIC0tPiAwCjMgLS0+IDIKNCAtLT4gMwpSIC0tPiA0ClIgLS0+IDUKNSAtLT4gMAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m= graph_compose(t1,t2,\n",
    "    mapping_dict = {'S':'S','R':'R',0:0}) \n",
    "draw(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_term_graphs_pair(g1,g2,exclude_props = ['label'],debug=False):\n",
    "    \"\"\"merge two term graphs into one term graph\n",
    "    when talking about term graphs, 2 nodes if their data is identical and all of their children are identical\n",
    "    but we would also like to merge rules for the same head, so we will also nodes that have the same 'rel' attribute\n",
    "    \"\"\"\n",
    "\n",
    "    def _are_nodes_equal(g1,u1,g2,u2):\n",
    "        u1_data = g1.nodes[u1]\n",
    "        u2_data = g2.nodes[u2]\n",
    "        \n",
    "        if 'rel' in u1_data and 'rel' in u2_data:\n",
    "            return u1_data['rel'] == u2_data['rel']\n",
    "\n",
    "        u1_clean_data = {k:v for k,v in u1_data.items() if k not in exclude_props}\n",
    "        u2_clean_data = {k:v for k,v in u2_data.items() if k not in exclude_props}\n",
    "\n",
    "        are_equal = u1_clean_data == u2_clean_data and all(v2 in node_mappings for v2 in g2.successors(u2))\n",
    "        return are_equal\n",
    "        \n",
    "\n",
    "    # we will check for each node in g2 if it has a node in g1 which is it's equal.\n",
    "    # and save that in a mapping\n",
    "    node_mappings=dict()# g2 node name to g1 node name\n",
    "    # we use the fact that g2 is going to be acyclic to travers it in postorder\n",
    "    for u2 in nx.dfs_postorder_nodes(g2):\n",
    "        for u1 in g1.nodes():\n",
    "            if _are_nodes_equal(g1,u1,g2,u2):\n",
    "                node_mappings[u2] = u1\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        return node_mappings\n",
    "    else:\n",
    "        return graph_compose(g1,g2,node_mappings)\n",
    "\n",
    "\n",
    "\n",
    "def merge_term_graphs(gs,exclude_props = ['label'],debug=False):\n",
    "    \"\"\"merge a list of term graphs into one term graph\n",
    "    \"\"\"\n",
    "    merge = gs[0]\n",
    "    for g in gs[1:-1]:\n",
    "        merge = merge_term_graphs_pair(merge,g,exclude_props,debug=False)\n",
    "    # if debug, we run debug only on the last merge so we can iteratively debug a list of merges\n",
    "    return merge_term_graphs_pair(merge,gs[-1],exclude_props,debug=debug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for orig in [t1,t2,t3]:\n",
    "    merge_self = merge_term_graphs([orig,orig])\n",
    "assert serialize_graph(merge_self) == serialize_graph(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzAjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdCjVbIjUKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X1JfMSNxdW90OyJdCjAgLS0+IFMKMSAtLT4gUzIKMiAtLT4gMQozIC0tPiAwCjMgLS0+IDIKNCAtLT4gMwpSIC0tPiA0ClIgLS0+IDUKNSAtLT4gMAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = merge_term_graphs([t1,t2])\n",
    "draw(m)\n",
    "assert serialize_graph(m) == ([('S', {'op': 'get_rel', 'rel': 'S'}),\n",
    "  (0, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  ('S2', {'op': 'get_rel', 'rel': 'S2'}),\n",
    "  (1, {'op': 'rename', 'names': [(0, 'X'), (1, 'A')]}),\n",
    "  (2, {'op': 'select', 'theta': [(2, 1)]}),\n",
    "  (3, {'op': 'join'}),\n",
    "  (4, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_0'}),\n",
    "  ('R', {'op': 'union', 'rel': 'R'}),\n",
    "  (5, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_1'})],\n",
    " [(0, 'S', {}),\n",
    "  (1, 'S2', {}),\n",
    "  (2, 1, {}),\n",
    "  (3, 0, {}),\n",
    "  (3, 2, {}),\n",
    "  (4, 3, {}),\n",
    "  ('R', 4, {}),\n",
    "  ('R', 5, {}),\n",
    "  (5, 0, {})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzAjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdClMzWyJTMwpvcD0jcXVvdDtnZXRfcmVsI3F1b3Q7LCByZWw9I3F1b3Q7UzMjcXVvdDsiXQo1WyI1Cm9wPSNxdW90O3JlbmFtZSNxdW90OywgbmFtZXM9WygwLCAjcXVvdDtYI3F1b3Q7KSwgKDEsICNxdW90O1kjcXVvdDspXSJdCjZbIjYKb3A9I3F1b3Q7am9pbiNxdW90OyJdCjdbIjcKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X1IyXzIjcXVvdDsiXQpSMlsiUjIKb3A9I3F1b3Q7dW5pb24jcXVvdDssIHJlbD0jcXVvdDtSMiNxdW90OyJdCjAgLS0+IFMKMSAtLT4gUzIKMiAtLT4gMQozIC0tPiAwCjMgLS0+IDIKNCAtLT4gMwpSIC0tPiA0CjUgLS0+IFMzCjYgLS0+IDUKNiAtLT4gMgo3IC0tPiA2ClIyIC0tPiA3Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = merge_term_graphs([t1,t3])\n",
    "draw(m)\n",
    "assert serialize_graph(m) == ([('S', {'op': 'get_rel', 'rel': 'S'}),\n",
    "  (0, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  ('S2', {'op': 'get_rel', 'rel': 'S2'}),\n",
    "  (1, {'op': 'rename', 'names': [(0, 'X'), (1, 'A')]}),\n",
    "  (2, {'op': 'select', 'theta': [(2, 1)]}),\n",
    "  (3, {'op': 'join'}),\n",
    "  (4, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_0'}),\n",
    "  ('R', {'op': 'union', 'rel': 'R'}),\n",
    "  ('S3', {'op': 'get_rel', 'rel': 'S3'}),\n",
    "  (5, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  (6, {'op': 'join'}),\n",
    "  (7, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R2_2'}),\n",
    "  ('R2', {'op': 'union', 'rel': 'R2'})],\n",
    " [(0, 'S', {}),\n",
    "  (1, 'S2', {}),\n",
    "  (2, 1, {}),\n",
    "  (3, 0, {}),\n",
    "  (3, 2, {}),\n",
    "  (4, 3, {}),\n",
    "  ('R', 4, {}),\n",
    "  (5, 'S3', {}),\n",
    "  (6, 5, {}),\n",
    "  (6, 2, {}),\n",
    "  (7, 6, {}),\n",
    "  ('R2', 7, {})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpTWyJTCm9wPSNxdW90O2dldF9yZWwjcXVvdDssIHJlbD0jcXVvdDtTI3F1b3Q7Il0KMFsiMApvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtZI3F1b3Q7KV0iXQpTMlsiUzIKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O1MyI3F1b3Q7Il0KMVsiMQpvcD0jcXVvdDtyZW5hbWUjcXVvdDssIG5hbWVzPVsoMCwgI3F1b3Q7WCNxdW90OyksICgxLCAjcXVvdDtBI3F1b3Q7KV0iXQoyWyIyCm9wPSNxdW90O3NlbGVjdCNxdW90OywgdGhldGE9WygyLCAxKV0iXQozWyIzCm9wPSNxdW90O2pvaW4jcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3Byb2plY3QjcXVvdDssIG9uPVsjcXVvdDtYI3F1b3Q7LCAjcXVvdDtZI3F1b3Q7XSwgcmVsPSNxdW90O19SXzAjcXVvdDsiXQpSWyJSCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7UiNxdW90OyJdCjVbIjUKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X1JfMSNxdW90OyJdClMzWyJTMwpvcD0jcXVvdDtnZXRfcmVsI3F1b3Q7LCByZWw9I3F1b3Q7UzMjcXVvdDsiXQo2WyI2Cm9wPSNxdW90O3JlbmFtZSNxdW90OywgbmFtZXM9WygwLCAjcXVvdDtYI3F1b3Q7KSwgKDEsICNxdW90O1kjcXVvdDspXSJdCjdbIjcKb3A9I3F1b3Q7am9pbiNxdW90OyJdCjhbIjgKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X1IyXzIjcXVvdDsiXQpSMlsiUjIKb3A9I3F1b3Q7dW5pb24jcXVvdDssIHJlbD0jcXVvdDtSMiNxdW90OyJdCjAgLS0+IFMKMSAtLT4gUzIKMiAtLT4gMQozIC0tPiAwCjMgLS0+IDIKNCAtLT4gMwpSIC0tPiA0ClIgLS0+IDUKNSAtLT4gMAo2IC0tPiBTMwo3IC0tPiA2CjcgLS0+IDIKOCAtLT4gNwpSMiAtLT4gOAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = merge_term_graphs([t1,t2,t3])\n",
    "draw(m)\n",
    "assert serialize_graph(m) == ([('S', {'op': 'get_rel', 'rel': 'S'}),\n",
    "  (0, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  ('S2', {'op': 'get_rel', 'rel': 'S2'}),\n",
    "  (1, {'op': 'rename', 'names': [(0, 'X'), (1, 'A')]}),\n",
    "  (2, {'op': 'select', 'theta': [(2, 1)]}),\n",
    "  (3, {'op': 'join'}),\n",
    "  (4, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_0'}),\n",
    "  ('R', {'op': 'union', 'rel': 'R'}),\n",
    "  (5, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_1'}),\n",
    "  ('S3', {'op': 'get_rel', 'rel': 'S3'}),\n",
    "  (6, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  (7, {'op': 'join'}),\n",
    "  (8, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R2_2'}),\n",
    "  ('R2', {'op': 'union', 'rel': 'R2'})],\n",
    " [(0, 'S', {}),\n",
    "  (1, 'S2', {}),\n",
    "  (2, 1, {}),\n",
    "  (3, 0, {}),\n",
    "  (3, 2, {}),\n",
    "  (4, 3, {}),\n",
    "  ('R', 4, {}),\n",
    "  ('R', 5, {}),\n",
    "  (5, 0, {}),\n",
    "  (6, 'S3', {}),\n",
    "  (7, 6, {}),\n",
    "  (7, 2, {}),\n",
    "  (8, 7, {}),\n",
    "  ('R2', 8, {})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Rule(\n",
    "    head=Relation(name='A', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='B', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "r2 = Rule(\n",
    "    head=Relation(name='A', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='C', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "r3 = Rule(\n",
    "    head=Relation(name='B', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='D', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "r4 = Rule(\n",
    "    head=Relation(name='B', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='A', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A(X,Y) <- B(X,Y)', 'A(X,Y) <- C(X,Y)', 'B(X,Y) <- D(X,Y)', 'B(X,Y) <- A(X,Y)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgpCWyJCCm9wPSNxdW90O3VuaW9uI3F1b3Q7LCByZWw9I3F1b3Q7QiNxdW90OyJdCjBbIjAKb3A9I3F1b3Q7cmVuYW1lI3F1b3Q7LCBuYW1lcz1bKDAsICNxdW90O1gjcXVvdDspLCAoMSwgI3F1b3Q7WSNxdW90OyldIl0KMVsiMQpvcD0jcXVvdDtwcm9qZWN0I3F1b3Q7LCBvbj1bI3F1b3Q7WCNxdW90OywgI3F1b3Q7WSNxdW90O10sIHJlbD0jcXVvdDtfQV8wI3F1b3Q7Il0KQVsiQQpvcD0jcXVvdDtnZXRfcmVsI3F1b3Q7LCByZWw9I3F1b3Q7QSNxdW90OyJdCkNbIkMKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O0MjcXVvdDsiXQoyWyIyCm9wPSNxdW90O3JlbmFtZSNxdW90OywgbmFtZXM9WygwLCAjcXVvdDtYI3F1b3Q7KSwgKDEsICNxdW90O1kjcXVvdDspXSJdCjNbIjMKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X0FfMSNxdW90OyJdCkRbIkQKb3A9I3F1b3Q7Z2V0X3JlbCNxdW90OywgcmVsPSNxdW90O0QjcXVvdDsiXQo0WyI0Cm9wPSNxdW90O3JlbmFtZSNxdW90OywgbmFtZXM9WygwLCAjcXVvdDtYI3F1b3Q7KSwgKDEsICNxdW90O1kjcXVvdDspXSJdCjVbIjUKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X0JfMiNxdW90OyJdCjZbIjYKb3A9I3F1b3Q7cHJvamVjdCNxdW90Oywgb249WyNxdW90O1gjcXVvdDssICNxdW90O1kjcXVvdDtdLCByZWw9I3F1b3Q7X0JfMyNxdW90OyJdCkIgLS0+IDUKQiAtLT4gNgowIC0tPiBCCjAgLS0+IEEKMSAtLT4gMApBIC0tPiAxCkEgLS0+IDMKMiAtLT4gQwozIC0tPiAyCjQgLS0+IEQKNSAtLT4gNAo2IC0tPiAwCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rules = [r1,r2,r3,r4]\n",
    "print([pretty(r) for r in rules])\n",
    "m = merge_term_graphs([_rule_to_term_graph(r,i) for i,r in enumerate(rules)])\n",
    "draw(m)\n",
    "assert serialize_graph(m) ==([('B', {'op': 'union', 'rel': 'B'}),\n",
    "  (0, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  (1, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_A_0'}),\n",
    "  ('A', {'op': 'get_rel', 'rel': 'A'}),\n",
    "  ('C', {'op': 'get_rel', 'rel': 'C'}),\n",
    "  (2, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  (3, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_A_1'}),\n",
    "  ('D', {'op': 'get_rel', 'rel': 'D'}),\n",
    "  (4, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')]}),\n",
    "  (5, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_B_2'}),\n",
    "  (6, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_B_3'})],\n",
    " [('B', 5, {}),\n",
    "  ('B', 6, {}),\n",
    "  (0, 'B', {}),\n",
    "  (0, 'A', {}),\n",
    "  (1, 0, {}),\n",
    "  ('A', 1, {}),\n",
    "  ('A', 3, {}),\n",
    "  (2, 'C', {}),\n",
    "  (3, 2, {}),\n",
    "  (4, 'D', {}),\n",
    "  (5, 4, {}),\n",
    "  (6, 0, {})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO from here, make a notebook that will make a Span extension type for pandas\n",
    "df= pd.DataFrame([\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine():\n",
    "    def __init__(self):\n",
    "        self.symbol_table={\n",
    "            # key : type,val\n",
    "        }\n",
    "        self.Relation_defs={\n",
    "            # key : RelationDefinition for both real and derived relations\n",
    "        }\n",
    "        self.ie_functions={\n",
    "            # name : IEFunction class\n",
    "        }\n",
    "\n",
    "        self.term_graph = nx.Digraph()\n",
    "        \n",
    "        node_counter = itertools.Count()\n",
    "\n",
    "        self.db = {\n",
    "            # relation_name: dataframe\n",
    "        }\n",
    "\n",
    "        # lets skip this for now and keep it a an attribute in the node graph\n",
    "        # self.rules_to_nodes = {\n",
    "        #     # rule pretty string, to node id in term_graph\n",
    "        # }\n",
    "\n",
    "        # self.rels_to_nodes() = {\n",
    "        #     # relation name to node that represents it\n",
    "        # }\n",
    "\n",
    "\n",
    "    def set_var(var_name,value,read_from_file=False):\n",
    "        symbol_table = self.symbol_table\n",
    "        if var_name in symbol_table:\n",
    "            existing_type,existing_value = symbol_table[var_name]\n",
    "            if type(value) != existing_type:\n",
    "                raise ValueError(f\"Variable {var_name} was previously defined with {existing_value}({pretty(existing_type)})\"\n",
    "                                f\" but is trying to be redefined to {value}({pretty(type(value))}) of a different type which might interfere with previous rule definitions\")    \n",
    "        symbol_table[var_name] = type(value),value\n",
    "        return\n",
    "    def get_var(var_name):\n",
    "        return self.symbol_table[var_name]\n",
    "    \n",
    "    def del_var(var_name):\n",
    "        del self.symbol_table[var_name]\n",
    "\n",
    "    def get_relation(self,rel_name:str):\n",
    "        return self.Relation_defs[rel_name]\n",
    "\n",
    "    def set_relation(self,rel_def:RelationDefinition):\n",
    "        if rel_def.name in self.Relation_defs:\n",
    "            existing_def = self.Relation_defs[rel_def.name]\n",
    "            if existing_def != rel_def:\n",
    "                raise ValueError(f\"Relation {rel_def.name} was previously defined with {existing_def}\"\n",
    "                                f\"but is trying to be redefined to {rel_def} which might interfere with previous rule definitions\")\n",
    "        else:\n",
    "            self.Relation_defs[rel_def.name] = rel_def\n",
    "            empty_df = pd.DataFrame(columns=[pretty(s) for s in rel_def.scheme])\n",
    "\n",
    "    def del_relation(self,rel_name:str):\n",
    "        # TODO we need to think about what to do with all relations that used this rule\n",
    "        raise NotImplementedError(\"deleting relations is not supported yet\")\n",
    "        pass\n",
    "\n",
    "    def add_fact(self,fact:Relation):\n",
    "        pass\n",
    "\n",
    "    def del_fact(self,fact:Relation):\n",
    "        pass\n",
    "\n",
    "    def get_ie_function(self,name:str):\n",
    "        pass\n",
    "\n",
    "    def set_ie_function(self,ie_func:IEFunction):\n",
    "        pass\n",
    "\n",
    "    def del_ie_function(self,name:str):\n",
    "        pass\n",
    "\n",
    "    def add_rule(self,rule:Rule):\n",
    "        # make term graph of the rule, make sure the nodes of relations have the same name\n",
    "        # merge the term graph with the existing one via graph union\n",
    "\n",
    "        # TODO extension, make the graph a semiring graph, so we can share common expressions\n",
    "        # give the rule head the id of the rule string so we can find it for removal\n",
    "\n",
    "        pass\n",
    "\n",
    "    def del_rule(self,name:str):\n",
    "        # find the node in the term graph that has the name of the rule\n",
    "        # remove the nodes and all of it's ancestors if they are not connected to any other node\n",
    "        # if the node of the head relation has no sons now, remove it as well\n",
    "        pass\n",
    "\n",
    "    def run_query(self,q:Relation,rewrites=None):\n",
    "        # get the subgraph of the term graph that has the query relation as a node\n",
    "        # call all rewrites on it\n",
    "        # TODO add verbose and display options for optimizations\n",
    "\n",
    "        # call the semi-naive evaluation on the subgraph\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Resolve Vars  # lets put this in the term graph\n",
    "# * Register new Relations\n",
    "# * Add/remove facts\n",
    "# * Add rules\n",
    "# * Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each RA operation, and the CalcIE operation, we have an operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select\n",
    "* Project\n",
    "* Rename\n",
    "* Union\n",
    "* Intersection\n",
    "* Difference\n",
    "* Join\n",
    "* SemiJoin\n",
    "* Calc (for calcing ie relations)\n",
    "* GetRel (for accessing relations from the DB)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemiNaive Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every RA operation and CalcIE operation, we have a funcion that taken the children as nodes that can get the underlying data from a specific iteration and compute the differential version of the operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select\n",
    "* Project\n",
    "* Rename\n",
    "* Union\n",
    "* Intersection\n",
    "* Difference\n",
    "* Join\n",
    "* SemiJoin\n",
    "* Calc (for calcing ie relations)\n",
    "* GetRel (for accessing relations from the DB)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi naive execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recursive least fixed point logic algorithm mimicing the seminaive bottom up evalutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO agg - build tests for engine and query based on current implementation to be used as a regression test\n",
    "# these tests should check the resulting computation graph and the output of the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bottom up\n",
    "# start at root\n",
    "# if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_node\n",
    "\n",
    "    # if node is not part of circle,\n",
    "    # compute it by computing all of its children and performing the nodes operation on them.\n",
    "\n",
    "    # if its a part of a cycle, \n",
    "        #compute current iterations\n",
    "\n",
    "\n",
    "# compute_current_iteration (i)\n",
    "    # take the (i-1) value of children that are in the cycle\n",
    "    # take the final value of children that are not in the cycle\n",
    "\n",
    "    # compute the node based on the children values, assign it to the values of the ith iteration of the node\n",
    "    # if the value of the node didnt change from last time, mark the node as finished and return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node(G,u,iter=0):\n",
    "    if u.final == True:\n",
    "        return u.answers[-1]\n",
    "    for child in G.children(u):\n",
    "        vals = compute_node(G,child,iter)\n",
    "\n",
    "    u.answers[iter] = u.op(vals)\n",
    "\n",
    "    if u.answers[iter] == u.answers[iter-1]:\n",
    "        u.final = True\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
