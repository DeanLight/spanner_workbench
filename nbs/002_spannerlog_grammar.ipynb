{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> This module contains the spannerlog grammar plus utilities that will help the developer assert that the ast he received matches the grammar\n",
    "that he expects to work with.\n",
    "\n",
    ">These asserts are useful as a general safety check, and also for finding places in the code that need to change\n",
    "should the spannerlog grammar be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import no_type_check, Set, Sequence, Any, Callable\n",
    "from typing import Sequence, Dict\n",
    "from lark import Lark,Token, Tree, Transformer\n",
    "import yaml\n",
    "import networkx as nx\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from graph_rewrite import rewrite,rewrite_iter,draw\n",
    "\n",
    "from spannerlib.utils import checkLogs, uniq_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "SpannerlogGrammar = r\"\"\"\n",
    "start: (_NEWLINE)* (statement (_NEWLINE)+)* (statement)?\n",
    "\n",
    "?statement: relation_declaration\n",
    "          | add_fact\n",
    "          | remove_fact\n",
    "          | rule\n",
    "          | query\n",
    "          | assignment\n",
    "\n",
    "assignment: var_name \"=\" string\n",
    "          | var_name \"=\" span\n",
    "          | var_name \"=\" int\n",
    "          | var_name \"=\" var_name\n",
    "          | var_name \"=\" \"read\" \"(\" string \")\" -> read_assignment\n",
    "          | var_name \"=\" \"read\" \"(\" var_name \")\" -> read_assignment\n",
    "\n",
    "relation_declaration: \"new\" _SEPARATOR relation_name \"(\" decl_term_list \")\"\n",
    "\n",
    "decl_term_list: decl_term (\",\" decl_term)*\n",
    "\n",
    "?decl_term: \"str\" -> decl_string\n",
    "          | \"span\" -> decl_span\n",
    "          | \"int\" -> decl_int\n",
    "\n",
    "rule: rule_head \"<-\" rule_body_relation_list\n",
    "\n",
    "rule_head: relation_name \"(\" free_var_name_list \")\"\n",
    "\n",
    "rule_body_relation_list: rule_body_relation (\",\" rule_body_relation)*\n",
    "\n",
    "?rule_body_relation: relation\n",
    "                   | ie_relation\n",
    "\n",
    "relation: relation_name \"(\" term_list \")\"\n",
    "\n",
    "ie_relation: relation_name \"(\" term_list \")\" \"->\" \"(\" term_list \")\"\n",
    "\n",
    "query: \"?\" relation_name \"(\" term_list \")\"\n",
    "\n",
    "term_list: term (\",\" term)*\n",
    "\n",
    "?term: const_term\n",
    "     | free_var_name\n",
    "\n",
    "add_fact: relation_name \"(\" const_term_list \")\"\n",
    "        | relation_name \"(\" const_term_list \")\" \"<-\" _TRUE\n",
    "\n",
    "remove_fact: relation_name \"(\" const_term_list \")\" \"<-\" _FALSE\n",
    "\n",
    "const_term_list: const_term (\",\" const_term)*\n",
    "\n",
    "?const_term: span\n",
    "          | string\n",
    "          | int\n",
    "          | var_name\n",
    "\n",
    "span: \"[\" int \",\" int \")\"\n",
    "\n",
    "int: INT -> integer\n",
    "\n",
    "string: STRING\n",
    "\n",
    "free_var_name_list: free_var_name (\",\" free_var_name)*\n",
    "\n",
    "relation_name: LOWER_CASE_NAME\n",
    "             | UPPER_CASE_NAME\n",
    "\n",
    "var_name: LOWER_CASE_NAME\n",
    "\n",
    "free_var_name : UPPER_CASE_NAME\n",
    "\n",
    "_TRUE: \"True\"\n",
    "_FALSE: \"False\"\n",
    "\n",
    "LOWER_CASE_NAME: (\"_\"|LCASE_LETTER) (\"_\"|LETTER|DIGIT)*\n",
    "UPPER_CASE_NAME: UCASE_LETTER (\"_\"|LETTER|DIGIT)*\n",
    "\n",
    "_COMMENT: \"#\" /[^\\n]*/\n",
    "\n",
    "_SEPARATOR: (_WS_INLINE | _LINE_OVERFLOW_ESCAPE)+\n",
    "\n",
    "STRING: \"\\\"\" (_STRING_INTERNAL (_LINE_OVERFLOW_ESCAPE)+)* _STRING_INTERNAL \"\\\"\"\n",
    "\n",
    "_LINE_OVERFLOW_ESCAPE: \"\\\\\" _NEWLINE\n",
    "\n",
    "_NEWLINE: CR? LF\n",
    "CR : /\\r/\n",
    "LF : /\\n/\n",
    "\n",
    "LCASE_LETTER: \"a\"..\"z\"\n",
    "UCASE_LETTER: \"A\"..\"Z\"\n",
    "LETTER: UCASE_LETTER | LCASE_LETTER\n",
    "DIGIT: \"0\"..\"9\"\n",
    "_WS_INLINE: (\" \"|/\\t/)+\n",
    "%ignore _WS_INLINE\n",
    "_STRING_INTERNAL: /.*?/ /(?<!\\\\)(\\\\\\\\)*?/\n",
    "INT: DIGIT+\n",
    "%ignore _LINE_OVERFLOW_ESCAPE\n",
    "%ignore _COMMENT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpannerlogParser = Lark(SpannerlogGrammar, parser='lalr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lark_to_nx_aux(tree,node_id,g):\n",
    "    if isinstance(tree, Token):\n",
    "        g.add_node(node_id,val=tree.value)\n",
    "    elif isinstance(tree, Tree):\n",
    "        g.add_node(node_id,type=tree.data)\n",
    "        for i,child in enumerate(tree.children):\n",
    "            child_id = uniq_id()\n",
    "            g.add_edge(node_id,child_id)\n",
    "            lark_to_nx_aux(child,child_id,g)\n",
    "            \n",
    "\n",
    "\n",
    "def lark_to_nx(t):\n",
    "    g = nx.DiGraph()\n",
    "    lark_to_nx_aux(t,uniq_id(),g)\n",
    "    return g\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_spannerlog(spannerlog_code: str,start='start',as_string=False,as_tree=False,as_nx=True):\n",
    "    parser = Lark(SpannerlogGrammar, parser='lalr',start=start)\n",
    "    tree = parser.parse(spannerlog_code)\n",
    "    if as_string:\n",
    "        return tree.pretty()\n",
    "    if as_tree:\n",
    "        return tree\n",
    "    if as_nx:\n",
    "        return lark_to_nx(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing utils\n",
    "def tree_to_json(node):\n",
    "    logger.debug(f'casting the following lark node to json: {node}')\n",
    "    if isinstance(node, Token):\n",
    "        #return {'type': node.type, 'value': node.value}\n",
    "        return node.value\n",
    "    if isinstance(node, Tree):\n",
    "        type = node.data\n",
    "    elif hasattr(node, 'type'):\n",
    "        type = node.type.value\n",
    "    else:\n",
    "        type = node.type\n",
    "    if len(node.children) == 1:\n",
    "        return {type: tree_to_json(node.children[0])}\n",
    "    else:\n",
    "        return {type: [tree_to_json(child) for child in node.children]}\n",
    "\n",
    "def tree_to_yaml(node):\n",
    "    return yaml.dump(tree_to_json(node))\n",
    "\n",
    "def assert_grammar(start,text,expected_yaml):\n",
    "    tree = parse_spannerlog(text,start=start,as_tree=True)\n",
    "    expected = yaml.safe_load(expected_yaml)\n",
    "    gotten = tree_to_json(tree)\n",
    "    assert gotten == expected, f'got unexpected parse results\\n{tree_to_yaml(tree)}\\nexpected\\n{expected_yaml}'\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree= assert_grammar(\n",
    "      'rule',\n",
    "      'head(X,Y,W)<-body1(X,Z),body2(Z,Y),ie_1(X,Y,Z)->(W)',\n",
    "    '''\n",
    "  rule:\n",
    "  - rule_head:\n",
    "    - relation_name: head\n",
    "    - free_var_name_list:\n",
    "      - free_var_name: X\n",
    "      - free_var_name: Y\n",
    "      - free_var_name: W\n",
    "  - rule_body_relation_list:\n",
    "    - relation:\n",
    "      - relation_name: body1\n",
    "      - term_list:\n",
    "        - free_var_name: X\n",
    "        - free_var_name: Z\n",
    "    - relation:\n",
    "      - relation_name: body2\n",
    "      - term_list:\n",
    "        - free_var_name: Z\n",
    "        - free_var_name: Y\n",
    "    - ie_relation:\n",
    "      - relation_name: ie_1\n",
    "      - term_list:\n",
    "        - free_var_name: X\n",
    "        - free_var_name: Y\n",
    "        - free_var_name: Z\n",
    "      - term_list:\n",
    "          free_var_name: W\n",
    "  ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule\n",
      "  rule_head\n",
      "    relation_name\thead\n",
      "    free_var_name_list\n",
      "      free_var_name\tX\n",
      "      free_var_name\tY\n",
      "      free_var_name\tW\n",
      "  rule_body_relation_list\n",
      "    relation\n",
      "      relation_name\tbody1\n",
      "      term_list\n",
      "        free_var_name\tX\n",
      "        free_var_name\tZ\n",
      "    relation\n",
      "      relation_name\tbody2\n",
      "      term_list\n",
      "        free_var_name\tZ\n",
      "        free_var_name\tY\n",
      "    ie_relation\n",
      "      relation_name\tie_1\n",
      "      term_list\n",
      "        free_var_name\tX\n",
      "        free_var_name\tY\n",
      "        free_var_name\tZ\n",
      "      term_list\n",
      "        free_var_name\tW\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = parse_spannerlog('head(X,Y,W)<-body1(X,1),body2(1,Y),ie_1(X,Y,1)->(W)')\n",
    "for match in rewrite_iter(g,lhs='''rel[val:str=\"relation\"]->z[val:str=\"relation_name\"]->y'''):\n",
    "    print(match['y']['val'])\n",
    "draw(g,direction='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBMUgoxMjRbIjEyNAp0eXBlPXN0YXJ0Il0KMTI1WyIxMjUKdHlwZT1ydWxlIl0KMTI2WyIxMjYKdHlwZT1ydWxlX2hlYWQiXQoxMjdbIjEyNwp0eXBlPXJlbGF0aW9uX25hbWUiXQoxMjhbIjEyOAp2YWw9aGVhZCJdCjEyOVsiMTI5CnR5cGU9ZnJlZV92YXJfbmFtZV9saXN0Il0KMTMwWyIxMzAKdHlwZT1mcmVlX3Zhcl9uYW1lIl0KMTMxWyIxMzEKdmFsPVgiXQoxMzJbIjEzMgp0eXBlPWZyZWVfdmFyX25hbWUiXQoxMzNbIjEzMwp2YWw9WSJdCjEzNFsiMTM0CnR5cGU9ZnJlZV92YXJfbmFtZSJdCjEzNVsiMTM1CnZhbD1XIl0KMTM2WyIxMzYKdHlwZT1ydWxlX2JvZHlfcmVsYXRpb25fbGlzdCJdCjEzN1siMTM3CnR5cGU9cmVsYXRpb24iXQoxMzhbIjEzOAp0eXBlPXJlbGF0aW9uX25hbWUiXQoxMzlbIjEzOQp2YWw9Ym9keTEiXQoxNDBbIjE0MAp0eXBlPXRlcm1fbGlzdCwgZnJlZV92YXJzPVsnWCddIl0KMTQzWyIxNDMKdHlwZT1pbnRlZ2VyIl0KMTQ0WyIxNDQKdmFsPTEiXQoxNDVbIjE0NQp0eXBlPXJlbGF0aW9uIl0KMTQ2WyIxNDYKdHlwZT1yZWxhdGlvbl9uYW1lIl0KMTQ3WyIxNDcKdmFsPWJvZHkyIl0KMTQ4WyIxNDgKdHlwZT10ZXJtX2xpc3QsIGZyZWVfdmFycz1bJ1knXSJdCjE0OVsiMTQ5CnR5cGU9aW50ZWdlciJdCjE1MFsiMTUwCnZhbD0xIl0KMTUzWyIxNTMKdHlwZT1pZV9yZWxhdGlvbiJdCjE1NFsiMTU0CnR5cGU9cmVsYXRpb25fbmFtZSJdCjE1NVsiMTU1CnZhbD1pZV8xIl0KMTU2WyIxNTYKdHlwZT10ZXJtX2xpc3QsIGZyZWVfdmFycz1bJ1gnLCAnWSddIl0KMTYxWyIxNjEKdHlwZT1pbnRlZ2VyIl0KMTYyWyIxNjIKdmFsPTEiXQoxNjNbIjE2Mwp0eXBlPXRlcm1fbGlzdCwgZnJlZV92YXJzPVsnVyddIl0KMTI0IC0tPiAxMjUKMTI1IC0tPiAxMjYKMTI1IC0tPiAxMzYKMTI2IC0tPiAxMjcKMTI2IC0tPiAxMjkKMTI3IC0tPiAxMjgKMTI5IC0tPiAxMzAKMTI5IC0tPiAxMzIKMTI5IC0tPiAxMzQKMTMwIC0tPiAxMzEKMTMyIC0tPiAxMzMKMTM0IC0tPiAxMzUKMTM2IC0tPiAxMzcKMTM2IC0tPiAxNDUKMTM2IC0tPiAxNTMKMTM3IC0tPiAxMzgKMTM3IC0tPiAxNDAKMTM4IC0tPiAxMzkKMTQwIC0tPiAxNDMKMTQzIC0tPiAxNDQKMTQ1IC0tPiAxNDYKMTQ1IC0tPiAxNDgKMTQ2IC0tPiAxNDcKMTQ4IC0tPiAxNDkKMTQ5IC0tPiAxNTAKMTUzIC0tPiAxNTQKMTUzIC0tPiAxNTYKMTUzIC0tPiAxNjMKMTU0IC0tPiAxNTUKMTU2IC0tPiAxNjEKMTYxIC0tPiAxNjIK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO currently we cant get all children of a node at once, so we can't make the list of free vars using rhs\n",
    "for match in rewrite_iter(g,lhs='''terms[type=\"term_list\"]->var[type=\"free_var_name\"]->val''',\n",
    "                          p='terms[type]',):\n",
    "        free_var_list = match['terms'].get('free_vars',[])\n",
    "        free_var_list.append(match['val']['val'])\n",
    "        match['terms']['free_vars'] = free_var_list\n",
    "\n",
    "draw(g,direction='LR')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
