{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Union, Optional, Callable, Type, Iterable, no_type_check, Sequence\n",
    "from IPython import display\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from spannerlib.utils import checkLogs,serialize_df_values,get_base_file_path\n",
    "from spannerlib.grammar import parse_spannerlog,reconstruct\n",
    "from spannerlib.span import Span\n",
    "from spannerlib.data_types import (\n",
    "    _infer_relation_schema,\n",
    "     Var,\n",
    "    FreeVar,\n",
    "    RelationDefinition,\n",
    "    Relation,\n",
    "    IEFunction,\n",
    "    IERelation,\n",
    "    Rule,\n",
    "    pretty,\n",
    ")\n",
    "from spannerlib.engine import Engine\n",
    "\n",
    "from spannerlib.micro_passes import (\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames,\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations,\n",
    "    rules_to_dataclasses,\n",
    "    consistent_free_var_types_in_rule,\n",
    "    check_rule_safety,\n",
    "    assignments_to_name_val_tuple,\n",
    "    execute_statement,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "\n",
    "from spannerlib.ie_func.json_path import JsonPath, JsonPathFull\n",
    "from spannerlib.ie_func.nlp import (Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment, TrueCase)\n",
    "from spannerlib.ie_func.python_regex import PYRGX, PYRGX_STRING\n",
    "from spannerlib.ie_func.rust_spanner_regex import RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE\n",
    "\n",
    "\n",
    "# ordered by rgx, json, nlp, etc.\n",
    "PREDEFINED_IE_FUNCS = [PYRGX, PYRGX_STRING, RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE,\n",
    "                       JsonPath, JsonPathFull,\n",
    "                       Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment,\n",
    "                       TrueCase]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Session():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.pass_stack = [\n",
    "            convert_primitive_values_to_objects,\n",
    "            remove_new_lines_from_strings,\n",
    "            CheckReservedRelationNames('spanner_'),\n",
    "            check_referenced_paths_exist,\n",
    "            check_referenced_vars_exist,\n",
    "            relations_to_dataclasses,\n",
    "            verify_referenced_relations,\n",
    "            rules_to_dataclasses,\n",
    "            consistent_free_var_types_in_rule,\n",
    "            check_rule_safety,\n",
    "            assignments_to_name_val_tuple\n",
    "        ]\n",
    "        self.engine=Engine()\n",
    "\n",
    "        # TODO define all the default ie funcs\n",
    "\n",
    "    def get_pass_stack(self):\n",
    "        \"\"\"\n",
    "        @return: the current pass stack.\n",
    "        \"\"\"\n",
    "        return self._pass_stack.copy()\n",
    "\n",
    "    def set_pass_stack(self,\n",
    "        user_stack #  a user supplied pass stack\n",
    "        ): \n",
    "        \"\"\"\n",
    "        Sets a new pass stack instead of the current one.\n",
    "        \"\"\"\n",
    "        if type(user_stack) is not list:\n",
    "            raise TypeError('user stack should be a list of passes')\n",
    "        self._pass_stack = user_stack.copy()\n",
    "\n",
    "    def _display_result(self,result):\n",
    "        if result is None:\n",
    "            pass\n",
    "        elif isinstance(result,pd.DataFrame):\n",
    "            display.display(result)\n",
    "        else:\n",
    "            print(result)\n",
    "    \n",
    "    def register(self,name,func,in_schema,out_schema):\n",
    "        #TODO add option for outschema to be a callable that gets the input and the output and confirms if the output is valid\n",
    "        ie_func_obj = IEFunction(name=name,func=func,in_schema=in_schema,out_schema=out_schema)\n",
    "        self.engine.set_ie_function(ie_func_obj)\n",
    "\n",
    "    def parse_and_check_semantics(self,code):\n",
    "        statements = parse_spannerlog(code,split_statements=True)\n",
    "        asts = []\n",
    "        for statement_nx,statement_lark in statements:\n",
    "            ast = statement_nx\n",
    "            for pass_ in self.pass_stack:\n",
    "                try:\n",
    "                    pass_(ast,self.engine)\n",
    "                except Exception as e:\n",
    "                    raise Exception(\n",
    "                        f\"During semantic checks for statement \\n\\\"{reconstruct(statement_lark)}\\\"\\n\"\n",
    "                        f\"in pass {pass_} the following exception was raised:\\n{e}\\n\"\n",
    "                        ).with_traceback(e.__traceback__)\n",
    "            yield ast,statement_lark\n",
    "\n",
    "\n",
    "    def plan_query(self,code):\n",
    "        statements = list(self.parse_and_check_semantics(code))\n",
    "        if len(statements) > 1:\n",
    "            raise ValueError(f\"Only one statement is allowed in plan_query, got {len(statements)}\")\n",
    "        ast,_ = statements[0]\n",
    "        statement_node = list(ast.nodes)[0]\n",
    "        node_data = ast.nodes[statement_node]\n",
    "        statement = node_data['type']\n",
    "        value = node_data['val']\n",
    "        if statement != 'query':\n",
    "            raise ValueError(f\"Expected a query statement, got {statement}\")\n",
    "\n",
    "        query_graph,root =  self.engine.plan_query(value)\n",
    "        return query_graph,root\n",
    "\n",
    "    def execute_plan(self,query_graph,root,return_intermediate=False):\n",
    "        return self.engine.execute_plan(query_graph,root,return_intermediate=return_intermediate)\n",
    "        \n",
    "\n",
    "    def export(self,code,display_results=False):\n",
    "        #TODO reconstruct the code for each statement using lark,reconstruct so we can print the query string together with the result\n",
    "        results = []\n",
    "        for clean_ast,statement_lark in self.parse_and_check_semantics(code):\n",
    "            try:\n",
    "                result = execute_statement(clean_ast,self.engine)\n",
    "            except Exception as e:\n",
    "                raise Exception(\n",
    "                    f\"During execution of statement \\n\\\"{reconstruct(statement_lark)}\\n\\\"\"\n",
    "                    f\"the following exception was raised:\\n{e}\\n\"\n",
    "                    ).with_traceback(e.__traceback__)\n",
    "            results.append(result)\n",
    "            if display_results:\n",
    "                self._display_result(result)\n",
    "        return results[-1]\n",
    "\n",
    "    def import_rel(self,name:str,data:Union[str,Path,pd.DataFrame],delim:str = None):\n",
    "        \"\"\"Imports a relation into the current session, either from a dataframe or from a csv file.\"\"\"\n",
    "        if isinstance(data, (Path,str)):\n",
    "            csv_file_name = Path(data)\n",
    "            if not csv_file_name.is_file():\n",
    "                raise IOError(\"csv file does not exist\")\n",
    "            if os.stat(csv_file_name).st_size == 0:\n",
    "                raise IOError(\"csv file is empty\")\n",
    "            data = pd.read_csv(csv_file_name, delimiter=delim)\n",
    "\n",
    "        first_row = list(data.iloc[0,:])\n",
    "        scheme = _infer_relation_schema(first_row)\n",
    "        rel_def = RelationDefinition(name=name,scheme=scheme)\n",
    "        self.engine.set_relation(rel_def)\n",
    "        self.engine.add_facts(name,data)\n",
    "        \n",
    "    def print_rules(self):\n",
    "        rules = list(self.engine.rules_to_ids.keys())\n",
    "        for rule in rules:\n",
    "            print(rule)\n",
    "        return rules\n",
    "    def remove_rule(self,rule:str):\n",
    "        self.engine.del_rule(rule)\n",
    "    def remove_relation(self,relation:str):\n",
    "        self.engine.del_relation(relation)\n",
    "    def clear(self):\n",
    "        self.engine = Engine()\n",
    "\n",
    "    def get_all_functions(self):\n",
    "        return self.engine.ie_functions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X\n",
       "0  Sam"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "    ?GrandParent(X, \"Austin\")\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "res = session.export(commands,display_results=True)\n",
    "assert serialize_df_values(res) == {('Sam',)}\n",
    "\n",
    "# check that rerunning query gives the same result\n",
    "res = session.export('?GrandParent(X, \"Austin\")')\n",
    "assert serialize_df_values(res) == {('Sam',)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(string: str) -> Iterable[int]:\n",
    "        yield (len(string),)\n",
    "\n",
    "sess = Session()\n",
    "sess.register('Length',length,[str],[int])\n",
    "res = sess.export('''\n",
    "    new string(str)\n",
    "    string(\"a\")\n",
    "    string(\"d\")\n",
    "    string(\"a\")\n",
    "    string(\"ab\")\n",
    "    string(\"abc\")\n",
    "    string(\"abcd\")\n",
    "\n",
    "    string_length(Str, Len) <- string(Str), Length(Str) -> (Len)\n",
    "    # ?string_length(Str, Len)\n",
    "''')\n",
    "#TODO from here, add the rest of the examples from the old notebook and start moving the failed ones to tests in the respective passes/execution\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_rewrite import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Str</th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ab</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abcd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Str  Len\n",
       "0     a    1\n",
       "2     d    1\n",
       "5    ab    2\n",
       "6   abc    3\n",
       "7  abcd    4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,root = sess.plan_query(\"?string_length(Str, Len)\")\n",
    "# draw(q)\n",
    "# with checkLogs(name='spannerlib.engine'):\n",
    "res,inter = sess.execute_plan(q,root,return_intermediate=True)\n",
    "assert serialize_df_values(res) == {('a', 1), ('ab', 2), ('abc', 3), ('abcd', 4), ('d', 1)}\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancestor(X,Y) <- parent(X,Y)\n",
      "ancestor(X,Y) <- grandparent(X,Y)\n",
      "ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y)\n",
      "==================================================\n",
      "ancestor(X,Y) <- grandparent(X,Y)\n",
      "ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y)\n"
     ]
    }
   ],
   "source": [
    "# test rule removal\n",
    "\n",
    "sess = Session()\n",
    "_ = sess.export('''\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    parent(\"James\", \"Lucas\")\n",
    "    parent(\"Noah\", \"Benjamin\")\n",
    "    parent(\"Benjamin\", \"Mason\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "''')\n",
    "\n",
    "\n",
    "rules = sess.print_rules()\n",
    "assert rules == ['ancestor(X,Y) <- parent(X,Y)',\n",
    "'ancestor(X,Y) <- grandparent(X,Y)',\n",
    "'ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y)',]\n",
    "\n",
    "sess.remove_rule(\"ancestor(X,Y) <- parent(X,Y)\")\n",
    "print(\"=\"*50)\n",
    "rules = sess.print_rules()\n",
    "assert rules == ['ancestor(X,Y) <- grandparent(X,Y)',\n",
    "'ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y)',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancestor(X,Y) <- parent(X,Y)\n",
      "ancestor(X,Y) <- grandparent(X,Y)\n",
      "ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y)\n"
     ]
    }
   ],
   "source": [
    "# test clearing the engine\n",
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.export(commands)\n",
    "session.print_rules()\n",
    "session.clear()\n",
    "assert session.print_rules() == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jordan</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gale</td>\n",
       "      <td>operating_systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>howard</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>howard</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abigail</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X                  Y\n",
       "0   jordan          chemistry\n",
       "1     gale  operating_systems\n",
       "2   howard          chemistry\n",
       "3   howard            physics\n",
       "0  abigail          chemistry"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing relations from csv\n",
    "session = Session()\n",
    "session.import_rel(name=\"enrolled\",data=\"./sample_data/enrolled.csv\", delim=\",\")\n",
    "commands = \"\"\"\n",
    "enrolled(\"abigail\", \"chemistry\")\n",
    "?enrolled(X,Y)\n",
    "\"\"\"\n",
    "res = session.export(commands)\n",
    "assert serialize_df_values(res) == {('abigail', 'chemistry'),\n",
    " ('gale', 'operating_systems'),\n",
    " ('howard', 'chemistry'),\n",
    " ('howard', 'physics'),\n",
    " ('jordan', 'chemistry')}\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use standard ie functions\n",
    "# # TODO fix this\n",
    "# session = Session()\n",
    "# session.import_rel(name=\"enrolled\",data=\"./sample_data/enrolled.csv\", delim=\",\")\n",
    "# commands = \"\"\"\n",
    "#     enrolled(\"abigail\", \"chemistry\")\n",
    "# gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"\n",
    "\n",
    "# gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "# ?gpa(X,Y)\n",
    "# \"\"\"\n",
    "# x = session.export(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walter</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linus</td>\n",
       "      <td>operating_systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X                  Y\n",
       "0  walter          chemistry\n",
       "1   linus  operating_systems"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing relations from dataframe\n",
    "session = Session()\n",
    "lecturer_df = pd.DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "session.import_rel(\"lecturer\",lecturer_df)\n",
    "commands = \"\"\" \n",
    "?lecturer(X,Y)\n",
    "\"\"\"\n",
    "res = session.export(commands)\n",
    "assert serialize_df_values(res) == {('linus', 'operating_systems'), ('walter', 'chemistry')}\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spannerlib.engine - DEBUG - computing node A with op get_rel and children results [] and data {'rel': 'A', 'rule_id': {0, 2}, 'op': 'get_rel', 'db': DB(A, B, C, D)}\n",
      "spannerlib.engine - DEBUG - node A results after iteration 0 are   col_0 col_1\n",
      "0     1     2\n",
      "spannerlib.engine - DEBUG - setting node A as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 0 with op rename and children results [  col_0 col_1\n",
      "0     1     2] and data {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {0}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 0 results after iteration 0 are    X  Y\n",
      "0  1  2\n",
      "spannerlib.engine - DEBUG - setting node 0 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 1 with op project and children results [   X  Y\n",
      "0  1  2] and data {'op': 'project', 'on': ['X', 'Y'], 'rel': '_C_0', 'rule_id': {0}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 1 results after iteration 0 are    X  Y\n",
      "0  1  2\n",
      "spannerlib.engine - DEBUG - setting node 1 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node C with op union and children results [   X  Y\n",
      "0  1  2] and data {'rel': 'C', 'op': 'union', 'rule_id': {0, 1}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node C results after iteration 0 are    X  Y\n",
      "0  1  2\n",
      "spannerlib.engine - DEBUG - setting node C as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 2 with op rename and children results [   X  Y\n",
      "0  1  2] and data {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {1}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 2 results after iteration 0 are    X  Y\n",
      "0  1  2\n",
      "spannerlib.engine - DEBUG - setting node 2 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 3 with op project and children results [   X  Y\n",
      "0  1  2] and data {'op': 'project', 'on': ['X', 'Y', 'X'], 'rel': '_D_1', 'rule_id': {1}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 3 results after iteration 0 are    X  Y  X\n",
      "0  1  2  1\n",
      "spannerlib.engine - DEBUG - setting node 3 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 16 with op rename and children results [  col_0 col_1\n",
      "0     1     2] and data {'op': 'rename', 'names': [(0, 'X')], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 16 results after iteration 0 are    X col_1\n",
      "0  1     2\n",
      "spannerlib.engine - DEBUG - setting node 16 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 17 with op select and children results [   X col_1\n",
      "0  1     2] and data {'op': 'select', 'theta': Theta(col_1=1), 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 17 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 17 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 18 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1]\n",
      "Index: []] and data {'op': 'project', 'on': ['X'], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 18 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 18 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node B with op get_rel and children results [] and data {'rel': 'B', 'rule_id': {2}, 'op': 'get_rel', 'db': DB(A, B, C, D)}\n",
      "spannerlib.engine - DEBUG - node B results after iteration 0 are   col_0 col_1\n",
      "0     1  3_id\n",
      "spannerlib.engine - DEBUG - setting node B as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 19 with op rename and children results [  col_0 col_1\n",
      "0     1  3_id] and data {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 19 results after iteration 0 are    X     Y\n",
      "0  1  3_id\n",
      "spannerlib.engine - DEBUG - setting node 19 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 12 with op join and children results [Empty DataFrame\n",
      "Columns: [X, col_1]\n",
      "Index: [],    X     Y\n",
      "0  1  3_id] and data {'op': 'join', 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 12 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 12 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 4 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []] and data {'op': 'project', 'on': ['Y'], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 4 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 4 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 5 with op ie_map and children results [Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []] and data {'op': 'ie_map', 'func': <function ID2>, 'rule_id': {2}, 'in_schema': [<class 'str'>], 'out_schema': [<class 'str'>, <class 'str'>], 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 5 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 5 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 6 with op rename and children results [Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []] and data {'op': 'rename', 'names': [(0, 'Y'), (1, 'Z'), (2, 'W')], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 6 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 6 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 7 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []] and data {'op': 'project', 'on': ['Y', 'Z', 'W'], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 7 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 7 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 13 with op join and children results [Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [X, col_1, Y]\n",
      "Index: []] and data {'op': 'join', 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 13 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 13 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 8 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []] and data {'op': 'project', 'on': ['X'], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 8 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 8 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 9 with op ie_map and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []] and data {'op': 'ie_map', 'func': <function ID>, 'rule_id': {2}, 'in_schema': [<class 'str'>], 'out_schema': [<class 'str'>], 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 9 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 9 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 10 with op rename and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []] and data {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 10 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 10 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 11 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []] and data {'op': 'project', 'on': ['X', 'Y'], 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 11 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 11 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 14 with op join and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [X, col_1_x, Y, col_1_y]\n",
      "Index: []] and data {'op': 'join', 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 14 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x_x, Y, col_1_y_x, col_1_x_y, col_1_y_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 14 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node 15 with op project and children results [Empty DataFrame\n",
      "Columns: [X, col_1_x_x, Y, col_1_y_x, col_1_x_y, col_1_y_y]\n",
      "Index: []] and data {'op': 'project', 'on': ['X', 'Y', 'Z'], 'rel': '_D_2', 'rule_id': {2}, 'visited': True}\n",
      "spannerlib.engine - DEBUG - node 15 results after iteration 0 are Empty DataFrame\n",
      "Columns: [X, col_1_x_x, Y, col_1_y_x, col_1_x_y, col_1_y_y]\n",
      "Index: []\n",
      "spannerlib.engine - DEBUG - setting node 15 as final since all children are final\n",
      "spannerlib.engine - DEBUG - computing node D with op union and children results [   X  Y  X\n",
      "0  1  2  1, Empty DataFrame\n",
      "Columns: [X, col_1_x_x, Y, col_1_y_x, col_1_x_y, col_1_y_y]\n",
      "Index: []] and data {'rel': 'D', 'op': 'union', 'rule_id': {1, 2}, 'visited': True}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "During execution of statement \n\"?D(X,Y,Z)\n\"the following exception was raised:\nReindexing only valid with uniquely valued Index objects\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m, in \u001b[0;36mSession.export\u001b[0;34m(self, code, display_results)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_ast\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/micro_passes.py:411\u001b[0m, in \u001b[0;36mexecute_statement\u001b[0;34m(ast, engine)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:249\u001b[0m, in \u001b[0;36mEngine.run_query\u001b[0;34m(self, q, rewrites, return_intermediate)\u001b[0m\n\u001b[1;32m    248\u001b[0m query_graph,root_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan_query(q,rewrites)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_intermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:241\u001b[0m, in \u001b[0;36mEngine.execute_plan\u001b[0;34m(self, query_graph, root_node, return_intermediate)\u001b[0m\n\u001b[1;32m    240\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m--> 241\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_intermediate:\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    292\u001b[0m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m children_results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren_ids\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    292\u001b[0m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m children_results \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m child_id \u001b[38;5;129;01min\u001b[39;00m children_ids]\n\u001b[1;32m    295\u001b[0m all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    292\u001b[0m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m children_results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren_ids\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    292\u001b[0m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m children_results \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m child_id \u001b[38;5;129;01min\u001b[39;00m children_ids]\n\u001b[1;32m    295\u001b[0m all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:303\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    302\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputing node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with op \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and children results \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchildren_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and data \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m current_results \u001b[38;5;241m=\u001b[39m \u001b[43mop_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchildren_results\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mu_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m results_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results_dict[u])\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/ra.py:97\u001b[0m, in \u001b[0;36munion\u001b[0;34m(*dfs, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munion\u001b[39m(\u001b[38;5;241m*\u001b[39mdfs,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/reshape/concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 680\u001b[0m         indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m session\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID2\u001b[39m\u001b[38;5;124m'\u001b[39m,ID2, [\u001b[38;5;28mstr\u001b[39m], [\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;28mstr\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m checkLogs(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspannerlib.engine\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommands\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m res\n",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m, in \u001b[0;36mSession.export\u001b[0;34m(self, code, display_results)\u001b[0m\n\u001b[1;32m     91\u001b[0m     result \u001b[38;5;241m=\u001b[39m execute_statement(clean_ast,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuring execution of statement \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mreconstruct(statement_lark)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following exception was raised:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         )\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     97\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_results:\n",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m, in \u001b[0;36mSession.export\u001b[0;34m(self, code, display_results)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clean_ast,statement_lark \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_and_check_semantics(code):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_ast\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuring execution of statement \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mreconstruct(statement_lark)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following exception was raised:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/micro_passes.py:411\u001b[0m, in \u001b[0;36mexecute_statement\u001b[0;34m(ast, engine)\u001b[0m\n\u001b[1;32m    409\u001b[0m     engine\u001b[38;5;241m.\u001b[39madd_rule(value)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown statement type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:249\u001b[0m, in \u001b[0;36mEngine.run_query\u001b[0;34m(self, q, rewrites, return_intermediate)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_query\u001b[39m(\u001b[38;5;28mself\u001b[39m,q:Relation,rewrites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,return_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    248\u001b[0m     query_graph,root_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan_query(q,rewrites)\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_intermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:241\u001b[0m, in \u001b[0;36mEngine.execute_plan\u001b[0;34m(self, query_graph, root_node, return_intermediate)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_plan\u001b[39m(\u001b[38;5;28mself\u001b[39m,query_graph,root_node,return_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     results_dict \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m--> 241\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_intermediate:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m results,results_dict\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    292\u001b[0m     u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     children_results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren_ids\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m     all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n\u001b[1;32m    300\u001b[0m op_code \u001b[38;5;241m=\u001b[39m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    292\u001b[0m     u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     children_results \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m child_id \u001b[38;5;129;01min\u001b[39;00m children_ids]\n\u001b[1;32m    295\u001b[0m     all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n\u001b[1;32m    300\u001b[0m op_code \u001b[38;5;241m=\u001b[39m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    292\u001b[0m     u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     children_results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren_ids\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m     all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n\u001b[1;32m    300\u001b[0m op_code \u001b[38;5;241m=\u001b[39m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    292\u001b[0m     u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     children_results \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m child_id \u001b[38;5;129;01min\u001b[39;00m children_ids]\n\u001b[1;32m    295\u001b[0m     all_children_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(child_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m child_data \u001b[38;5;129;01min\u001b[39;00m children_data)\n\u001b[1;32m    300\u001b[0m op_code \u001b[38;5;241m=\u001b[39m u_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/engine.py:303\u001b[0m, in \u001b[0;36mcompute_node\u001b[0;34m(G, u, results_dict)\u001b[0m\n\u001b[1;32m    301\u001b[0m op_func \u001b[38;5;241m=\u001b[39m op_to_func[op_code]\n\u001b[1;32m    302\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputing node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with op \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and children results \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchildren_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and data \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m current_results \u001b[38;5;241m=\u001b[39m \u001b[43mop_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchildren_results\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mu_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m results_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results_dict[u])\n\u001b[1;32m    305\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m results after iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/tdk/spannerlib/spannerlib/ra.py:97\u001b[0m, in \u001b[0;36munion\u001b[0;34m(*dfs, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munion\u001b[39m(\u001b[38;5;241m*\u001b[39mdfs,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/reshape/concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/span/lib/python3.11/site-packages/pandas/core/indexes/base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mException\u001b[0m: During execution of statement \n\"?D(X,Y,Z)\n\"the following exception was raised:\nReindexing only valid with uniquely valued Index objects\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "commands = \"\"\"\n",
    "        new A(str, str)\n",
    "        new B(str, str)\n",
    "        A(\"1\", \"2\")\n",
    "        B(\"1\", \"3_id\")\n",
    "        C(X, Y) <- A(X, Y)\n",
    "        D(X, Y, X) <- C(X, Y)\n",
    "        D(X, Y, Z) <- A(X, \"1\"), B(X, Y), ID(X) -> (Y), ID2(Y)->(Z,W)\n",
    "        ?D(X, Y, Z)\n",
    "    \"\"\"\n",
    "\n",
    "def ID(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id'\n",
    "\n",
    "def ID2(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id2_z',f'{string}_id2_w'\n",
    "\n",
    "session = Session()\n",
    "session.register('ID',ID, [str], [str])\n",
    "session.register('ID2',ID2, [str], [str,str])\n",
    "with checkLogs(name='spannerlib.engine'):\n",
    "    res = session.export(commands)\n",
    "#TODO form here\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add cases\n",
    "# a rule with an ie function bound by constants\n",
    "# a rule that returns ture\n",
    "# a rule that returns false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
