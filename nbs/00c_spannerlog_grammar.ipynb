{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> This module contains the spannerlog grammar plus utilities that will help the developer assert that the ast he received matches the grammar\n",
    "that he expects to work with.\n",
    "\n",
    ">These asserts are useful as a general safety check, and also for finding places in the code that need to change\n",
    "should the spannerlog grammar be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import no_type_check, Set, Sequence, Any, Callable\n",
    "#from spannerlib.graphs import GraphBase, EvalState\n",
    "from typing import Sequence, Dict\n",
    "from lark import Lark,Token, Tree, Transformer\n",
    "import yaml\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from graph_rewrite import rewrite,rewrite_iter,draw\n",
    "\n",
    "from spannerlib.utils import checkLogs, uniq_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "SpannerlogGrammar = r\"\"\"\n",
    "start: (_NEWLINE)* (statement (_NEWLINE)+)* (statement)?\n",
    "\n",
    "?statement: relation_declaration\n",
    "          | add_fact\n",
    "          | remove_fact\n",
    "          | rule\n",
    "          | query\n",
    "          | assignment\n",
    "\n",
    "assignment: var_name \"=\" string\n",
    "          | var_name \"=\" span\n",
    "          | var_name \"=\" int\n",
    "          | var_name \"=\" var_name\n",
    "          | var_name \"=\" \"read\" \"(\" string \")\" -> read_assignment\n",
    "          | var_name \"=\" \"read\" \"(\" var_name \")\" -> read_assignment\n",
    "\n",
    "relation_declaration: \"new\" _SEPARATOR relation_name \"(\" decl_term_list \")\"\n",
    "\n",
    "decl_term_list: decl_term (\",\" decl_term)*\n",
    "\n",
    "?decl_term: \"str\" -> decl_string\n",
    "          | \"span\" -> decl_span\n",
    "          | \"int\" -> decl_int\n",
    "\n",
    "rule: rule_head \"<-\" rule_body_relation_list\n",
    "\n",
    "rule_head: relation_name \"(\" free_var_name_list \")\"\n",
    "\n",
    "rule_body_relation_list: rule_body_relation (\",\" rule_body_relation)*\n",
    "\n",
    "?rule_body_relation: relation\n",
    "                   | ie_relation\n",
    "\n",
    "relation: relation_name \"(\" term_list \")\"\n",
    "\n",
    "ie_relation: relation_name \"(\" term_list \")\" \"->\" \"(\" term_list \")\"\n",
    "\n",
    "query: \"?\" relation_name \"(\" term_list \")\"\n",
    "\n",
    "term_list: term (\",\" term)*\n",
    "\n",
    "?term: const_term\n",
    "     | free_var_name\n",
    "\n",
    "add_fact: relation_name \"(\" const_term_list \")\"\n",
    "        | relation_name \"(\" const_term_list \")\" \"<-\" _TRUE\n",
    "\n",
    "remove_fact: relation_name \"(\" const_term_list \")\" \"<-\" _FALSE\n",
    "\n",
    "const_term_list: const_term (\",\" const_term)*\n",
    "\n",
    "?const_term: span\n",
    "          | string\n",
    "          | int\n",
    "          | var_name\n",
    "\n",
    "span: \"[\" int \",\" int \")\"\n",
    "\n",
    "int: INT -> integer\n",
    "\n",
    "string: STRING\n",
    "\n",
    "free_var_name_list: free_var_name (\",\" free_var_name)*\n",
    "\n",
    "relation_name: LOWER_CASE_NAME\n",
    "             | UPPER_CASE_NAME\n",
    "\n",
    "var_name: LOWER_CASE_NAME\n",
    "\n",
    "free_var_name : UPPER_CASE_NAME\n",
    "\n",
    "_TRUE: \"True\"\n",
    "_FALSE: \"False\"\n",
    "\n",
    "LOWER_CASE_NAME: (\"_\"|LCASE_LETTER) (\"_\"|LETTER|DIGIT)*\n",
    "UPPER_CASE_NAME: UCASE_LETTER (\"_\"|LETTER|DIGIT)*\n",
    "\n",
    "_COMMENT: \"#\" /[^\\n]*/\n",
    "\n",
    "_SEPARATOR: (_WS_INLINE | _LINE_OVERFLOW_ESCAPE)+\n",
    "\n",
    "STRING: \"\\\"\" (_STRING_INTERNAL (_LINE_OVERFLOW_ESCAPE)+)* _STRING_INTERNAL \"\\\"\"\n",
    "\n",
    "_LINE_OVERFLOW_ESCAPE: \"\\\\\" _NEWLINE\n",
    "\n",
    "_NEWLINE: CR? LF\n",
    "CR : /\\r/\n",
    "LF : /\\n/\n",
    "\n",
    "LCASE_LETTER: \"a\"..\"z\"\n",
    "UCASE_LETTER: \"A\"..\"Z\"\n",
    "LETTER: UCASE_LETTER | LCASE_LETTER\n",
    "DIGIT: \"0\"..\"9\"\n",
    "_WS_INLINE: (\" \"|/\\t/)+\n",
    "%ignore _WS_INLINE\n",
    "_STRING_INTERNAL: /.*?/ /(?<!\\\\)(\\\\\\\\)*?/\n",
    "INT: DIGIT+\n",
    "%ignore _LINE_OVERFLOW_ESCAPE\n",
    "%ignore _COMMENT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpannerlogParser = Lark(SpannerlogGrammar, parser='lalr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_spannerlog(spannerlog_code: str,start='start',as_string=False):\n",
    "    parser = Lark(SpannerlogGrammar, parser='lalr',start=start)\n",
    "    tree = parser.parse(spannerlog_code)\n",
    "    if as_string:\n",
    "        return tree.pretty()\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing utils\n",
    "def tree_to_json(node):\n",
    "    logger.debug(f'casting the following lark node to json: {node}')\n",
    "    if isinstance(node, Token):\n",
    "        #return {'type': node.type, 'value': node.value}\n",
    "        return node.value\n",
    "    if isinstance(node, Tree):\n",
    "        type = node.data\n",
    "    elif hasattr(node, 'type'):\n",
    "        type = node.type.value\n",
    "    else:\n",
    "        type = node.type\n",
    "    if len(node.children) == 1:\n",
    "        return {type: tree_to_json(node.children[0])}\n",
    "    else:\n",
    "        return {type: [tree_to_json(child) for child in node.children]}\n",
    "\n",
    "def tree_to_yaml(node):\n",
    "    return yaml.dump(tree_to_json(node))\n",
    "\n",
    "def assert_grammar(start,text,expected_yaml):\n",
    "    tree = parse_spannerlog(text,start=start)\n",
    "    expected = yaml.safe_load(expected_yaml)\n",
    "    gotten = tree_to_json(tree)\n",
    "    assert gotten == expected, f'got unexpected parse results\\n{tree_to_yaml(tree)}\\nexpected\\n{expected_yaml}'\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree= assert_grammar(\n",
    "      'rule',\n",
    "      'head(X,Y,W)<-body1(X,Z),body2(Z,Y),ie_1(X,Y,Z)->(W)',\n",
    "    '''\n",
    "  rule:\n",
    "  - rule_head:\n",
    "    - relation_name: head\n",
    "    - free_var_name_list:\n",
    "      - free_var_name: X\n",
    "      - free_var_name: Y\n",
    "      - free_var_name: W\n",
    "  - rule_body_relation_list:\n",
    "    - relation:\n",
    "      - relation_name: body1\n",
    "      - term_list:\n",
    "        - free_var_name: X\n",
    "        - free_var_name: Z\n",
    "    - relation:\n",
    "      - relation_name: body2\n",
    "      - term_list:\n",
    "        - free_var_name: Z\n",
    "        - free_var_name: Y\n",
    "    - ie_relation:\n",
    "      - relation_name: ie_1\n",
    "      - term_list:\n",
    "        - free_var_name: X\n",
    "        - free_var_name: Y\n",
    "        - free_var_name: Z\n",
    "      - term_list:\n",
    "          free_var_name: W\n",
    "  ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule\n",
      "  rule_head\n",
      "    relation_name\thead\n",
      "    free_var_name_list\n",
      "      free_var_name\tX\n",
      "      free_var_name\tY\n",
      "      free_var_name\tW\n",
      "  rule_body_relation_list\n",
      "    relation\n",
      "      relation_name\tbody1\n",
      "      term_list\n",
      "        free_var_name\tX\n",
      "        free_var_name\tZ\n",
      "    relation\n",
      "      relation_name\tbody2\n",
      "      term_list\n",
      "        free_var_name\tZ\n",
      "        free_var_name\tY\n",
      "    ie_relation\n",
      "      relation_name\tie_1\n",
      "      term_list\n",
      "        free_var_name\tX\n",
      "        free_var_name\tY\n",
      "        free_var_name\tZ\n",
      "      term_list\n",
      "        free_var_name\tW\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rule': [{'rule_head': [{'relation_name': 'head'},\n",
       "    {'free_var_name_list': [{'free_var_name': 'X'},\n",
       "      {'free_var_name': 'Y'},\n",
       "      {'free_var_name': 'W'}]}]},\n",
       "  {'rule_body_relation_list': [{'relation': [{'relation_name': 'body1'},\n",
       "      {'term_list': [{'free_var_name': 'X'}, {'free_var_name': 'Z'}]}]},\n",
       "    {'relation': [{'relation_name': 'body2'},\n",
       "      {'term_list': [{'free_var_name': 'Z'}, {'free_var_name': 'Y'}]}]},\n",
       "    {'ie_relation': [{'relation_name': 'ie_1'},\n",
       "      {'term_list': [{'free_var_name': 'X'},\n",
       "        {'free_var_name': 'Y'},\n",
       "        {'free_var_name': 'Z'}]},\n",
       "      {'term_list': {'free_var_name': 'W'}}]}]}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_to_json(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rule'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import networkx as nx\n",
    "def lark_to_nx_aux(tree,node_id,g):\n",
    "    if isinstance(tree, Token):\n",
    "        g.add_node(node_id,val=tree.value,type=tree.type)\n",
    "    elif isinstance(tree, Tree):\n",
    "        g.add_node(node_id,val=tree.data,type=tree.type)\n",
    "        for i,child in enumerate(tree.children):\n",
    "            child_id = uniq_id()\n",
    "            g.add_edge(node_id,child_id)\n",
    "            lark_to_nx_aux(child,child_id,g)\n",
    "            \n",
    "\n",
    "\n",
    "def lark_to_nx(t):\n",
    "    g = nx.DiGraph()\n",
    "    lark_to_nx_aux(t,uniq_id(),g)\n",
    "    return g\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test it works\n",
    "\n",
    "g= lark_to_nx(tree)\n",
    "draw(g,direction='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring Correct Structure in spannerlog's AST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When dealing with spannerlog's Abstract Syntax Tree (AST), it's crucial to ensure that the node structure conforms to the expected grammar. The `spannerlog_expected_children_names_lists` data structure maps every node type in the AST to its expected list(s) of children node names. Below is a comprehensive guide on how to safely modify the spannerlog grammar and update the code to accommodate the changes.\n",
    "\n",
    "## Expected Children Structure for AST Nodes\n",
    "\n",
    "For each node in the AST, `spannerlog_expected_children_names_lists` contains a list of its expected children node names. Each node type maps to a list of lists, where each internal list represents a valid set of children node names for that particular node type.\n",
    "\n",
    "::: {.callout-note}\n",
    "Some nodes in spannerlog can have variable-length children lists (e.g., `term_list`). Such nodes are not included in `spannerlog_expected_children_names_lists`.\n",
    ":::\n",
    "---\n",
    "\n",
    "## Strategy for Modifying spannerlog Grammar\n",
    "\n",
    "### 1. Assert Original Node Structure\n",
    "\n",
    "Before any modifications, assert that each AST node retains its original, expected structure using `spannerlog_expected_children_names_lists`.\n",
    "\n",
    "```python\n",
    "# Example usage\n",
    "lark_passes_utils.assert_expected_node_structure(node, spannerlog_expected_children_names_lists)\n",
    "```\n",
    "\n",
    "### 2. Modify the Grammar\n",
    "\n",
    "Go ahead and make the changes to the spannerlog grammar file.\n",
    "\n",
    "### 3. Run a Varied spannerlog Program\n",
    "\n",
    "Execute a spannerlog program that uses a variety of different statements to ensure broad test coverage. Observe where your program crashes due to failed node structure assertions. Modify the code to work with the new grammar and temporarily comment out the node structure assertion(s).\n",
    "\n",
    "Repeat this step until no crashes occur.\n",
    "\n",
    "```python\n",
    "# Temporarily comment this line\n",
    "# lark_passes_utils.assert_expected_node_structure(node, spannerlog_expected_children_names_lists)\n",
    "```\n",
    "\n",
    "### 4. Uncomment the Assertion\n",
    "\n",
    "Once you are sure the program doesn't crash with the new grammar, uncomment the node structure assertion(s).\n",
    "\n",
    "```python\n",
    "# Uncomment this line\n",
    "lark_passes_utils.assert_expected_node_structure(node, spannerlog_expected_children_names_lists)\n",
    "```\n",
    "\n",
    "### 5. Update `spannerlog_expected_children_names_lists`\n",
    "\n",
    "Finally, update the `spannerlog_expected_children_names_lists` data structure to reflect your new grammar.\n",
    "\n",
    "---\n",
    "\n",
    "By following this strategy, you ensure that the new grammar is functional and that the code that interacts with the AST is updated to accommodate the changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "spannerlog_expected_children_names_lists: Dict[str, Sequence] = {\n",
    "\n",
    "    'assignment': [\n",
    "        ['var_name', 'string'],\n",
    "        ['var_name', 'integer'],\n",
    "        ['var_name', 'span'],\n",
    "        ['var_name', 'var_name'],\n",
    "    ],\n",
    "\n",
    "    'read_assignment': [\n",
    "        ['var_name', 'string'],\n",
    "        ['var_name', 'var_name']\n",
    "    ],\n",
    "\n",
    "    'relation_declaration': [['relation_name', 'decl_term_list']],\n",
    "\n",
    "    'rule': [['rule_head', 'rule_body_relation_list']],\n",
    "\n",
    "    'rule_head': [['relation_name', 'free_var_name_list']],\n",
    "\n",
    "    'relation': [['relation_name', 'term_list']],\n",
    "\n",
    "    'ie_relation': [['relation_name', 'term_list', 'term_list']],\n",
    "\n",
    "    'query': [['relation_name', 'term_list']],\n",
    "\n",
    "    'add_fact': [['relation_name', 'const_term_list']],\n",
    "\n",
    "    'remove_fact': [['relation_name', 'const_term_list']],\n",
    "\n",
    "    'span': [\n",
    "        ['integer', 'integer'],\n",
    "        []  # allow empty list to support spans that were converted a datatypes.Span instance\n",
    "    ],\n",
    "\n",
    "    'integer': [[]],\n",
    "\n",
    "    'string': [[]],\n",
    "\n",
    "    'relation_name': [[]],\n",
    "\n",
    "    'var_name': [[]],\n",
    "\n",
    "    'free_var_name': [[]]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
