{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using native Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When rgxlog is loaded, a default session (`rgxlog.magic_session`) is created behind the scenes. This is the session that %%rgxlog uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a session manually enables one to dynamically generate queries, facts, and rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rgxlog\n",
    "session = rgxlog.magic_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.run_commands('''\n",
    "    new uncle(str, str)\n",
    "    uncle(\"benjen\", \"jon\")''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'uncle(\"ned\", Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'uncle(\"robb\", Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'uncle(\"benjen\", Y)':\n",
      "  Y\n",
      "-----\n",
      " jon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for maybe_uncle in ['ned', 'robb', 'benjen']:\n",
    "    result = session.run_commands(f'?uncle(\"{maybe_uncle}\",Y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the session of the magic cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where you want to work with a custom session, but still make use of the magic system, you can overide the session used by the magic system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rgxlog  # default session starts here\n",
    "from rgxlog import Session\n",
    "\n",
    "another_session=Session()\n",
    "old_magic_session = rgxlog.magic_session\n",
    "rgxlog.magic_session = another_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'uncle(X, Y)':\n",
      "  X  |  Y\n",
      "-----+------\n",
      " bob | greg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "# we're now using the new session\n",
    "new uncle(str, str)\n",
    "uncle(\"bob\", \"greg\")\n",
    "?uncle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to the old session\n",
    "rgxlog.magic_session = old_magic_session\n",
    "%rgxlog uncle(\"jim\", \"dwight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: uncle(str, str)\n",
      "    (1) (computed) add_fact: uncle(\"benjen\", \"jon\")\n",
      "    (2) (computed) query: uncle(\"ned\", Y)\n",
      "    (3) (computed) query: uncle(\"robb\", Y)\n",
      "    (4) (computed) query: uncle(\"benjen\", Y)\n",
      "    (5) (computed) add_fact: uncle(\"jim\", \"dwight\")\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: uncle(str, str)\n",
      "    (1) (computed) add_fact: uncle(\"bob\", \"greg\")\n",
      "    (2) (computed) query: uncle(X, Y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rgxlog.magic_session._parse_graph)\n",
    "print(another_session._parse_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing magics with dynamic session calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the GPA example from the introductory tutorial.\n",
    "What if we want to have multiple rules each looking for GPAs of students in different classes.\n",
    "We wouldnt want to manually write a rule for every single subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write our data manually. In the future we would be able to import it from csvs/dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%rgxlog\n",
    "new lecturer(str, str)\n",
    "lecturer(\"walter\", \"chemistry\")\n",
    "lecturer(\"linus\", \"operation_systems\")\n",
    "lecturer(\"rick\", \"physics\")\n",
    "\n",
    "new enrolled(str, str)\n",
    "enrolled(\"abigail\", \"chemistry\")\n",
    "enrolled(\"abigail\", \"operation_systems\")\n",
    "enrolled(\"jordan\", \"chemistry\")\n",
    "enrolled(\"gale\", \"operation_systems\")\n",
    "enrolled(\"howard\", \"chemistry\")\n",
    "enrolled(\"howard\", \"physics\")\n",
    "\n",
    "\n",
    "\n",
    "gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa(X, Y)':\n",
      "    X    |   Y\n",
      "---------+-----\n",
      " abigail | 100\n",
      " jordan  |  80\n",
      "  gale   |  79\n",
      " howard  |  60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "\n",
    "gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "?gpa(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the rules using a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    gpa_of_chemistry_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"chemistry\")\n",
      "    \n",
      "\n",
      "    gpa_of_physics_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"physics\")\n",
      "    \n",
      "\n",
      "    gpa_of_operation_systems_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"operation_systems\")\n",
      "    \n",
      "\n",
      "    gpa_of_magic_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"magic\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "subjects = [\n",
    "    \"chemistry\",\n",
    "    \"physics\",\n",
    "    \"operation_systems\",\n",
    "    \"magic\",\n",
    "]\n",
    "\n",
    "for subject in subjects:\n",
    "    rule = f\"\"\"\n",
    "    gpa_of_{subject}_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"{subject}\")\n",
    "    \"\"\"\n",
    "    session.run_commands(rule)\n",
    "    print(rule)  # we print the rule here to show you what strings are sent to the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can use the dynamically defined rules in a magic cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa_of_operation_systems_students(X, Y)':\n",
      "    X    |   Y\n",
      "---------+-----\n",
      " abigail | 100\n",
      "  gale   |  79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?gpa_of_operation_systems_students(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also query dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa_of_chemistry_students(Student, Grade)':\n",
      "  Student  |   Grade\n",
      "-----------+---------\n",
      "  abigail  |     100\n",
      "  jordan   |      80\n",
      "  howard   |      60\n",
      "\n",
      "printing results for query 'gpa_of_physics_students(Student, Grade)':\n",
      "  Student  |   Grade\n",
      "-----------+---------\n",
      "  howard   |      60\n",
      "\n",
      "printing results for query 'gpa_of_operation_systems_students(Student, Grade)':\n",
      "  Student  |   Grade\n",
      "-----------+---------\n",
      "  abigail  |     100\n",
      "   gale    |      79\n",
      "\n",
      "printing results for query 'gpa_of_magic_students(Student, Grade)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjects = [\n",
    "    \"chemistry\",\n",
    "    \"physics\",\n",
    "    \"operation_systems\",\n",
    "    \"magic\",\n",
    "]\n",
    "\n",
    "for subject in subjects:\n",
    "    query = f\"\"\"\n",
    "    ?gpa_of_{subject}_students(Student, Grade)\n",
    "    \"\"\"\n",
    "    session.run_commands(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the result of a query in python and using the result in a new query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can add `format_results=True` to `run_statements` to get the output as one of the following:\n",
    "1. `[]`, if the result is false,\n",
    "2. `[tuple()]`, if the result if true (the tuple is empty), or\n",
    "3. `pandas.DataFrame`, otherwise-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'buddies(First, Second)':\n",
      "  First  |  Second\n",
      "---------+----------\n",
      "   bob   |   greg\n",
      "  lenny  |  homer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = session.run_commands(f'''\n",
    "    new friends(str, str, str)\n",
    "    friends(\"bob\", \"greg\", \"clyde\")\n",
    "    friends(\"steven\", \"benny\", \"horace\")\n",
    "    friends(\"lenny\", \"homer\", \"toby\")\n",
    "    ?friends(X,Y,Z)''', print_results=False, format_results=True)\n",
    "\n",
    "# now we'll showcase processing the result with native python...\n",
    "# lets filter our tuples with some predicate:\n",
    "res = results[0].values.tolist()\n",
    "filtered = tuple(filter(lambda friends: 'bob' in friends or 'lenny' in friends, res))\n",
    "\n",
    "# and feed the matching tuples into a new query:\n",
    "session.run_commands('new buddies(str, str)')\n",
    "\n",
    "for first, second, _ in filtered:\n",
    "    session.run_commands(f'buddies(\"{first}\", \"{second}\")')\n",
    "\n",
    "result = session.run_commands(\"?buddies(First, Second)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a relation from a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, non-boolean query results are saved as a `DataFrame`.\n",
    "A relation can also be imported from a `DataFrame`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'ogres(X, Y)':\n",
      "   X   |    Y\n",
      "-------+------\n",
      " Shrek |   42\n",
      " Fiona | 1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame([[\"Shrek\",42], [\"Fiona\", 1337]], columns=[\"name\", \"number\"])\n",
    "session.import_relation_from_df(df, relation_name=\"ogres\")\n",
    "%rgxlog ?ogres(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Information Extractors Dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sometimes we can save time by creating rgxlog code dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: uncle_aunt(A,Z) <- sibling(A,B), parent(B,Z)\n",
      "printing results for query 'uncle_aunt(X, Y)':\n",
      "  X  |   Y\n",
      "-----+--------\n",
      " dio | george\n",
      "\n",
      "running: grandparent(A,Z) <- parent(A,B), parent(B,Z)\n",
      "printing results for query 'grandparent(X, Y)':\n",
      "    X     |   Y\n",
      "----------+--------\n",
      " jonathan | joseph\n",
      "  george  |  holy\n",
      "  joseph  | jotaro\n",
      "\n",
      "running: great_aunt_uncle(A,Z) <- sibling(A,B), parent(B,C), parent(C,Z)\n",
      "printing results for query 'great_aunt_uncle(X, Y)':\n",
      "  X  |   Y\n",
      "-----+--------\n",
      " dio | joseph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rgxlog import magic_session\n",
    "\n",
    "%rgxlog new sibling(str, str)\n",
    "%rgxlog new parent(str, str)\n",
    "%rgxlog parent(\"jonathan\", \"george\")\n",
    "%rgxlog parent(\"george\", \"joseph\")\n",
    "%rgxlog parent(\"joseph\", \"holy\")\n",
    "%rgxlog parent(\"holy\", \"jotaro\")\n",
    "%rgxlog sibling(\"dio\", \"jonathan\")\n",
    "\n",
    "a = [\"parent\", \"uncle_aunt\", \"grandparent\", \"sibling\"]\n",
    "d = {\"uncle_aunt\": [\"sibling\", \"parent\"], \"grandparent\": [\"parent\", \"parent\"], \"great_aunt_uncle\": [\"sibling\", \"parent\", \"parent\"]}\n",
    "\n",
    "for key, steps in d.items():\n",
    "    # add the start of the rule\n",
    "    result = key + \"(A,Z) <- \"\n",
    "    for num, step in enumerate(steps):\n",
    "        # for every step in the list, add the condition: step(letter, next letter).\n",
    "        #  the first letter is always `A`, and the last is always `Z`\n",
    "        curr_letter = chr(num + ord(\"A\"))\n",
    "        result += step + \"(\" + curr_letter + \",\"\n",
    "        if (num == len(steps) - 1):\n",
    "            result += \"Z)\"\n",
    "        else:\n",
    "            result += chr(1 + ord(curr_letter)) + \"), \"\n",
    "    print(\"running:\", result)\n",
    "    magic_session.run_commands(result)\n",
    "    magic_session.run_commands(f\"?{key}(X,Y)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Optimization Passes to the Pass Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading this section, we recommend to go over [detailed readme file](long_readme.md) in order to undrestand how passes work.\n",
    "\n",
    "There are three kind of optimization passes:\n",
    "1. The first one, manipulates rules before they are added to the `term graph`.\n",
    "2. The second one, manipulates the structure of the `term graph`.\n",
    "    \n",
    "In this section, we will implement two simple optimization passes one of each kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Manipulation Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kind of optimization travrse the `parse_graph` and rules that weren't added to the `term graph`.\n",
    "Then, they update each rule - by modyfieng it's body relations list.\n",
    "\n",
    "Here are some example of possible optimization passes of this kind:\n",
    "1. optimization that removes duplicated relations from a rule.\n",
    "   i.e., the rule `A(X) <- B(X), C(X), B(X)` contains the relation `B(X)` twice.\n",
    "   the optimization will transform the rule into `A(X) <- B(X), C(X)`.\n",
    "   \n",
    "2. optimization that removes useless relations from a rule.\n",
    "   i.e., the rule `A(X) <- B(X), C(Y)` contains the useless relation `C(Y)`.\n",
    "   the optimization will transform the rule into `A(X) <- B(X)`.\n",
    "   \n",
    "We will demonsrate how to implement the second example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgxlog.engine.utils.general_utils import fixed_point  # gets intial value, step function and distance function; computes a fixed point.\n",
    "from rgxlog.engine.utils.general_utils import get_output_free_var_names # returns the free vars of the realtion (if it's ie relation it returns the output free vars)\n",
    "from rgxlog.engine.utils.general_utils import get_input_free_var_names # returns input free vars of ie relation (if it's regulare relation returns empty set)\n",
    "\n",
    "\n",
    "\n",
    "# first, lets implement the logic that removes useless relations from a rule\n",
    "def remove_useless_relations(rule):\n",
    "        \"\"\"\n",
    "        Finds redundant relations and removes them from the rule.\n",
    "        \n",
    "        @param rule: a rule.\n",
    "        \"\"\"\n",
    "        # holds free vars that are essential to compute to rule\n",
    "        relevant_free_vars = set(rule.head_relation.get_term_list())  \n",
    "\n",
    "        # relation without free vars are always relevant (we use them as predicates)\n",
    "        initial_useless_relations_and_types = [(rel, rel_type) for rel, rel_type in zip(rule.body_relation_list, rule.body_relation_type_list)\n",
    "                                               if len(get_output_free_var_names(rel)) != 0]\n",
    "\n",
    "        def step_function(current_useless_relations_and_types):\n",
    "            \"\"\"\n",
    "            Used by fixed pont algorithm.\n",
    "\n",
    "            @param current_useless_relations_and_types: current useless relations and their types\n",
    "            @return: useless relations after considering the new relevant free vars.\n",
    "            \"\"\"\n",
    "\n",
    "            next_useless_relations_and_types = []\n",
    "            for relation, rel_type in current_useless_relations_and_types:\n",
    "                term_list = get_output_free_var_names(relation)\n",
    "                if len(relevant_free_vars.intersection(term_list)) == 0:\n",
    "                    next_useless_relations_and_types.append((relation, rel_type))\n",
    "                else:\n",
    "                    # if relation contains essential free var than all it's free vars are essential\n",
    "                    relevant_free_vars.update(term_list)\n",
    "                    relevant_free_vars.update(get_input_free_var_names(relation))\n",
    "\n",
    "            return next_useless_relations_and_types\n",
    "\n",
    "        useless_relations_and_types = fixed_point(start=initial_useless_relations_and_types, step=step_function, distance=lambda x, y: int(len(x) != len(y)))\n",
    "        \n",
    "        # this part filters the useless relation from the rule\n",
    "        relevant_relations_and_types = set(zip(rule.body_relation_list, rule.body_relation_type_list)).difference(useless_relations_and_types)\n",
    "        new_body_relation_list, new_body_relation_type_list = zip(*relevant_relations_and_types)\n",
    "        rule.body_relation_list = list(new_body_relation_list)\n",
    "        rule.body_relation_type_list = list(new_body_relation_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgxlog.engine.state.graphs import GraphBase, EvalState, STATE, TYPE, VALUE\n",
    "from rgxlog.engine.utils.passes_utils import ParseNodeType\n",
    "\n",
    "# now we'll implement a function that traverses the parse graph and finds rule that weren't added to the term graph yet\n",
    "# note: this function is already implemented in the passes_utils file, we re-implement it here in order to show how to traverse the parse grpah.\n",
    "def get_new_rule_nodes(parse_graph: GraphBase):\n",
    "    \"\"\"\n",
    "    Finds all rules that weren't added to the term graph yet.\n",
    "    \"\"\"\n",
    "\n",
    "    node_ids = parse_graph.post_order_dfs()  # get all nodes inside the parse graph\n",
    "    rule_nodes: List = list()\n",
    "\n",
    "    for node_id in node_ids:\n",
    "        term_attrs = parse_graph.get_node_attributes(node_id)\n",
    "\n",
    "        # the term is not computed, get its type and compute it accordingly\n",
    "        term_type = term_attrs[TYPE]\n",
    "\n",
    "        # make sure that the rule wasn't adde to term graph before\n",
    "        if term_type == ParseNodeType.RULE and term_attrs[STATE] == EvalState.NOT_COMPUTED:\n",
    "            rule_nodes.append(node_id)\n",
    "\n",
    "    return rule_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgxlog.engine.passes.lark_passes import GenericPass\n",
    "    \n",
    "\n",
    "# finally, the implemntation of the optimization pass\n",
    "class RemoveUselessRelationsFromRule(GenericPass):\n",
    "    \"\"\"\n",
    "    This pass removes duplicated relations from a rule.\n",
    "    For example, the rule A(X) <- B(X), C(Y) contains a redundant relation (C(Y)).\n",
    "    After this pass the rule will be A(X) <- B(X).\n",
    "\n",
    "    @note: in the rule A(X) <- B(X, Y), C(Y); C(Y) is not redundant!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.parse_graph: GraphBase = kwargs[\"parse_graph\"]\n",
    "            \n",
    "    def run_pass(self, **kwargs):\n",
    "        rules = get_new_rule_nodes(self.parse_graph)\n",
    "        for rule_node_id in rules:\n",
    "            rule_node = self.parse_graph[rule_node_id]\n",
    "            rule = rule_node[VALUE]\n",
    "            remove_useless_relations(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add this optimization into the pass stack you shold do the follwing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass stack before:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToComputationTermGraph\n",
      "\n",
      "Pass stack after:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tRemoveUselessRelationsFromRule\n",
      "\tAddRulesToComputationTermGraph\n"
     ]
    }
   ],
   "source": [
    "def print_pass_stack(pass_stack):\n",
    "    \"\"\"prints pass stack in a nice format\"\"\"\n",
    "    \n",
    "    for pass_ in pass_stack:\n",
    "        print(\"\\t\" + pass_.__name__)\n",
    "        \n",
    "magic_session = Session()  # reset the magic session\n",
    "\n",
    "original_pass_stack = magic_session.get_pass_stack()  # save the original pass stack\n",
    "\n",
    "new_pass_stack = original_pass_stack.copy()\n",
    "term_graph_pass = new_pass_stack.pop()  # remove last pass - adds rules to term graph\n",
    "new_pass_stack.extend([RemoveUselessRelationsFromRule, term_graph_pass])\n",
    "\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(f\"Pass stack before:\")\n",
    "print_pass_stack(original_pass_stack)\n",
    "\n",
    "print(\"\\nPass stack after:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the affat of this pass on the pars graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse graph of unmodified pass stack:\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X), Bad(Y)\n",
      "\n",
      "\n",
      "Parse graph of pass stack with the optimizaion pass:\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new Good(int)\n",
    "new Bad(int)\n",
    "\n",
    "Example(X) <- Good(X), Bad(Y)\n",
    "\"\"\"\n",
    "\n",
    "def run_first_experiment(session):\n",
    "    \"\"\"runs the command and print the parse graph\"\"\"\n",
    "    session.run_commands(commands)\n",
    "    print(session._parse_graph)\n",
    "    \n",
    "\n",
    "print(\"Parse graph of unmodified pass stack:\\n\")\n",
    "run_first_experiment(Session()) \n",
    "print()\n",
    "\n",
    "print(\"Parse graph of pass stack with the optimizaion pass:\\n\")\n",
    "run_first_experiment(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in the rule node!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-Graph-Structure Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These kind of optimization travrse the `term_graph` and modify it's structure.\n",
    "Before you keep reading, make sure you understand how the `term graph` looks like (there is detailed documentation insidee the class docstring) and in order to understand the our terminology.\n",
    "\n",
    "Here are some example of possible optimization passes of this kind:\n",
    "1. optimization that removes join nodes that has only one child relation\n",
    "   note: this optimization already exists so there is no need to implement it.\n",
    "   \n",
    "2. optimization that removes project nodes that get relation with one column.\n",
    "   \n",
    "We will demonsrate how to implement the second example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgxlog.engine.state.graphs import TermGraphBase, TermNodeType\n",
    "\n",
    "\n",
    "# first, we will implement a function that finds all the union node and their project children (inside the term graph)\n",
    "def get_all_union_and_project_nodes(term_graph: TermGraphBase):\n",
    "    \"\"\"\n",
    "    @return: a mapping between union nodes ids to their project children nodes id.\n",
    "    \"\"\"\n",
    "\n",
    "    union_to_project_children = {}\n",
    "    nodes_ids = term_graph.post_order_dfs()  # get all the nodes in the term graph\n",
    "\n",
    "    for node_id in nodes_ids:\n",
    "        node_attrs = term_graph[node_id]\n",
    "        node_type = node_attrs[TYPE]\n",
    "\n",
    "        if node_type is TermNodeType.UNION:\n",
    "            children = term_graph.get_children(node_id)\n",
    "            # get all project children\n",
    "            project_children = [node for node in children if term_graph[node][TYPE] is TermNodeType.PROJECT]\n",
    "            union_to_project_children[node_id] = project_children\n",
    "\n",
    "    return union_to_project_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will implement a function that get a union node and one of it's project children, it will prune the project node\n",
    "def remove_project_node(term_graph: TermGraphBase, union_node, project_node) -> None:\n",
    "    \"\"\"\n",
    "    Removes the project node from the term graph and connects it's child to the union node that was his parent.\n",
    "\n",
    "    @param union_node: id of the union node.\n",
    "    @param project_node: id of the project node.\n",
    "    \"\"\"\n",
    "\n",
    "    # project node has exactly one child\n",
    "    project_child = next(iter(term_graph.get_children(project_node)))\n",
    "\n",
    "    # connect project's child to it's union node parent\n",
    "    term_graph.add_edge(union_node, project_child)\n",
    "\n",
    "    # delete project node from the term graph\n",
    "    term_graph.remove_node(project_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_relation_has_one_free_var(relation) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether relation is only one free variable.\n",
    "\n",
    "    @param relation_: a relation or an ie_relation.\n",
    "    \"\"\"\n",
    "\n",
    "    return len(relation.get_term_list()) == 1\n",
    "\n",
    "\n",
    "# the final helper function, will get id of a node and will compute the number of free vars in the input relation of this node\n",
    "def find_arity_of_node(term_graph: TermGraphBase, node_id) -> int:\n",
    "    \"\"\"\n",
    "    @param node_id: id of the node.\n",
    "    @note: we expect id of project/join node.\n",
    "    @return: the arity of the relation that the node gets during the execution.\n",
    "    \"\"\"\n",
    "\n",
    "    # this methods suppose to work for both project nodes and join nodes.\n",
    "    # project nodes always have one child while join nodes always have more than one child.\n",
    "    # for that reason, we traverse all the children of the node.\n",
    "    node_ids = term_graph.get_children(node_id)\n",
    "    free_vars: Set[str] = set()\n",
    "\n",
    "    for node_id in node_ids:\n",
    "        node_attrs = term_graph[node_id]\n",
    "        node_type = node_attrs[TYPE]\n",
    "        \n",
    "        # in the follwing cases the input relation is the relation stored in the value attribute of the node\n",
    "        if node_type in (TermNodeType.GET_REL, TermNodeType.RULE_REL, TermNodeType.GET_REL.CALC):\n",
    "            relation = node_attrs[VALUE]\n",
    "            # if relation has more than one free var we can't prune the project\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return 0\n",
    "\n",
    "            free_vars |= set(relation.get_term_list())\n",
    "\n",
    "        elif node_type is TermNodeType.JOIN:\n",
    "            # the input of project node is the same as the input of the join node\n",
    "            return find_arity_of_node(term_graph, node_id)\n",
    "\n",
    "        # in this case, we extratc the free vars of the relation (since not all the terms ore free vars)\n",
    "        elif node_type is TermNodeType.SELECT:\n",
    "            relation_child_id = next(iter(term_graph.get_children(node_id)))\n",
    "            relation = term_graph[relation_child_id][VALUE]\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return 0\n",
    "\n",
    "            relation_free_vars = [var for var, var_type in zip(relation.get_term_list(), relation.get_type_list()) if var_type is DataTypes.free_var_name]\n",
    "            free_vars |= set(relation_free_vars)\n",
    "\n",
    "    return len(free_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, lets implement the optimization pass\n",
    "class PruneUnnecessaryProjectNodes(GenericPass):\n",
    "    \"\"\"\n",
    "    This class prunes project nodes that gets a relation with one column (therefore, the project is redundant).\n",
    "\n",
    "    For example, the rule A(X) <- B(X) will yield the following term graph:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                project node (on X)\n",
    "                   get_rel node (get B)\n",
    "\n",
    "        since we project a relation with one column, after this pass the term graph will be:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                get_rel node (get B)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.term_graph: TermGraphBase = kwargs[\"term_graph\"]\n",
    "\n",
    "    def run_pass(self, **kwargs):\n",
    "        self.prune_project_nodes()\n",
    "        \n",
    "    def prune_project_nodes(self) -> None:\n",
    "        \"\"\"\n",
    "        Prunes the redundant project nodes.\n",
    "        \"\"\"\n",
    "\n",
    "        union_to_project_children = get_all_union_and_project_nodes(self.term_graph)\n",
    "        for union_id, project_ids in union_to_project_children.items():\n",
    "            for project_id in project_ids:\n",
    "                arity = find_arity_of_node(self.term_graph, project_id)\n",
    "                if arity == 1:\n",
    "                    # in this case the input relations of the project node has arity of one so we can prune the node\n",
    "                    remove_project_node(self.term_graph, union_id, project_id)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is adding this pass to the pass stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pass stack:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToComputationTermGraph\n",
      "\tPruneUnnecessaryProjectNodes\n"
     ]
    }
   ],
   "source": [
    "magic_session = Session()  # reset the magic_session\n",
    "\n",
    "new_pass_stack = magic_session.get_pass_stack()\n",
    "new_pass_stack.append(PruneUnnecessaryProjectNodes)\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(\"New pass stack:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets see how this pass modifies the term graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term graph of unmodified pass stack:\n",
      "\n",
      "(__rgxlog_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (1) (not_computed) project: ['X']\n",
      "                (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__rgxlog_root\n",
      "    A\n",
      "\n",
      "\n",
      "Term graph of pass stack with the optimizaion pass:\n",
      "\n",
      "(__rgxlog_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__rgxlog_root\n",
      "    A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new B(int)\n",
    "A(X) <- B(X)\n",
    "\"\"\"\n",
    "\n",
    "def run_second_experiment(session):\n",
    "    \"\"\"runs the command and print the term graph\"\"\"\n",
    "    session.run_commands(commands)\n",
    "    print(session._term_graph)\n",
    "    \n",
    "\n",
    "print(\"Term graph of unmodified pass stack:\\n\")\n",
    "run_second_experiment(Session()) \n",
    "print()\n",
    "\n",
    "print(\"Term graph of pass stack with the optimizaion pass:\\n\")\n",
    "run_second_experiment(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the changes in the term_graph's structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will show a more advanced optimization pass, but this time we won't implement it.\n",
    "\n",
    "The optimization will do the following:\n",
    "1. find overlapping structure of rules.\n",
    "2. than it will merge the overlapping structure and add it to the term graph.\n",
    "\n",
    "this example is described in detail in the [readme file](long_readme.md).\n",
    "    \n",
    "We will show a pseudo implementation of this pass: \n",
    "\n",
    "- get all the registered rules by using ```term_graph.get_all_rules```.\n",
    "- find overlapping strucre between rules  (this step can be implemented in many different ways).\n",
    "- cretae new rule that consists of the overlapping structute.\n",
    "- add this new rule to the term graph by using ```term_graph.add_rule_to_term_graph```.\n",
    "- updated the previous rule to use the newly created rule.\n",
    "- added the rules to the term graph.\n",
    "- delete the previous versions of the rule from the term graph by using ```term_graph.remove_rule```\n",
    "\n",
    "For example, \n",
    "if the following rule were registerd:\n",
    "1. ```D(X,Y) <- A(X),B(Y),C(X,Y,Z)```\n",
    "2. ```E(X,Y) <- A(X),C(X,Y,Z), F(Z)```\n",
    "\n",
    "in the second step of the algorith desived above we will find that both rule share the structure ```A(X),C(X,Y,Z)```.<br>\n",
    "in the third step we will create a new relation ```TEMP(X,Y,Z) <- A(X), C(X,Y,Z)```, and add it to the term grah.<br>\n",
    "in the fifth step we will modify to original rules in the following way:\n",
    "1. ```D(X,Y) <- B(Y),TEMP(X,Y,Z)```\n",
    "2. ```E(X,Y) <- TEMP(X,Y,Z), F(Z)```\n",
    "\n",
    "and then we will add them to the term graph.\n",
    "the last step will delete the old rules from the term graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
