{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 NLP pipeline\n",
    "\n",
    "### The pipline repository [link](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/)\n",
    "\n",
    "### Inroduction:\n",
    "The primary objective of the NLP pipeline is to identify individuals who have been positively diagnosed with COVID-19 by extracting pertinent information from unstructured free-text narratives found within the Electronic Health Record (EHR) of the Department of Veterans Affairs (VA). By automating this process, the pipeline streamlines the screening of a substantial volume of clinical text, significantly reducing the time and effort required for identification.\n",
    "The pipeline is built on medSpacy framework, and defines a new UI to use.\n",
    "Our goal is to write the pipline in rgxlog language so we show a real world example about the benefits of the rgxlog framework from the NLP world.\n",
    "\n",
    "### pipline stages:\n",
    "- [Concept tagger](#concept-tag-rules)\n",
    "- [Target matcher](#target-rules)\n",
    "- [Sectionizer](#section-rules)\n",
    "- [Context matcher](#context-rules)\n",
    "- [Postprocessor](#postprocess-rules)\n",
    "- [Document Classifier](#document_classifier)\n",
    "\n",
    "We will implement each stage separately later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install some requirements to work with [medspacy](https://github.com/medspacy/medspacy) framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import what we need from the rgxlog framework and define some ie functions that will be used in every stage of the pipline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import rgxlog\n",
    "from rgxlog import magic_session\n",
    "from rgxlog import Session\n",
    "from rgxlog.engine.datatypes.primitive_types import DataTypes\n",
    "from rgxlog.engine.datatypes.primitive_types import Span\n",
    "session = rgxlog.magic_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(text_path):\n",
    "    \"\"\"\n",
    "    Reads from file and return it's content.\n",
    "\n",
    "    Parameters:\n",
    "        text_path (str): The path to the text file to read from.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the file.\n",
    "    \"\"\"\n",
    "    with open(f\"{text_path}\", 'r') as file:\n",
    "        content = file.read()\n",
    "    yield content\n",
    "magic_session.register(ie_function=read_from_file,\n",
    "                       ie_function_name = \"read_from_file\",\n",
    "                       in_rel=[DataTypes.string],\n",
    "                       out_rel=[DataTypes.string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_interval_conflicts(replacements):\n",
    "    \"\"\"\n",
    "    This function takes a list of replacements, where each replacement is represented\n",
    "    as a list containing a label and a span (interval). It checks for conflicts among\n",
    "    the intervals and returns a list of resolved replacements, ensuring that no two\n",
    "    intervals overlap.\n",
    "\n",
    "    Parameters:\n",
    "    replacements (list of lists): A list of replacements, where each replacement\n",
    "        is represented as a list [label, span].\n",
    "\n",
    "    Returns:\n",
    "    list of lists: A list of resolved replacements, where each replacement is a list\n",
    "        [label, span], ensuring that there are no conflicts among intervals.\n",
    "    \"\"\"\n",
    "    # Sort the replacements by the size of the spans in descending order\n",
    "    replacements.sort(key=lambda x: x[1].span_end - x[1].span_start, reverse=True)\n",
    "\n",
    "    # Initialize a list to keep track of intervals that have been replaced\n",
    "    resolved_replacements = []\n",
    "    \n",
    "    for label, span in replacements:\n",
    "        conflict = False\n",
    "\n",
    "        for _, existing_span in resolved_replacements:\n",
    "            existing_start = existing_span.span_start\n",
    "            existing_end = existing_span.span_end\n",
    "\n",
    "            if not (span.span_end <= existing_start or span.span_start >= existing_end):\n",
    "                conflict = True\n",
    "                break\n",
    "\n",
    "        if not conflict:\n",
    "            resolved_replacements.append([label, span])\n",
    "\n",
    "    return resolved_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_spans(spans_table, paths_table):\n",
    "    \"\"\"\n",
    "    This function takes tables a spans tables and path table for the files paths,\n",
    "    it generate queries for the tables, executes the queries using a session, processes the results, \n",
    "    and replaces specific spans in a text with the corresponding labels, it first\n",
    "    resolve spans overlapping conflicts for each giving path.\n",
    "\n",
    "    Parameters:\n",
    "    spans_table (str): A string representing the spans table to process, table columns are formated as (Label, Span, Path).\n",
    "    paths_table (str): A string representing the paths table to process, table columns are formated as (Path)\n",
    "\n",
    "    Returns:\n",
    "    str: The adjusted text string with the new labels.\n",
    "    \"\"\"\n",
    "    # Get a list of all the paths\n",
    "    paths = session.run_commands(f\"?{paths_table}(Path)\", print_results=False, format_results=True)\n",
    "    paths = paths[0].values.tolist()\n",
    "    for path_list in paths:\n",
    "        path = path_list[0]\n",
    "\n",
    "        # Generate a spans query for each path, the query will be formates as (Label, Span, Path)\n",
    "        results = session.run_commands(f'?{spans_table}(Label, Span, \"{path}\")', print_results=True, format_results=True)\n",
    "        if len(results[0]) == 0:\n",
    "            continue\n",
    "        # replacments is list of lists where each list is a [Label, Span]\n",
    "        replacements = results[0].values.tolist()\n",
    "        \n",
    "        with open(f\"{path}\", 'r') as file:\n",
    "            adjusted_string = file.read()\n",
    "    \n",
    "        # Resolve spans conflicts\n",
    "        resolved_replacements = resolve_interval_conflicts(replacements)\n",
    "    \n",
    "        # Sort the resolved replacements by the starting index of each span in descending order\n",
    "        resolved_replacements.sort(key=lambda x: x[1].span_start, reverse=True)\n",
    "    \n",
    "        # iterate over the resolved query results and replace the space with the corresponding label\n",
    "        for i in range(len(resolved_replacements)):\n",
    "            replace_string, span = resolved_replacements[i]\n",
    "            replace_length = len(replace_string)\n",
    "            adjusted_string = adjusted_string[:span.span_start] + replace_string + adjusted_string[span.span_end:]\n",
    "    \n",
    "        with open(f\"{path}\", 'w') as file:\n",
    "            file.writelines(adjusted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The paths of the text files to be classified should be written in \"files_paths.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1.txt\n",
      "sample2.txt\n",
      "sample3.txt\n",
      "sample4.txt\n",
      "sample5.txt"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat files_paths.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"files_paths.csv\", relation_name=\"FilesPaths\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                                   Content\n",
      "-------------+---------------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | Patient presents to be tested for COVID-19. His wife recently tested positive for novel coronavirus. SARS-COV-2 results came back positive.\n",
      " sample2.txt |                                         The patient was tested for COVID-19. Results are positive.\n",
      " sample3.txt |                                            Problem List: 1. Pneumonia 2. Novel Coronavirus 2019\n",
      " sample4.txt |                                                            neg covid education.\n",
      " sample5.txt |                                                         positive covid precaution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "FilesContent(Path, Content) <- FilesPaths(Path), read_from_file(Path) -> (Content)\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='concept-tag-rules'></a>\n",
    "### [Concept Tag Rules](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/concept_tag_rules.py):\n",
    "Concept tag rules, also known as pattern-based rules or custom rules, are a way to specify and define patterns that an NLP (Natural Language Processing) system should recognize within text data. These rules are used to identify specific concepts or entities within text documents. In the context of MedSpaCy and medical NLP, concept tag rules are often used to identify medical entities and concepts accurately.\n",
    "\n",
    "In the orginal project they used the TargetRule class which defines a rule for identifying a specific concept or entity in text.\n",
    "each concept Target Rule looks like this:\n",
    "\n",
    "TargetRule(\n",
    "            literal=\"coronavirus\",\n",
    "            category=\"COVID-19\",\n",
    "            pattern=[{\"LOWER\": {\"REGEX\": \"coronavirus|hcov|ncov$\"}}],\n",
    "          )\n",
    "\n",
    "**Literal** : This specifies the literal text or word that this rule is targeting.\n",
    "\n",
    "**Category** : This specifies the category or label associated with the identified entity.\n",
    "\n",
    "**Pattern** : This defines the pattern or conditions under which the entity should be recognized. It's a list of dictionaries specifying conditions for token matching. These rules some times used lemma attribute or POS of each token. A documentation can be found at : https://spacy.io/usage/rule-based-matching.\n",
    "\n",
    "Instead what we did is to define regex patterns, we have added these pattern in concept_target_rules.csv file, there are two types of these patterns lemma and pos, that we will implement each later on.\n",
    "Each rule in the csv file is like this : regexPattern, label, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?i)(?:hcov|covid(?:(?:-)?(?:\\s)?19|10)?|2019-cov|cov2|ncov-19|covd 19|no-cov|sars cov),COVID-19,lemma\n",
      "(?i)(?:coivid|(?:novel )?corona(?:virus)?(?: (?:20)?19)?|sars(?:\\s)?(?:-)?(?:\\s)?cov(?:id)?(?:-)?(?:2|19)),COVID-19,lemma\n",
      "(?i)(?:\\+(?: ve)?|\\(\\+\\)|positive|\\bpos\\b|active|confirmed),positive,lemma\n",
      "(?i)(?:pneum(?:onia)?|pna|hypoxia|septic shoc|ards\\(?(?:(?:[12])/2)\\)?|(?:hypoxemic|acute|severe)? resp(?:iratory)? failure(?:\\(?(?:[12]/2)\\)?)?)\",associated_diagnosis,lemma\n",
      "(?i)(?:(?:diagnos(?:is|ed)|dx(?:\\.)?)(?:of|with)?),diagnosis,lemma\n",
      "(?i)(?:^screen),screening,lemma\n",
      "(?i)(?:in contact with|any one|co-worker|at work|(?:the|a)(?:wo)?man|(?:another|a) (?:pt|patient|pt\\.)),other_experiencer,lemma\n",
      "(?i)(?:patient|pt(?:\\.)?|vt|veteran),patient,lemma\n",
      "(?i)(?:like_num (?:days|day|weeks|week|months|month) (?:ago|prior)),timesx,lemma\n",
      "(?i)(?:(?:antibody|antibodies|ab) test),antibody test,lemma\n",
      "(?i)(?:(?:coronavirus|hcovs?|ncovs?|covs?)(?:\\s)?(?:-)?(?:\\s)?(?: infection)?(?: strain)?(?:\\s)?(?:229(?:e)?|oc(?:-)?(?:43)?|o43|0c43|43|nl(?:16(?:3|5))?|hku(?:t|-)?1|hkui|emc|63)),OTHER_CORONAVIRUS,lemma\n",
      "(?i)(?:(?:229(?:e)?|oc(?:-)?(?:43)?|o43|0c43|43|nl(?:16(?:3|5))?|hku(?:t|-)?1|hkui|emc|63) (?:coronavirus|hcovs?|ncovs?|covs?)),OTHER_CORONAVIRUS,lemma\n",
      "(?i)(?:non(?:\\s)?(?:-)?(?:\\s)?(?:novel|covid|ncovid|covid-19)(?: coronavirus)?|other coronavirus),OTHER_CORONAVIRUS,lemma\n",
      "(?i)(?:wife|husband|spouse|family|member|girlfriend|boyfriend|mother|father|nephew|niece|grandparent|grandparents|granddaughter|relative|relatives|caregiver),family,pos\n",
      "(?i)(?:grandchild|grandson|cousin|grandmother|grandfather|parent|son|daughter|mom|dad|brother|sister|aunt|uncle|child|children|sibling|siblings),family,pos\n",
      "(?i)(?:someone|somebody|person|anyone|anybody|people|individual|individuals|teacher|anybody|employees|employer|customer|client|residents),other_experiencer,pos\n",
      "(?i)(?:resident|pts|patients|coworker|coworkers|workers|colleague|captain|captains|pilot|pilots|sailor|sailors|meeting),other_experiencer,pos\n",
      "(?i)(?:boyfriend|persons|person|church|convention|guest|party|attendee|conference|roommate|friend|friends|coach|player|neighbor|manager|boss),other_experiencer,pos\n",
      "(?i)(?:cashier|landlord|worked|works|^mate|nobody|mates|housemate|housemates|hotel|soldier|airport|tsa|lady|ladies|lobby|staffer|staffers),other_experiencer,pos"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat concept_tags_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"concept_tags_rules.csv\", relation_name=\"ConceptTagRules\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemma Rules:\n",
    "Lemma rules are rules that used the attribute _lemma of each token in the NLP, so what we defined this function to lemmatize the text, most of the rules used only the raw text, thats why we decided that only to lemmatize the tokens we needed.\n",
    "\n",
    "Example for a lemma rule from the original NLP:\n",
    "\n",
    "        TargetRule(\n",
    "            \"results positive\",\n",
    "            \"positive\",\n",
    "            pattern=[\n",
    "                {\"LOWER\": \"results\"},\n",
    "                {\"LEMMA\": \"be\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": {\"IN\": [\"pos\", \"positive\"]}},\n",
    "            ],\n",
    "        ),\n",
    "We used the py_rgx_span to capture the patterns, and will use the spans later on in replace_spans that will replace each span with the correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text_path, lemma_words_path):\n",
    "    \"\"\"\n",
    "    This function reads a text file, lemmatizes its content using spaCy's English language model,\n",
    "    and replaces certain words with their lemmas the rest will remain the same. The updated text is then written back to the same file.\n",
    "\n",
    "    Parameters:\n",
    "        text_path (str): The path to the text file to be lemmatized.\n",
    "        lemma_words_path(str): The path that contains the list of words to be lemmatized\n",
    "\n",
    "    Returns:\n",
    "        str: The lemmatized text.\n",
    "    \"\"\"\n",
    "    # Define a list of words to be lemmatized\n",
    "    lemma_words = [line.strip() for line in open(f\"{lemma_words_path}\") if line.strip()]\n",
    "\n",
    "    with open(text_path, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(contents)\n",
    "\n",
    "    lemmatized_text = \"\"\n",
    "    for token in doc:\n",
    "        if token.lemma_ in lemma_words:\n",
    "            lemmatized_text += token.lemma_\n",
    "        elif token.like_num:\n",
    "            lemmatized_text += \"like_num\"\n",
    "        else:\n",
    "            lemmatized_text += token.text\n",
    "        lemmatized_text += \" \"\n",
    "\n",
    "    # Write the lemmatized text back to the same file\n",
    "    with open(text_path, 'w') as file:\n",
    "        file.writelines(lemmatized_text)\n",
    "\n",
    "    yield lemmatized_text\n",
    "magic_session.register(ie_function=lemmatize_text, ie_function_name = \"lemmatize_text\", in_rel=[DataTypes.string, DataTypes.string], out_rel=[DataTypes.string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'lemma_texts(Path, LemmaText)':\n",
      "    Path     |                                                                    LemmaText\n",
      "-------------+--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His wife recently tested positive for novel coronavirus . SARS - COV-2 results came back positive .\n",
      " sample2.txt |                                            The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                                    Problem List : like_num . Pneumonia like_num . Novel Coronavirus like_num\n",
      " sample4.txt |                                                              neg covid education .\n",
      " sample5.txt |                                                           positive covid precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "lemma_texts(Path, LemmaText) <- FilesPaths(Path), lemmatize_text(Path, \"lemma_words.txt\") -> (LemmaText)\n",
    "?lemma_texts(Path, LemmaText)\n",
    "\n",
    "LemmaMatches(Label, Span, Path) <- lemma_texts(Path, Text), ConceptTagRules(Pattern, Label, \"lemma\"), py_rgx_span(Text, Pattern) -> (Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'LemmaMatches(Label, Span, \"sample1.txt\")':\n",
      "  Label   |    Span\n",
      "----------+------------\n",
      " COVID-19 |  [34, 42)\n",
      " COVID-19 | [103, 115)\n",
      " COVID-19 | [83, 100)\n",
      " positive | [134, 142)\n",
      " positive |  [70, 78)\n",
      " patient  |   [0, 7)\n",
      "\n",
      "printing results for query 'LemmaMatches(Label, Span, \"sample2.txt\")':\n",
      "  Label   |   Span\n",
      "----------+----------\n",
      " COVID-19 | [26, 34)\n",
      " positive | [48, 56)\n",
      " patient  | [4, 11)\n",
      "\n",
      "printing results for query 'LemmaMatches(Label, Span, \"sample3.txt\")':\n",
      "        Label         |   Span\n",
      "----------------------+----------\n",
      "       COVID-19       | [47, 64)\n",
      " associated_diagnosis | [26, 35)\n",
      "\n",
      "printing results for query 'LemmaMatches(Label, Span, \"sample4.txt\")':\n",
      "  Label   |  Span\n",
      "----------+--------\n",
      " COVID-19 | [4, 9)\n",
      "\n",
      "printing results for query 'LemmaMatches(Label, Span, \"sample5.txt\")':\n",
      "  Label   |  Span\n",
      "----------+---------\n",
      " COVID-19 | [9, 14)\n",
      " positive | [0, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace the matches with the correct label\n",
    "replace_spans(\"LemmaMatches\", \"FilesPaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                               Content\n",
      "-------------+-------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His wife recently tested positive for COVID-19 . COVID-19 results came back positive .\n",
      " sample2.txt |                                     The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                             Problem List : like_num . associated_diagnosis like_num . COVID-19 like_num\n",
      " sample4.txt |                                                      neg COVID-19 education .\n",
      " sample5.txt |                                                   positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Rules:\n",
    "As we mentioned above these rules used the POS attribute of each token, there were a small number of rules so we only used this to the tokens we needed.\n",
    "Example of the a rule from the original NLP:\n",
    "\n",
    "        TargetRule(\n",
    "            \"other experiencer\",\n",
    "            category=\"other_experiencer\",\n",
    "            pattern=[\n",
    "                {\n",
    "                    \"POS\": {\"IN\": [\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"]},\n",
    "                    \"LOWER\": {\n",
    "                        \"IN\": [\n",
    "                            \"someone\",\n",
    "                            \"somebody\",\n",
    "                            \"person\",\n",
    "                            \"anyone\",\n",
    "                            \"anybody\",\n",
    "                        ]\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "The patterns we've defined will match words listed under \"IN\", We specifically capture words if their Part-of-Speech (POS) falls into one of the categories: [\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"]. To accomplish this, two functions are employed: the first function determines the POS of each token, and the second one, py_rgx_span, captures the predefined patterns. After matching words, We confirm the accurate POS tags of the matched words using spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_text_with_pos(text_path):\n",
    "    \"\"\"\n",
    "    This function reads a text file, processes its content using spaCy's English language model,\n",
    "    and returns a tuple of (POS, Span) for each token if it's one of NOUN|PROPN|PRON|ADJ\n",
    "    otherwise an empty tuple will be returned\n",
    "    \n",
    "    Parameters:\n",
    "        text_path (str): The path to the text file to be annotated.\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, Span): The POS of the token and it's span\n",
    "    \"\"\"\n",
    "    with open(text_path, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(contents)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"]:\n",
    "            yield token.pos_, Span(token.idx, token.idx + len(token.text))\n",
    "        else:\n",
    "            yield tuple()\n",
    "magic_session.register(ie_function=annotate_text_with_pos, ie_function_name = \"annotate_text_with_pos\", in_rel=[DataTypes.string], out_rel=[DataTypes.string, DataTypes.span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'POSTable(POS, Span, Path)':\n",
      "  POS  |    Span    |    Path\n",
      "-------+------------+-------------\n",
      "  ADJ  |   [0, 7)   | sample1.txt\n",
      "  ADJ  | [121, 129) | sample1.txt\n",
      "  ADJ  |  [70, 78)  | sample1.txt\n",
      " NOUN  | [103, 110) | sample1.txt\n",
      " NOUN  |  [49, 53)  | sample1.txt\n",
      " NOUN  |  [8, 16)   | sample1.txt\n",
      " PROPN |  [83, 91)  | sample1.txt\n",
      "  ADJ  |  [48, 56)  | sample2.txt\n",
      " NOUN  |  [26, 34)  | sample2.txt\n",
      " NOUN  |  [37, 44)  | sample2.txt\n",
      " NOUN  |  [4, 11)   | sample2.txt\n",
      " NOUN  |  [15, 23)  | sample3.txt\n",
      " PROPN |   [0, 7)   | sample3.txt\n",
      " PROPN |  [26, 46)  | sample3.txt\n",
      " PROPN |  [47, 55)  | sample3.txt\n",
      " PROPN |  [67, 75)  | sample3.txt\n",
      " PROPN |  [8, 12)   | sample3.txt\n",
      " NOUN  |  [13, 22)  | sample4.txt\n",
      " PROPN |   [0, 3)   | sample4.txt\n",
      " PROPN |  [4, 12)   | sample4.txt\n",
      "  ADJ  |   [0, 8)   | sample5.txt\n",
      " NOUN  |  [18, 28)  | sample5.txt\n",
      "\n",
      "printing results for query 'POSMatches(Label, Span, Path)':\n",
      "  Label  |   Span   |    Path\n",
      "---------+----------+-------------\n",
      " family  | [49, 53) | sample1.txt\n",
      "\n",
      "printing results for query 'POSRuleMatches(Label, Span, Path)':\n",
      "  Label  |   Span   |    Path\n",
      "---------+----------+-------------\n",
      " family  | [49, 53) | sample1.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "POSTable(POS, Span, Path) <- lemma_texts(Path, Text), annotate_text_with_pos(Path) -> (POS, Span)\n",
    "?POSTable(POS, Span, Path)\n",
    "\n",
    "POSMatches(Label, Span, Path) <- lemma_texts(Path, Text), ConceptTagRules(Pattern, Label, \"pos\"), py_rgx_span(Text, Pattern) -> (Span)\n",
    "?POSMatches(Label, Span, Path)\n",
    "\n",
    "POSRuleMatches(Label, Span, Path) <- POSTable(POS, Span, Path), POSMatches(Label, Span, Path)\n",
    "?POSRuleMatches(Label, Span, Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'POSRuleMatches(Label, Span, \"sample1.txt\")':\n",
      "  Label  |   Span\n",
      "---------+----------\n",
      " family  | [49, 53)\n",
      "\n",
      "printing results for query 'POSRuleMatches(Label, Span, \"sample2.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'POSRuleMatches(Label, Span, \"sample3.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'POSRuleMatches(Label, Span, \"sample4.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'POSRuleMatches(Label, Span, \"sample5.txt\")':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace the matches with the correct label\n",
    "replace_spans(\"POSRuleMatches\", \"FilesPaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                                Content\n",
      "-------------+---------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His family recently tested positive for COVID-19 . COVID-19 results came back positive .\n",
      " sample2.txt |                                      The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                              Problem List : like_num . associated_diagnosis like_num . COVID-19 like_num\n",
      " sample4.txt |                                                       neg COVID-19 education .\n",
      " sample5.txt |                                                    positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='target-rules'></a>\n",
    "### [Target Rules](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/target_rules.py):\n",
    "These rules used the label that was assigned through the concept tagger, to capture some more complex patterns and assign a label for them inorder to decremnt the cases of false positive.\n",
    "Each rule look like this:\n",
    "\n",
    "        TargetRule(\n",
    "            literal=\"coronavirus screening\",\n",
    "            category=\"IGNORE\",\n",
    "            pattern=[\n",
    "                {\"_\": {\"concept_tag\": \"COVID-19\"}},\n",
    "                {\"LOWER\": {\"IN\": [\"screen\", \"screening\", \"screenings\"]}},\n",
    "            ],\n",
    "        ),\n",
    "Since we replaced the spans we found with the corresponding label we didn't need the concept_tag attribute of the token/span.\n",
    "To ease the patterns we have devided them into two groups PreTargetRules and TargetRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreTargetRules: \n",
    "To ease the process, we have implemented preTarget rules aimed at squash consecutive identical labels assigned through the concept tagger into a single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?i)(?:COVID-19(?: COVID-19)+),COVID-19\n",
      "(?i)(?:positive(?: positive)+),positive\n",
      "(?i)(?:patient(?: patient)+),patient\n",
      "(?i)(?:other_experiencer(?: other_experiencer)+),other_experiencer\n",
      "(?i)(?:screening(?: screening)+),screening"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat pre_target_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"pre_target_rules.csv\", relation_name=\"PreTargetTagRules\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'PreTargetMatches(Label, Span, Path)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "PreTargetMatches(Label, Span, Path) <- lemma_texts(Path, Text), PreTargetTagRules(Pattern, Label), py_rgx_span(Text,Pattern) -> (Span)\n",
    "?PreTargetMatches(Label, Span, Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'PreTargetMatches(Label, Span, \"sample1.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'PreTargetMatches(Label, Span, \"sample2.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'PreTargetMatches(Label, Span, \"sample3.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'PreTargetMatches(Label, Span, \"sample4.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'PreTargetMatches(Label, Span, \"sample5.txt\")':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "replace_spans(\"PreTargetMatches\", \"FilesPaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                                Content\n",
      "-------------+---------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His family recently tested positive for COVID-19 . COVID-19 results came back positive .\n",
      " sample2.txt |                                      The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                              Problem List : like_num . associated_diagnosis like_num . COVID-19 like_num\n",
      " sample4.txt |                                                       neg COVID-19 education .\n",
      " sample5.txt |                                                    positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?i)(?:COVID-19 positive (?:unit|floor)|positive COVID-19 (?:unit|floor|exposure)),COVID-19\n",
      "(?i)(?:known(?: positive)? COVID-19(?: positive)? (?:exposure|contact)),COVID-19\n",
      "(?i)(?:COVID-19 positive screening|positive COVID-19 screening|screening COVID-19 positive|screening positive COVID-19),positive coronavirus screening\n",
      "(?i)(?:diagnosis : COVID-19 (?:test|screening)),COVID-19\n",
      "(?i)(?:COVID-19 screening),coronavirus screening\n",
      "(?i)(?:active COVID-19 precaution|droplet isolation precaution|positive for (?:flu|influenza)|(?:the|a) positive case|results are confirm),1 2 3\n",
      "(?i)(?:exposed to positive|[ ] COVID-19|age like_num(?: )?\\+|(?:return|back) to work|COVID-19 infection rate),1 2 3\n",
      "(?i)(?:COVID-19 (?:restriction|emergency|epidemic|outbreak|crisis|breakout|pandemic|spread|screening)|droplet precaution),1 2\n",
      "(?i)(?:contact precautions|positive (?:flu|influenza)|positive (?:patient|person)|confirm (?:with|w/(?:/)?|w)|(?:the|positive) case),1 2\n",
      "(?i)(?:results confirm|(?:neg|pos)\\S+ pressure|positive (?:attitude|feedback|serology)|COVID-19 (guidelines|rate)),1 2\n",
      "(?i)(?:has the patient been diagnosed (?:with|w/(?:/)?|w)),1 2 3 4 5 6\n",
      "(?i)(?:has patient been diagnosed (?:with|w/(?:/)?|w)),1 2 3 4 5\n",
      "(?i)((?:person|patient) with confirm COVID-19),1 2 3 4\n",
      "(?i)(?:COVID-19 positive (?:tested )?other_experiencer),COVID-19\n",
      "(?i)(?:in order to decrease the spread of the COVID-19 infection),1 2 3 4 5 6 7 8 9 10\n",
      "(?i)(?:COVID-19 positive (?:patient|person|people|veteran)),OTHER_PERSON\n",
      "(?i)(?:positive COVID-19 (?:tested )?other_experiencer),COVID-19\n",
      "(?i)(?:(?:(?:contact|exposure) (?:with|to)? )?positive COVID-19 (?:patient|person|veteran)),OTHER_PERSON\n",
      "(?i)(?:(?:patient|person) (?:who|that) test (?:positive|confirm) for COVID-19),OTHER_PERSON\n",
      "(?i)(ref : not detected|history of present illness|does not know|but|therefore|flu|metapneumovirus|;),<IGNORE>"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat target_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"target_rules.csv\", relation_name=\"TargetTagRules\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%rgxlog\n",
    "TargetTagMatches(Label, Span, Path) <- lemma_texts(Path, Text), TargetTagRules(Pattern, Label), py_rgx_span(Text,Pattern) -> (Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'TargetTagMatches(Label, Span, \"sample1.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'TargetTagMatches(Label, Span, \"sample2.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'TargetTagMatches(Label, Span, \"sample3.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'TargetTagMatches(Label, Span, \"sample4.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'TargetTagMatches(Label, Span, \"sample5.txt\")':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "replace_spans(\"TargetTagMatches\", \"FilesPaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                                Content\n",
      "-------------+---------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His family recently tested positive for COVID-19 . COVID-19 results came back positive .\n",
      " sample2.txt |                                      The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                              Problem List : like_num . associated_diagnosis like_num . COVID-19 like_num\n",
      " sample4.txt |                                                       neg COVID-19 education .\n",
      " sample5.txt |                                                    positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-rules'></a>\n",
    "### [Section Rules](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/section_rules.py):\n",
    "Here, we'll add a section detection component that defines rules for detecting sections titles, which usually appear before a semicolon.\n",
    "Section rules are utilized to identify specific section names, enabling the separation of text into different parts. Entities occurring in certain sections are considered positive.\n",
    "\n",
    "In the original project, the SectionRule class was used to define rules for identifying specific section text. Each SectionRule has the following structure\n",
    "\n",
    "      SectionRule(category=\"problem_list\", literal=\"Active Problem List:\"),\n",
    "      SectionRule(category=\"problem_list\", literal=\"Current Problems:\"),\n",
    "    \n",
    "    \n",
    "**Literal** : This specifies the literal section text or word that this rule is targeting.\n",
    "\n",
    "**Category** : This specifies the section category associated with the identified section.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Similar to the approach used in the concept tagger stage, regex patterns were derived from these literals, and these patterns are stored in the 'section_target_rules.csv' file and are used to match section texts and replace them with their appropriate category.\n",
    "\n",
    "Each rule in the CSV file follows this format: regexPattern, sectionLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?i)(?:Lab results :),labs :\n",
      "(?i)(?:Addendum :),addendum :\n",
      "(?i)(?:(?:ALLERGIC REACTIONS|ALLERGIES) :),allergies :\n",
      "(?i)(?:(?:CC|Chief Complaint) :),chief_complaint :\n",
      "(?i)(?:COMMENTS :),comments :\n",
      "(?i)(?:(?:(?:ADMISSION )?DIAGNOSES|Diagnosis|Primary Diagnosis|Primary|Secondary(?: (?:Diagnoses|Diagnosis))) :),diagnoses :\n",
      "(?i)(?:(?:Brief Hospital Course|CONCISE SUMMARY OF HOSPITAL COURSE BY ISSUE/SYSTEM|HOSPITAL COURSE|SUMMARY OF HOSPITAL COURSE) :),hospital_course :\n",
      "(?i)(?:(?:Imaging|MRI|INTERPRETATION|Radiology) :),imaging :\n",
      "(?i)(?:(?:ADMISSION LABS|Discharge Labs|ECHO|Findings|INDICATION|Labs|Micro|Microbiology|Studies|Pertinent Results) :),labs_and_studies :\n",
      "(?i)(?:(?:ACTIVE MEDICATIONS(?: LIST)|ADMISSION MEDICATIONS|CURRENT MEDICATIONS|DISCHARGE MEDICATIONS|HOME MEDICATIONS|MEDICATIONS) :),medications :\n",
      "(?i)(?:(?:MEDICATIONS AT HOME|MEDICATIONS LIST|MEDICATIONS ON ADMISSION|MEDICATIONS ON DISCHARGE|MEDICATIONS ON TRANSFER|MEDICATIONS PRIOR TO ADMISSION) :),medications :\n",
      "(?i)(?:Neuro :),neurological :\n",
      "(?i)(?:(?:A/P|MEDICATIONS LIST|ASSESSMENT/PLAN|ASSESSMENT|Clinical Impression|DISCHARGE DIAGNOSES|DISCHARGE DIAGNOSIS) :),observation_and_plan :\n",
      "(?i)(?:(?:Discharge Condition|Discharge Disposition|FINAL DIAGNOSES|FINAL DIAGNOSIS|IMPRESSION|Impression and Plan|Impression and Recommendation) :),observation_and_plan :\n",
      "(?i)(?:(?:Facility|Service) :),other :\n",
      "(?i)(?:(?:Current Medical Problems|History of Chronic Illness|MHx|PAST HISTORY|PAST MEDICAL Hx|PAST SURGICAL HISTORY|PMH|PMHx|PAST MEDICAL HISTORY|UNDERLYING MEDICAL CONDITION) :),past_medical_history :\n",
      "(?i)(?:(?:Education|Patient Education|DISCHARGE INSTRUCTIONS/FOLLOWUP|DISCHARGE INSTRUCTIONS|Followup Instructions) :),patient_education :\n",
      "(?i)(?:(?:PE|PHYSICAL EXAM|PHYSICAL EXAMINATION) :),physical_exam :\n",
      "(?i)(?:(?:Active Problem List|Current Problems|Medical Problems|PROBLEM LIST) :),problem_list :\n",
      "(?i)(?:REASON FOR THIS EXAMINATION :),reason_for_examination :\n",
      "(?i)(?:(?:Electronic Signature|Signed electronically by) :),signature :\n",
      "(?i)(?:(?:PMHSx|PSH|SH|Sexual History:|Social History) :),social_history :"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat section_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"section_rules.csv\", relation_name=\"SectionRules\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_span_contained(span1, span2):\n",
    "    \"\"\"\n",
    "    Checks if one span is contained within the other span and returns the smaller span if yes.\n",
    "\n",
    "    Parameters:\n",
    "        span1 (span)\n",
    "        span2 (span)\n",
    "\n",
    "    Returns:\n",
    "        span: span1 if contained within span2 or vice versa, or None if not contained.\n",
    "    \"\"\"\n",
    "    start1, end1 = span1.span_start, span1.span_end\n",
    "    start2, end2 = span2.span_start, span2.span_end\n",
    "    \n",
    "    if start2 <= start1 and end1 <= end2:\n",
    "        yield span1\n",
    "        \n",
    "    elif start1 <= start2 and end2 <= end1:\n",
    "        yield span2\n",
    "\n",
    "magic_session.register(is_span_contained, \"is_span_contained\", in_rel=[DataTypes.span, DataTypes.span], out_rel=[DataTypes.span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'SectionRulesMatches(Label, Span, Path)':\n",
      "     Label      |  Span   |    Path\n",
      "----------------+---------+-------------\n",
      " problem_list : | [0, 14) | sample3.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "SectionRulesMatches(Label, Span, Path) <- lemma_texts(Path, Text), SectionRules(Pattern, Label), py_rgx_span(Text,Pattern) -> (Span)\n",
    "?SectionRulesMatches(Label, Span, Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'SectionRulesMatches(Label, Span, \"sample1.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'SectionRulesMatches(Label, Span, \"sample2.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'SectionRulesMatches(Label, Span, \"sample3.txt\")':\n",
      "     Label      |  Span\n",
      "----------------+---------\n",
      " problem_list : | [0, 14)\n",
      "\n",
      "printing results for query 'SectionRulesMatches(Label, Span, \"sample4.txt\")':\n",
      "[]\n",
      "\n",
      "printing results for query 'SectionRulesMatches(Label, Span, \"sample5.txt\")':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "replace_spans(\"SectionRulesMatches\", \"FilesPaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'FilesContent(Path, Content)':\n",
      "    Path     |                                                                Content\n",
      "-------------+---------------------------------------------------------------------------------------------------------------------------------------\n",
      " sample1.txt | patient presents to be tested for COVID-19 . His family recently tested positive for COVID-19 . COVID-19 results came back positive .\n",
      " sample2.txt |                                      The patient be tested for COVID-19 . Results be positive .\n",
      " sample3.txt |                              problem_list : like_num . associated_diagnosis like_num . COVID-19 like_num\n",
      " sample4.txt |                                                       neg COVID-19 education .\n",
      " sample5.txt |                                                    positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?FilesContent(Path, Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Assertion:\n",
    "\n",
    " Next, we will explore how to assert attributes indicating whether a mention of COVID-19 is positive or not. In our project, we have created a table     named 'CovidAttributes' that contains all attributes for each COVID-19 mention. This table will be used for classifying documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'SectionMatches(Path, Span, CovidAttribute)':\n",
      "    Path     |  Span   |  CovidAttribute\n",
      "-------------+---------+------------------\n",
      " sample3.txt | [0, 76) |     positive\n",
      "\n",
      "printing results for query 'CovidMatches(Path, Span)':\n",
      "    Path     |   Span\n",
      "-------------+-----------\n",
      " sample1.txt | [34, 42)\n",
      " sample1.txt | [85, 93)\n",
      " sample1.txt | [96, 104)\n",
      " sample2.txt | [26, 34)\n",
      " sample3.txt | [58, 66)\n",
      " sample4.txt |  [4, 12)\n",
      " sample5.txt |  [9, 17)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "#Here, we employ a pattern to identify entities present in specific sections and mark them as positive,\n",
    "#and adding them to the 'CovidAttributes' table.\n",
    "\n",
    "pattern = \"(?i)(?:diagnoses :|observation_and_plan :|past_medical_history :|problem_list :)(?:(?!labs :|addendum :|allergies :|chief_complaint :|comments :|family_history :|hospital_course :|imaging :|labs_and_studies :|medications :|neurological :|other :|patient_education :|physical_exam :|reason_for_examination :|signature :|social_history :).)*\"\n",
    "new SectionRulesAttribute(str, str)\n",
    "SectionRulesAttribute(pattern, \"positive\")\n",
    "\n",
    "SectionMatches(Path, Span, CovidAttribute) <- lemma_texts(Path, Text), SectionRulesAttribute(Pattern, CovidAttribute), py_rgx_span(Text, Pattern) -> (Span)\n",
    "?SectionMatches(Path, Span, CovidAttribute)\n",
    "\n",
    "CovidMatches(Path, Span) <- lemma_texts(Path, Text), py_rgx_span(Text, \"COVID-19\") -> (Span)\n",
    "?CovidMatches(Path, Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'SectionCovidAttributes(Path, CovidSpan, CovidAttribute)':\n",
      "    Path     |  CovidSpan  |  CovidAttribute\n",
      "-------------+-------------+------------------\n",
      " sample3.txt |  [58, 66)   |     positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "SectionCovidAttributes(Path, CovidSpan, CovidAttribute) <- SectionMatches(Path, Span1, CovidAttribute), CovidMatches(Path, Span2), is_span_contained(Span1, Span2) -> (CovidSpan)\n",
    "?SectionCovidAttributes(Path, CovidSpan, CovidAttribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Text into Sentences:\n",
    "\n",
    "In the subsequent stages, where attributes are assigned to COVID-19 mentions, a departure from the previous stages occurs. Here, patterns are no longer applied to the entire text, instead, they are applied at the sentence level, since the attributes of COVID-19 mentions are typically determined by the context of the sentence in which they appear. This means the text is processed and tokenized into sentences using spaCy's English language model. This process is accomplished through the use of  ie functions and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tokenization(text_path):\n",
    "    \"\"\"\n",
    "    This function reads a text file, processes its content using spaCy's English language model,\n",
    "    tokenizing it into sentences and returns each individual sentence in the processed text using a generator.\n",
    "    \n",
    "    Parameters:\n",
    "        text_path (str): The path to the text file to be annotated.\n",
    "\n",
    "    Returns:\n",
    "        str: Individual sentences extracted from the input text.\n",
    "    \"\"\"\n",
    "    with open(text_path, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(contents)\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        yield sentence.text\n",
    "\n",
    "magic_session.register(ie_function=sent_tokenization, ie_function_name = \"sent_tokenization\", in_rel=[DataTypes.string], out_rel=[DataTypes.string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'Sents(Path, Sent)':\n",
      "    Path     |                        Sent\n",
      "-------------+----------------------------------------------------\n",
      " sample1.txt |       COVID-19 results came back positive .\n",
      " sample1.txt | His family recently tested positive for COVID-19 .\n",
      " sample1.txt |    patient presents to be tested for COVID-19 .\n",
      " sample2.txt |               Results be positive .\n",
      " sample2.txt |        The patient be tested for COVID-19 .\n",
      " sample3.txt |                 COVID-19 like_num\n",
      " sample3.txt |          associated_diagnosis like_num .\n",
      " sample3.txt |             problem_list : like_num .\n",
      " sample4.txt |              neg COVID-19 education .\n",
      " sample5.txt |           positive COVID-19 precaution .\n",
      "\n",
      "printing results for query 'SentSpans(Path, Sent, SentSpan)':\n",
      "    Path     |                        Sent                        |  SentSpan\n",
      "-------------+----------------------------------------------------+------------\n",
      " sample1.txt |       COVID-19 results came back positive .        | [96, 133)\n",
      " sample1.txt | His family recently tested positive for COVID-19 . |  [45, 95)\n",
      " sample1.txt |    patient presents to be tested for COVID-19 .    |  [0, 44)\n",
      " sample2.txt |               Results be positive .                |  [37, 58)\n",
      " sample2.txt |        The patient be tested for COVID-19 .        |  [0, 36)\n",
      " sample3.txt |                 COVID-19 like_num                  |  [58, 75)\n",
      " sample3.txt |          associated_diagnosis like_num .           |  [26, 57)\n",
      " sample3.txt |             problem_list : like_num .              |  [0, 25)\n",
      " sample4.txt |              neg COVID-19 education .              |  [0, 24)\n",
      " sample5.txt |           positive COVID-19 precaution .           |  [0, 30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "#Sentences of the text\n",
    "Sents(Path, Sent) <- FilesPaths(Path), sent_tokenization(Path) -> (Sent)\n",
    "?Sents(Path, Sent)\n",
    "\n",
    "#SentSpan is the span of the sentence in the text\n",
    "SentSpans(Path, Sent, SentSpan) <- lemma_texts(Path, Text), Sents(Path, Sent), py_rgx_span(Text, Sent) -> (SentSpan)\n",
    "?SentSpans(Path, Sent, SentSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_span(span1, span2):\n",
    "    \"\"\"\n",
    "    Computes the relative position of the conatined span within the other span.\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "        span1 (Span): The first span object.\n",
    "        span2 (Span): The second span object.\n",
    "\n",
    "    Yields:\n",
    "        Span: The new relative span of the contained one.\n",
    "        None: If there's no span contained within the other.\n",
    "    \"\"\"\n",
    "    start1, end1 = span1.span_start, span1.span_end\n",
    "    start2, end2 = span2.span_start, span2.span_end\n",
    "    \n",
    "    if start2 <= start1 and end1 <= end2:\n",
    "        yield Span(span1.span_start - span2.span_start, span1.span_end - span2.span_start)\n",
    "        \n",
    "    elif start1 <= start2 and end2 <= end1:\n",
    "        yield Span(span2.span_start - span1.span_start, span2.span_end - span1.span_start)\n",
    "\n",
    "magic_session.register(get_relative_span, \"get_relative_span\", in_rel=[DataTypes.span, DataTypes.span], out_rel=[DataTypes.span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)':\n",
      "    Path     |  CovidSpan  |  CovidAttribute  |       Sent\n",
      "-------------+-------------+------------------+-------------------\n",
      " sample3.txt |   [0, 8)    |     positive     | COVID-19 like_num\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "CovidAttributes(Path, CovidSpan, CovidAttribute, Sent) <- SectionCovidAttributes(Path, AbsCovidSpan, CovidAttribute),\\\n",
    "SentSpans(Path, Sent, SentSpan) ,get_relative_span(AbsCovidSpan, SentSpan) -> (CovidSpan)\n",
    "?CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='context-rules'></a>\n",
    "### [Context Rules](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/context_rules.py):\n",
    "These rules assign an attribute for each COVID-19 label based on the context, these attributes will be used later to classify each text.\n",
    "\n",
    "Example for this rule is: \n",
    "\n",
    "    ConTextRule(\n",
    "        literal=\"Not Detected\",\n",
    "        category=\"NEGATED_EXISTENCE\",\n",
    "        direction=\"BACKWARD\",\n",
    "        pattern=[\n",
    "            {\"LOWER\": {\"IN\": [\"not\", \"non\"]}},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"TEXT\": \"-\", \"OP\": \"?\"},\n",
    "            {\"LOWER\": {\"REGEX\": \"detecte?d\"}},\n",
    "        ],\n",
    "        allowed_types={\"COVID-19\"},\n",
    "    ),\n",
    "   **direction** specify if the allowed_types should be before or after the pattern,\n",
    "   **allowed_types** specify on what labels should this rule be applied on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?i)(?:positive COVID-19|COVID-19 (?:\\([^)]*\\)) (?:positive|detected)|COVID-19(?: positive)? associated_diagnosis)#positive\n",
      "(?i)(?:COVID-19 status : positive)#positive\n",
      "(?i)(?:associated_diagnosis COVID-19|associated_diagnosis (?:with|w|w//|from) (?:associated_diagnosis )?COVID-19)#positive\n",
      "(?i)(?:COVID-19 positive(?: patient| precaution)?|associated_diagnosis (?:due|secondary) to COVID-19)#positive\n",
      "(?i)(?:(?:current|recent) COVID-19 diagnosis)#positive\n",
      "(?i)(?:COVID-19 (?:- )?related (?:admission|associated_diagnosis)|admitted (?:due to|(?:with|w|w/)) COVID-19)#positive\n",
      "(?i)(?:COVID-19 infection|b34(?:\\.)?2|b97.29|u07.1)#positive\n",
      "(?i)(?:COVID-19 eval(?:uation)?|(?:positive )? COVID-19 symptoms|rule out COVID-19)#uncertain\n",
      "(?i)(?:patient (?:do )?have COVID-19)#positive\n",
      "(?i)(?:diagnosis : COVID-19(?: (?:test|screen)(?:ing|ed|s)? positive)?(?: positive)?)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:not|non) (?:- )?detecte?d)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} negative screening|negative screening(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} : negative)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:not be|none) detected)#negated\n",
      "(?i)(?:free from(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? not (?:be )?tested)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} not indicated)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? NEGATIVE NEG)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,3} negative test)#negated\n",
      "(?i)(?:negative test(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#negated\n",
      "(?i)(?:without any(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:denie(?:s|d)(?: any| travel)?(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#negated\n",
      "(?i)(?:no (?:evidence(?: of)?|(?:hx|-hx|history) of|diagnosis (?:of)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:no(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:no (?:positive|one|residents|confirm case|contact(?: w/?(?:ith)?$))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? no confirm case)#negated\n",
      "(?i)(?:(?:no|n't) (?:be )? confirm(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:(?:no known|not have)(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:answer(?:ed|s|ing)? (?:no|negative|neg)|negative))#negated\n",
      "(?i)(?:(?:answer(?:ed|s|ing)? (?:no|negative|neg)|(?:neg|negative)(?: for)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:not positive(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? not positive)#negated\n",
      "(?i)(?:excluded(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,3} excluded)#negated\n",
      "(?i)(?:no risk factor for(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#uncertain\n",
      "(?i)(?:negative screening(?: for)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? screening (?:negative|neg))#negated\n",
      "(?i)(?:(?:screening (?:negative|neg) for|do (?:not|n't) have (?:any )?(?:signs|symptoms|ss|s/s))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? do not screening positive)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:be negative|not test positive))#negated\n",
      "(?i)(?:(?:be negative|not test positive|not? screening(?: for)|no signs of|no (?:sign|symptom|indication(?:of|for)?)|not? test(?:\\S+)? for)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:no exposure|(?:without|w/o) (?:signs|symptoms)(?:or (?:signs|symptoms))|do)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} not have)#negated\n",
      "(?i)(?:(?:(?:not|n't) have a (?:positive )?diagnosis|do not meet criteria|no concern (?:for|of)|not? (?:at )risk)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:(?:not|n't) have a (?:positive )?diagnosis|do not meet criteria))#negated\n",
      "(?i)(?:(?:no suspicion(?: for)|not suspect|ruled out for|no(?: recent) travel|not be in|clear(?:ed|s|ing) (?:of|for|from))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:not(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:be ruled out|be not likely|not have contact with))#negated\n",
      "(?i)(?:(?:no (?:hx|history) (?:of )travel|not have contact with|no symptoms of|no risk factors|no (?:confirm case|report))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:no (?:exposure|contact) (?:to|with)|not test(?:\\S+)? positive))#negated\n",
      "(?i)(?:(?:no (?:exposure|contact) (?:to|with)|do (?:not|n't) meet(?: screening)(?: criteria)(?: for)|not test(?:\\S+)? positive(?: for)|not tested(?: or diagnosis))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:no|any)(?: known) contact(?: with)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,3} : no)#negated\n",
      "(?i)(?:(?:(?:not|never) diagnosis with|not been tested (?:for )?or diagnosis with)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} confirm)#positive\n",
      "(?i)(?:(?:confirm|known)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#positive\n",
      "(?i)(?:(?:(?:test(?:\\S+)?)?positive(?: for)?|notif(?:y|ied) of positive (?:results?|test(?:\\S+)?|status))(?: (?!<IGNORE>)\\S+)*? COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:positiv(?:e|ity)|test(?:\\S+)? positive|(?:test|pcr) remains positive|notif(?:y|ied) of positive (?:results?|test(?:ing)?|status)))#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:positiv(?:e|ity)|test(?:\\S+)? positive|(?:test|pcr) remains positive|notif(?:y|ied) of positive (?:results?|test(?:ing)?|status)))#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} (?:positive status|results be positive))#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} results positive)#positive\n",
      "(?i)(?:results positive(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#positive\n",
      "(?i)(?:notif(?:y|ied) (?:the )? (?:veteran|patient|family) of positive (?:results?|test(?:ing)?|status)(?: (?!<IGNORE>)\\S+)*? COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? notif(?:y|ied) (?:the )? (?:veteran|patient|family) of positive (?:results?|test(?:ing)?|status))#positive\n",
      "(?i)(?:likely secondary to(?: (?!<IGNORE>)\\S+){0,0} COVID-19)#positive\n",
      "(?i)(?:(?:problem(?: list)? (?:of|:)|(?:active|current|acute) problems :|admi(?:t|ssion) diagnosis(?: :)?)(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#positive\n",
      "(?i)(?:(?:reason for admission :|treatment of|(?:admitting )diagnosis(?: :)?)(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,3} diagnosis like_num)#positive\n",
      "(?i)(?:(?:Reason for admission :|inpatient with|discharged from|in m?icu (?:for|with))(?: (?!<IGNORE>)\\S+){0,5} COVID-19)#admission\n",
      "(?i)(?:(?:admit(?:ted|s|ting) (?:like_num|with|for)|admitted (?:to|on)|Reason for ICU :|admission for)(?: (?!<IGNORE>)\\S+)*? COVID-19)#admission\n",
      "(?i)(?:Reason for ED visit or Hospital Admission :(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#admission\n",
      "(?i)(?:(?:(?:in|to) (?:the )(?:hospital|icu|micu) (?:for|due to)|hospitali(?:zed)?(?: timesx)? (?:for|due to))(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#admission\n",
      "(?i)(?:(?:diagnosis with|found to be positive for)(?: (?!<IGNORE>)\\S+){0,5} COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,5} found to be positive)#positive\n",
      "(?i)(?:(?:positive test|presum(?:e|ed|es|ing) positive|not(?: yet)? recover(?:s|ing|ed)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:positive test|presum(?:e|ed|es|ing) positive))#positive\n",
      "(?i)(?:(?:management of|ards(?: (?:from|with|secondary to))?|acute respiratory distress|post - extubation)(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#positive\n",
      "(?i)(?:(?:in(?: the)? setting of|in the s / o|found to have|present(?:s|ed|ing)? with)(?: (?!<IGNORE>)\\S+){0,5} COVID-19)#positive\n",
      "(?i)(?:resp(?:iratory) failure(?:(?: (?:with|due to))?|like_num|\\( like_num \\))(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#positive\n",
      "(?i)(?:(?:active(?: for)|recovering from)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} recovering from)#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} (?:detected|value : detected|POSITIVEH))#positive\n",
      "(?i)(?:(?:\\d+(?: )?-|like_num )year(?:(?: )?-(?: )?old| old) (?:(?:aa|white|black|hispanic|caucasian) )?(?:\\b(?!family\\b|other_experiencer\\b)\\S+\\b )?(?:with|w|w/|admitted)(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#patient_experiencer\n",
      "(?i)(?:(?:like_num (?:y[or]|y / o)|[\\d]+yo) (?:\\b(?!family\\b|other_experiencer\\b)\\S+\\b )?(?:patient |veteran )?(?:with|w|w/)(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#patient_experiencer\n",
      "(?i)(?:the (?:veteran|vet|patient) have(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#patient_experiencer\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} precaution)#future\n",
      "(?i)(?:(?:(?:precaution|protection|protect) (?:for|against)|concern about|reports of|vaccine|protect yourself|prevent(?:ed|ion|s|ing)|avoid)(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:prevent(?:ed|ion|s|ing)|vaccine|educat\\S*|instruction))#future\n",
      "(?i)(?:(?:questions (?:about|regarding|re|concerning|on|for)|(?:anxiety|ask(?:ing|ed|es|ed)?) about|educat(?:ion|ed|ing|ed)?|instruction)(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:(?:information(?: )?(?:on|about|regarding|re)?|protocols?)(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#future\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} protocols?)#future\n",
      "(?i)(?:(?:materials|fact(?: )?sheet|literature|(?:informat(?:ion|ed|ing) )?handouts?|(?:anxious|worr(?:ied|ies|y|ying)) (?:about|re|regarding))(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:materials|fact(?: )?sheet|literature|(?:informat(?:ion|ed|ing) )?handouts?))#future\n",
      "(?i)(?:if(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#future\n",
      "(?i)(?:(?:advisor(?:y|ies)|travel screen(?: :)?|Travel History Questionnaire|prescreen|front gate)(?: (?!<IGNORE>)\\S+)*? COVID-19)#screening\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} (?:questionnaire :|questionn?aire|question\\S*|prescreen|front gate))#screening\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,9} screen\\S*)#screening\n",
      "(?i)(?:screen\\S*(?: (?!<IGNORE>)\\S+){0,9} COVID-19)#screening\n",
      "(?i)(?:have you(?: (?!<IGNORE>)\\S+)*? COVID-19)#not relevant\n",
      "(?i)(?:(?:mers)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:This patient was screened for the following suspected travel related illness(?:es)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? This patient was screened for the following suspected travel related illness(?:es)?)#future\n",
      "(?i)(?:(?:will(?: be) travel|travel plans|if you need|plan to travel)(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:(?:(?:limit|reduce|lower|minimize)(?: the)? (?:risk|chance|possibility) of|if you)(?: (?!<IGNORE>)\\S+)*? COVID-19)#future\n",
      "(?i)(?:(?:(?:(?:-)?hx|history|) of)(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#negated\n",
      "(?i)(?:(?:^(?:check|test|retest|eval)(?: for)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#test\n",
      "(?i)(?:(?:work(?:-|\\s)up)(?: (?!<IGNORE>)\\S+)*? COVID-19)#test\n",
      "(?i)(?:(?:evaluation)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#test\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} (?:evaluation))#test\n",
      "(?i)(?:(?:swab|PCR|specimen sent)(?: (?!<IGNORE>)\\S+)*? COVID-19)#test\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:swab|PCR|specimen sent))#test\n",
      "(?i)(?:(?:awaiting results|at risk for|risk for|currently being ruled out or has tested positive for|to exclude)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:awaiting results|currently being ruled out or has tested positive for|(?:patient|person) of interest))#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,0} (?:risk))#uncertain\n",
      "(?i)(?:(?:investigation of)(?: (?!<IGNORE>)\\S+){0,0} COVID-19)#uncertain\n",
      "(?i)(?:(?:question of|differential diagnosis :|ddx :)(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#uncertain\n",
      "(?i)(?:(?:awaiting|questionnaire|r(?:/)?o(?:\\.)?)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} (?:awaiting|questionnaire|r(?:/)?o(?:\\.)?))#uncertain\n",
      "(?i)(?:(?:under investigation|(?:may|might) be positive(?: for)?|flew|tarvel(?:ed)?|travelled)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:under investigation|(?:may|might) be positive))#uncertain\n",
      "(?i)(?:(?:facility (?:with|has)(?: a)?|known to have|(?:same )?room|patients with)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:(?:area|county|community|city) (?:with|of)|in the building|(?:several|multiple|one)(?:of )?(?:the )? other_experiencer)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:in the building))#negated\n",
      "(?i)(?:(?:(?:he|she) thinks (?:he|she) (?:have|had|has)|\\S+ would like)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:positive (?:screen|criteria|triage)|(?:^test )?pending|screen positive|unlikely to be)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:positive (?:screen|criteria|triage)|(?:^test )?pending|screen positive|possible positive))#uncertain\n",
      "(?i)(?:(?:(?:possible|potential)? exposure|possibly|possible positive)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:(?:risk of|likely|probable|probably)(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#uncertain\n",
      "(?i)(?:(?:suspicion(?: for)?|^suspect|differential diagnosis|ddx(?: :)?|doubt)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:suspicion|^suspect|differential diagnosis|ddx(?: :)?|may have been exposed))#uncertain\n",
      "(?i)(?:(?:(?:positive )?(?:sign|symptom) of)(?: (?!<IGNORE>)\\S+){0,3} COVID-19)#uncertain\n",
      "(?i)(?:(?:sx|s/s|rule (?:- )out|be ruled out(?: for)?|^(?:vs\\.?|versus)$)(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} (?:sx|s/s|rule (?:- )out|^(?:vs\\.?|versus)$))#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:(?:possible|potential)? exposure|may have been exposed))#uncertain\n",
      "(?i)(?:(?:concern(:?s)?(?: for| of)?|if (?:negative|positive)|c/f|assess(?:ed)? for|concerning for)(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:(?:unlikely(?: to be positive)?|low (?:suspicion|probability|risk (?:for|in|of)))(?: (?!<IGNORE>)\\S+)*? COVID-19)#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:unlikely(?: to be positive)?|low (?:suspicion|probability)|is unlikely))#uncertain\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,2} (?:extremely low))#uncertain\n",
      "(?i)(?:(?:low risk of)(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#uncertain\n",
      "(?i)(?:(?:(?:other_experiencer|family) ^test positive(?: for)?|any one|contact with(?: known))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:other_experiencer|family)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:other_experiencer|any one|contact with(?: known)))#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,0} (?:(?:a|an|another) \\S+ tested positive))#negated\n",
      "(?i)(?:(?:had contact|same (?:building|floor)|care for|clean)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:had contact|same (?:building|floor)|care for|clean))#negated\n",
      "(?i)(?:(?:concern(?:ed)? about)(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#negated\n",
      "(?i)(?:(?:patient concern (?:for|of)|desire|(?:concerned|prepare) (?:for|about))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:seen in|a (?:positive|confirmed) case of|cases|epidemic|pandemic)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,1} (?:cases|epidemic|pandemic|national emergency|crisis|situation|mandate|\\?))#negated\n",
      "(?i)(?:(?:national emergency|crisis|situation|mandate)(?: (?!<IGNORE>)\\S+){0,1} COVID-19)#negated\n",
      "(?i)(?:(?:seen in(?: the)? setting of)(?: (?!<IGNORE>)\\S+){0,5} COVID-19)#negated\n",
      "(?i)(?:(?:^cancel (?:flight|plan|trip|vacation)|supposed to (?:travel|go|visit)|called off|goals :)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:^cancel (?:flight|plan|trip|vacation)|supposed to (?:travel|go|visit)|called off))#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:in the (?:area|community)|outbreak))#negated\n",
      "(?i)(?:(?:in the (?:area|community)|outbreak)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:news|media|tv|television|broadcast|headline(?:s)?|newspaper(?:s)?|clinic cancellation)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:news|media|tv|television|broadcast|headline(?:s)?|newspaper(?:s)?|clinic cancellation))#negated\n",
      "(?i)(?:(?:^read about|deploy|(?:come|been) in close contact(?: with)?)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:^read about|deploy|(?:come|been) in close contact(?: with)?|error))#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:have you had close contact|web(?:\\s)?site|internet|world(?:\\s|-)?wide|countries with cases))#negated\n",
      "(?i)(?:(?:have you had close contact|the group|session|(?:nurse(?:s)?|rn) notes)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:web(?:\\s)?site|internet|world(?:\\s|-)?wide|countries with cases|error)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:(?:(?:person|patients) with(?: confirmed)?(?: or)?(?: suspected)?|cases of)(?: (?!<IGNORE>)\\S+){0,2} COVID-19)#negated\n",
      "(?i)(?:elective(?: (?!<IGNORE>)\\S+){0,4} COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,4} elective)#negated\n",
      "(?i)(?:(?:reschedule|barrier to travel|positive (?:individual(?:s)?|contact(?:s)?|patient(?:s)?))(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:reschedule|barrier to travel|positive (?:individual(?:s)?|contact(?:s)?|patient(?:s)?)))#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:(?:someone|person) who (?:has|have) tested positive|contact with))#negated\n",
      "(?i)(?:(?:(?:someone|person) who (?:has|have) tested positive|contact with)(?: (?!<IGNORE>)\\S+)*? COVID-19)#negated\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+){0,0} (?:\\(resolved\\)))#positive\n",
      "(?i)(?:COVID-19(?: (?!<IGNORE>)\\S+)*? (?:social worker|initially negative|likely recovered|not aware|positive (?:case|symptom|sign)|client history|emergency contact|several positive|special instructions :))#IGNORE\n",
      "(?i)(?:(?:social worker|initially negative|likely recovered|not aware|positive (?:case|symptom|sign)|client history|emergency contact|several positive|special instructions :)(?: (?!<IGNORE>)\\S+)*? COVID-19)#IGNORE"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat context_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"context_rules.csv\", relation_name=\"ContextRules\", delimiter=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'ContextMatches(CovidAttribute, Span, Path, Sent)':\n",
      "  CovidAttribute  |   Span   |    Path     |                        Sent\n",
      "------------------+----------+-------------+----------------------------------------------------\n",
      "     positive     | [0, 35)  | sample1.txt |       COVID-19 results came back positive .\n",
      "     positive     | [27, 48) | sample1.txt | His family recently tested positive for COVID-19 .\n",
      "     negated      | [4, 48)  | sample1.txt | His family recently tested positive for COVID-19 .\n",
      "     negated      | [0, 12)  | sample4.txt |              neg COVID-19 education .\n",
      "      future      | [4, 22)  | sample4.txt |              neg COVID-19 education .\n",
      "     positive     | [0, 17)  | sample5.txt |           positive COVID-19 precaution .\n",
      "      future      | [9, 28)  | sample5.txt |           positive COVID-19 precaution .\n",
      "\n",
      "printing results for query 'CovidSpans(Path, Span, Sent)':\n",
      "    Path     |   Span   |                        Sent\n",
      "-------------+----------+----------------------------------------------------\n",
      " sample1.txt |  [0, 8)  |       COVID-19 results came back positive .\n",
      " sample1.txt | [40, 48) | His family recently tested positive for COVID-19 .\n",
      " sample1.txt | [34, 42) |    patient presents to be tested for COVID-19 .\n",
      " sample2.txt | [26, 34) |        The patient be tested for COVID-19 .\n",
      " sample3.txt |  [0, 8)  |                 COVID-19 like_num\n",
      " sample4.txt | [4, 12)  |              neg COVID-19 education .\n",
      " sample5.txt | [9, 17)  |           positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "#covid_attributes: negated, other_experiencer, is_future, not_relevant, uncertain, positive\n",
    "ContextMatches(CovidAttribute, Span, Path, Sent) <- Sents(Path, Sent), ContextRules(Pattern, CovidAttribute),\\\n",
    "py_rgx_span(Sent, Pattern) -> (Span)\n",
    "?ContextMatches(CovidAttribute, Span, Path, Sent)\n",
    "\n",
    "CovidSpans(Path, Span, Sent) <- Sents(Path, Sent), py_rgx_span(Sent, \"COVID-19\") -> (Span)\n",
    "?CovidSpans(Path, Span, Sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)':\n",
      "    Path     |  CovidSpan  |  CovidAttribute  |                        Sent\n",
      "-------------+-------------+------------------+----------------------------------------------------\n",
      " sample1.txt |   [0, 8)    |     positive     |       COVID-19 results came back positive .\n",
      " sample1.txt |  [40, 48)   |     negated      | His family recently tested positive for COVID-19 .\n",
      " sample1.txt |  [40, 48)   |     positive     | His family recently tested positive for COVID-19 .\n",
      " sample3.txt |   [0, 8)    |     positive     |                 COVID-19 like_num\n",
      " sample4.txt |   [4, 12)   |      future      |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |     negated      |              neg COVID-19 education .\n",
      " sample5.txt |   [9, 17)   |      future      |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |     positive     |           positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "CovidAttributes(Path, CovidSpan, CovidAttribute, Sent) <- ContextMatches(CovidAttribute, Span1, Path, Sent), CovidSpans(Path, Span2, Sent), is_span_contained(Span1, Span2) -> (CovidSpan)\n",
    "?CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='postprocess-rules'></a>\n",
    "### [Postprocessor](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/postprocess_rules.py):\n",
    "These rules assign an additional attribute for each COVID-19 mention based on its attributes or the context of the sentences they are part of. This way, we can be flexible and fix problems with the data and make specific improvements. For example, they can be handy for spotting and correcting wrongly tagged positive cases, making our classification more accurate.\n",
    "\n",
    "\n",
    "Example rule in the original project:\n",
    "\n",
    "PostprocessingRule(\n",
    "        patterns=[\n",
    "        \n",
    "            PostprocessingPattern(lambda ent: ent.label_ == \"COVID-19\"),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.sentence_contains,\n",
    "                condition_args=({\"deny\", \"denies\", \"denied\"},),\n",
    "            ),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.sentence_contains,\n",
    "                condition_args=({\"contact\", \"contacts\", \"confirmed\"},),\n",
    "            ),\n",
    "        ],\n",
    "        action=postprocessing_functions.remove_ent,\n",
    "        description=\"Remove a coronavirus entity if 'denies' and 'contact' are in. This will help get rid of false positives from screening.\",\n",
    "    ),    \n",
    "\n",
    "This rule iterates through each entity and checks a series of conditions which are the \"PostprocessingPattern\". If all conditions evaluate as True, then some action is taken on the entity, which is 'remove' action in this example. Some other actions could include changing attributes.\n",
    "\n",
    "\n",
    "In our case, we assign \"IGNORE\" attribute to the COVID-19 mention causing it to be excluded from consideration during the document classification process.\n",
    "\n",
    "Each rule in the CSV file follows this format: regexPattern, Attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*education.*#IGNORE\n",
      ".* \\?#IGNORE\n",
      "(?=.*\\b(?:deny|denies|denied)\\b)(?=.*\\b(?:contact|confirm)\\b).*#IGNORE\n",
      "(?=.*\\b(?:setting of|s/o)\\b)(?!.*\\b(?:COVID-19 infection|COVID-19 ards)\\b).*#no_positive\n",
      "(?i)(.*benign.*)#uncertain\n",
      "admitted to COVID-19 unit#positive"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat postprocess_pattern_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"postprocess_pattern_rules.csv\", relation_name=\"PostprocessRules\", delimiter=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'PostprocessMatches(CovidAttribute, Span, Path, Sent)':\n",
      "  CovidAttribute  |  Span   |    Path     |           Sent\n",
      "------------------+---------+-------------+--------------------------\n",
      "      IGNORE      | [0, 24) | sample4.txt | neg COVID-19 education .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "PostprocessMatches(CovidAttribute, Span, Path, Sent) <- Sents(Path, Sent), PostprocessRules(Pattern, CovidAttribute),\\\n",
    "py_rgx_span(Sent, Pattern) -> (Span)\n",
    "?PostprocessMatches(CovidAttribute, Span, Path, Sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)':\n",
      "    Path     |  CovidSpan  |  CovidAttribute  |                        Sent\n",
      "-------------+-------------+------------------+----------------------------------------------------\n",
      " sample1.txt |   [0, 8)    |     positive     |       COVID-19 results came back positive .\n",
      " sample1.txt |  [40, 48)   |     negated      | His family recently tested positive for COVID-19 .\n",
      " sample1.txt |  [40, 48)   |     positive     | His family recently tested positive for COVID-19 .\n",
      " sample3.txt |   [0, 8)    |     positive     |                 COVID-19 like_num\n",
      " sample4.txt |   [4, 12)   |      IGNORE      |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |      future      |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |     negated      |              neg COVID-19 education .\n",
      " sample5.txt |   [9, 17)   |      future      |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |     positive     |           positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "CovidAttributes(Path, CovidSpan, CovidAttribute, Sent) <- PostprocessMatches(CovidAttribute, Span1, Path, Sent), CovidSpans(Path, Span2, Sent), is_span_contained(Span1, Span2) -> (CovidSpan)\n",
    "?CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocess rules with attributes example:\n",
    "\n",
    "PostprocessingRule(\n",
    "        patterns=[\n",
    "        \n",
    "            PostprocessingPattern(lambda ent: ent.label_ == \"COVID-19\"),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.is_modified_by_category,\n",
    "                condition_args=(\"DEFINITE_POSITIVE_EXISTENCE\",),\n",
    "            ),\n",
    "            # PostprocessingPattern(postprocessing_functions.is_modified_by_category, condition_args=(\"TEST\",)),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.sentence_contains,\n",
    "                condition_args=(\n",
    "                    {\n",
    "                        \"should\",\n",
    "                        \"unless\",\n",
    "                        \"either\",\n",
    "                        \"if comes back\",\n",
    "                        \"if returns\",\n",
    "                        \"if s?he tests positive\",\n",
    "                    },\n",
    "                    True,\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "        action=set_is_uncertain,\n",
    "        action_args=(True,),\n",
    "        description=\"Subjunctive of test returning positive. 'Will contact patient should his covid-19 test return positive.'\",\n",
    "    ),\n",
    "\n",
    "This rule examines whether a COVID-19 mention possesses a positive attribute and if the sentence containing it includes any of the words specified in 'condition_args' If these conditions are met, the uncertain attribute is set to true.\n",
    "\n",
    "\n",
    "In our case, we check for each COVID-19 mention in the 'CovidAttributes' table if it's labeled as 'positive', also, we check if any of the specified words in 'condition_args' are present in the same sentence using a regex search. If the conditions are met, then we simply assign it an 'uncertain' attribute.\n",
    "\n",
    "Each rule in the CSV file follows this format: regexPattern, ExistingAttribute, NewAttribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*pending.*#negated#no_negated\n",
      ".*(?:should|unless|either|if comes back|if returns|if s?he tests positive).*#positive#uncertain\n",
      ".*precaution.*#positive#no_future\n",
      ".*(?:re[ -]?test|second test|repeat).*#negated#no_negated\n",
      ".*(?:sign|symptom|s/s).*#positive#uncertain"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat postprocess_attributes_rules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"postprocess_attributes_rules.csv\", relation_name=\"PostprocessRulesWithAttributes\", delimiter=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'PostprocessWithAttributesMatches(CovidAttribute, NewAttribute, Span, Path, Sent)':\n",
      "  CovidAttribute  |  NewAttribute  |  Span   |    Path     |              Sent\n",
      "------------------+----------------+---------+-------------+--------------------------------\n",
      "     positive     |   no_future    | [0, 30) | sample5.txt | positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "PostprocessWithAttributesMatches(CovidAttribute, NewAttribute, Span, Path, Sent) <- Sents(Path, Sent), PostprocessRulesWithAttributes(Pattern, CovidAttribute, NewAttribute),\\\n",
    "py_rgx_span(Sent, Pattern) -> (Span)\n",
    "?PostprocessWithAttributesMatches(CovidAttribute, NewAttribute, Span, Path, Sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'CovidAttributes(Path, CovidSpan, NewAttribute, Sent)':\n",
      "    Path     |  CovidSpan  |  NewAttribute  |                        Sent\n",
      "-------------+-------------+----------------+----------------------------------------------------\n",
      " sample1.txt |   [0, 8)    |    positive    |       COVID-19 results came back positive .\n",
      " sample1.txt |  [40, 48)   |    negated     | His family recently tested positive for COVID-19 .\n",
      " sample1.txt |  [40, 48)   |    positive    | His family recently tested positive for COVID-19 .\n",
      " sample3.txt |   [0, 8)    |    positive    |                 COVID-19 like_num\n",
      " sample4.txt |   [4, 12)   |     IGNORE     |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |     future     |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |    negated     |              neg COVID-19 education .\n",
      " sample5.txt |   [9, 17)   |     future     |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |   no_future    |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |    positive    |           positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "CovidAttributes(Path, CovidSpan, NewAttribute, Sent) <- CovidAttributes(Path, CovidSpan, CovidAttribute, Sent), PostprocessWithAttributesMatches(CovidAttribute, NewAttribute, Span, Path, Sent)\n",
    "?CovidAttributes(Path, CovidSpan, NewAttribute, Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocess rules with next_sentence:\n",
    "\n",
    "There's a rule that checks if the following sentence contains positive mentions. If it does, the COVID-19 mentions in the current sentence are also\n",
    "marked as positive. To Implement this rule in our project, we defined a new relation that pairs each sentence with its subsequent sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_sent(text_path):\n",
    "    with open(text_path, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(contents)\n",
    "\n",
    "    # Tokenize sentences\n",
    "    sentences = list(doc.sents)\n",
    "    for i in range(len(sentences) - 1):  # Iterate until the second-to-last sentence\n",
    "        yield(sentences[i].text, sentences[i + 1].text)\n",
    "\n",
    "magic_session.register(ie_function=next_sent, ie_function_name = \"next_sent\", in_rel=[DataTypes.string], out_rel=[DataTypes.string,DataTypes.string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'NextSent(Path, Sent1, Sent2)':\n",
      "    Path     |                       Sent1                        |                       Sent2\n",
      "-------------+----------------------------------------------------+----------------------------------------------------\n",
      " sample1.txt | His family recently tested positive for COVID-19 . |       COVID-19 results came back positive .\n",
      " sample1.txt |    patient presents to be tested for COVID-19 .    | His family recently tested positive for COVID-19 .\n",
      " sample2.txt |        The patient be tested for COVID-19 .        |               Results be positive .\n",
      " sample3.txt |          associated_diagnosis like_num .           |                 COVID-19 like_num\n",
      " sample3.txt |             problem_list : like_num .              |          associated_diagnosis like_num .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "NextSent(Path, Sent1, Sent2) <- FilesPaths(Path), next_sent(Path) -> (Sent1, Sent2)\n",
    "?NextSent(Path, Sent1, Sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)':\n",
      "    Path     |  CovidSpan  |  CovidAttribute  |                        Sent\n",
      "-------------+-------------+------------------+----------------------------------------------------\n",
      " sample1.txt |   [0, 8)    |     positive     |       COVID-19 results came back positive .\n",
      " sample1.txt |  [40, 48)   |     negated      | His family recently tested positive for COVID-19 .\n",
      " sample1.txt |  [40, 48)   |     positive     | His family recently tested positive for COVID-19 .\n",
      " sample2.txt |  [26, 34)   |     positive     |        The patient be tested for COVID-19 .\n",
      " sample3.txt |   [0, 8)    |     positive     |                 COVID-19 like_num\n",
      " sample4.txt |   [4, 12)   |      IGNORE      |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |      future      |              neg COVID-19 education .\n",
      " sample4.txt |   [4, 12)   |     negated      |              neg COVID-19 education .\n",
      " sample5.txt |   [9, 17)   |      future      |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |    no_future     |           positive COVID-19 precaution .\n",
      " sample5.txt |   [9, 17)   |     positive     |           positive COVID-19 precaution .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "new PostProcessWithNextSentenceRules(str, str)\n",
    "PostProcessWithNextSentenceRules(\"(?i)(?:^(?:positive|detected)|results?(?: be)? positive)\", \"positive\")\n",
    "PostProcessWithNextSentenceMatches(CovidAttribute, Span, Path, Sent) <- Sents(Path, Sent), PostProcessWithNextSentenceRules(Pattern, CovidAttribute),\\\n",
    "py_rgx_span(Sent, Pattern) -> (Span)\n",
    "\n",
    "CovidAttributes(Path, CovidSpan, CovidAttribute, Sent1) <- CovidSpans(Path, CovidSpan, Sent1), NextSent(Path, Sent1, Sent2), PostProcessWithNextSentenceMatches(CovidAttribute, Span, Path, Sent2)\n",
    "?CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='document_classifier'></a>\n",
    "### [Document Classifier](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/blob/master/cov_bsv/knowledge_base/document_classifier.py):\n",
    "Now we have the basic pieces in place to make our document classification. Each document is classified as either 'POS', 'UNK', or 'NEG' determined by the attributes of its COVID-19 mentions. The Results are stored in a DataFrame.\n",
    "\n",
    "Document Classifier stage has 2 parts:\n",
    " 1) **Attribute filtering**: Our pipeline assigns various attributes to each COVID-19 mention. However, during this stage, each COVID-19 case is refined to possess only one attribute. This filtering process operates based on specific conditions outlined in the 'attribute_filter' function.\n",
    " 2) **Document classification**: Documents are classified based on distinct conditions, as detailed in the 'classify_doc_helper' function. This step ensures the accurate categorization of each document according to the specified criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_filter(group):\n",
    "    \"\"\"\n",
    "    Filters attributes within each \"CovidSpan\" of a DataFrame table based on specific conditions.\n",
    "\n",
    "    Parameters:\n",
    "        group (pandas.Series): A pandas Series representing attributes for each \"CovidSpan\" within a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        str: Filtered \"CovidSpan\" attribute determined by the following rules:\n",
    "            - If 'IGNORE' is present, returns 'IGNORE'.\n",
    "            - If 'negated' is present (and 'no_negated' is not present), returns 'negated'.\n",
    "            - If 'future' is present (and 'no_future' is not present), returns 'negated'.\n",
    "            - If 'other experiencer' or 'not relevant' is present, returns 'negated'.\n",
    "            - If 'positive' is present (and 'uncertain' and 'no_positive' are not present), returns 'positive'.\n",
    "            - Otherwise, returns 'uncertain'.\n",
    "    \"\"\"\n",
    "    if 'IGNORE' in group.values:\n",
    "        return 'IGNORE'\n",
    "    elif 'negated' in group.values and not 'no_negated' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'future' in group.values and not 'no_future' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'other experiencer' in group.values or 'not relevant' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'positive' in group.values and not 'uncertain' in group.values and not 'no_positive' in group.values:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'uncertain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>CovidSpan</th>\n",
       "      <th>CovidAttribute</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>[0, 8)</td>\n",
       "      <td>positive</td>\n",
       "      <td>COVID-19 results came back positive .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>[40, 48)</td>\n",
       "      <td>negated</td>\n",
       "      <td>His family recently tested positive for COVID-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>[26, 34)</td>\n",
       "      <td>positive</td>\n",
       "      <td>The patient be tested for COVID-19 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>[0, 8)</td>\n",
       "      <td>positive</td>\n",
       "      <td>COVID-19 like_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>[4, 12)</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>neg COVID-19 education .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>[9, 17)</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive COVID-19 precaution .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path CovidSpan CovidAttribute  \\\n",
       "0  sample1.txt    [0, 8)       positive   \n",
       "1  sample1.txt  [40, 48)        negated   \n",
       "2  sample2.txt  [26, 34)       positive   \n",
       "3  sample3.txt    [0, 8)       positive   \n",
       "4  sample4.txt   [4, 12)         IGNORE   \n",
       "5  sample5.txt   [9, 17)       positive   \n",
       "\n",
       "                                                Sent  \n",
       "0              COVID-19 results came back positive .  \n",
       "1  His family recently tested positive for COVID-...  \n",
       "2               The patient be tested for COVID-19 .  \n",
       "3                                  COVID-19 like_num  \n",
       "4                           neg COVID-19 education .  \n",
       "5                     positive COVID-19 precaution .  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (session.run_commands(\"?CovidAttributes(Path, CovidSpan, CovidAttribute, Sent)\", print_results=False, format_results=True))[0]\n",
    "if len(df) == 0:\n",
    "    df = DataFrame(columns=[\"Path\",\"CovidSpan\",\"CovidAttribute\"])\n",
    "df['CovidAttribute'] = df.groupby(['CovidSpan', 'Sent'])['CovidAttribute'].transform(attribute_filter)\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_doc_helper(group):\n",
    "    \"\"\"\n",
    "Classifies a document as 'POS', 'UNK', or 'NEG' based on COVID-19 attributes.\n",
    "\n",
    "Parameters:\n",
    "    group (pandas.Series): A pandas Series representing COVID-19 attributes for each document within a DataFrame.\n",
    "    \n",
    "Returns:\n",
    "    str: Document classification determined as follows:\n",
    "         - 'POS': If at least one COVID-19 attribute with \"positive\" is present in the group.\n",
    "         - 'UNK': If at least one COVID-19 attribute with \"uncertain\" is present in the group and no \"positive\" attributes,\n",
    "                  or there's at least one COVID-19 attribute with 'IGNORE' and no other COVID-19 attributes exist.\n",
    "         - 'NEG': Otherwise.\n",
    "\"\"\"\n",
    "    if 'positive' in group.values:\n",
    "        return 'POS'\n",
    "    elif 'uncertain' in group.values:\n",
    "        return 'UNK'\n",
    "    elif 'negated' in group.values:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>DocResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path DocResult\n",
       "0  sample1.txt       POS\n",
       "1  sample2.txt       POS\n",
       "2  sample3.txt       POS\n",
       "3  sample4.txt       UNK\n",
       "4  sample5.txt       POS"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DocResult'] = df.groupby('Path')['CovidAttribute'].transform(classify_doc_helper)\n",
    "df = df[['Path', 'DocResult']]\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>DocResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path DocResult\n",
       "0  sample1.txt       POS\n",
       "1  sample2.txt       POS\n",
       "2  sample3.txt       POS\n",
       "3  sample4.txt       UNK\n",
       "4  sample5.txt       POS"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path = (session.run_commands(\"?FilesPaths(Path)\", print_results=False, format_results=True))[0]\n",
    "df = (pd.merge(df, df_path, on='Path', how='outer'))\n",
    "df['DocResult'] = df['DocResult'].fillna(\"UNK\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
