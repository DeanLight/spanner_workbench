# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/008_extended_RA_operations.ipynb.

# %% auto 0
__all__ = ['logger', 'equalConstTheta', 'equalColTheta', 'get_const', 'select', 'project', 'rename', 'union', 'intersection',
           'difference', 'join', 'product', 'assert_tuple_like', 'assert_ie_schema', 'assert_iterable', 'map_iter',
           'ie_map']

# %% ../nbs/008_extended_RA_operations.ipynb 4
import pytest
import pandas as pd
pd.set_option("mode.copy_on_write", True)
import numpy as np
from typing import no_type_check, Set, Sequence, Any,Optional,List,Callable,Dict,Union
import networkx as nx
import itertools

from .utils import serialize_df_values
from .span import Span
from .data_types import _infer_relation_schema,pretty

import logging
logger = logging.getLogger(__name__)

# %% ../nbs/008_extended_RA_operations.ipynb 5
def _col_names(length):
    # these names wont conflixt with logical variables since they must always start with Uppercase letters
    return [f'col_{i}' for i in range(length)]



# %% ../nbs/008_extended_RA_operations.ipynb 9
# some select theta functions

class equalConstTheta():
    def __init__(self,*pos_val_tuples):
        self.pos_val_tuples = pos_val_tuples
    def __call__(self,df):
        masks = [df.iloc[:,pos]==val for pos,val in self.pos_val_tuples]
        return pd.concat(masks,axis=1).all(axis=1)
    def __str__(self):
        return f'''Theta({', '.join([f'col_{pos}={val}' for pos,val in self.pos_val_tuples])})'''
    def __repr__(self):
        return str(self)
    def __eq__(self,other):
        if not isinstance(other,equalConstTheta):
            return False
        return self.pos_val_tuples == other.pos_val_tuples

class equalColTheta():
    def __init__(self,*col_pos_tuples):
        self.col_pos_tuples = col_pos_tuples

    def __call__(self,df):
        masks = [df.iloc[:,pos1]==df.iloc[:,pos2] for pos1,pos2 in self.col_pos_tuples]
        return pd.concat(masks,axis=1).all(axis=1)    
    def __str__(self):
        return f'''Theta({', '.join([f'col_{pos1}=col_{pos2}' for pos1,pos2 in self.col_pos_tuples])})'''
    def __repr__(self):
        return str(self)
    def __eq__(self,other):
        if not isinstance(other,equalColTheta):
            return False
        return self.col_pos_tuples == other.col_pos_tuples

# %% ../nbs/008_extended_RA_operations.ipynb 13
def get_const(const_dict,**kwargs):
    return pd.DataFrame([const_dict])

# %% ../nbs/008_extended_RA_operations.ipynb 16
def select(df,theta,**kwargs):
    if df.empty:
        return df

    if callable(theta):
        return df[theta(df)]
    else:
        raise ValueError(f"theta must be callable, got {theta}")

def project(df,on=None,not_on=None,**kwargs):
    if df.empty and len(df.columns)==0:
        return df
    if on is None and not_on is None:
        raise Value("either on or not_on must be specified")
    if on is not None:
        return df[on]
    else:
        return df.drop(columns=not_on)

def rename(df,names,**kwargs):
    if df.empty and len(df.columns)==0:
        return df
    df=df.copy()
    new_names = list(df.columns)
    for i,name in names:
        new_names[i]=name
    df.columns = new_names
    return df

def union(*dfs,**kwargs):
    # use numpy arrays to ignore column names
    non_empty_dfs = [df for df in dfs if not df.empty]
    if len(non_empty_dfs)==0:
        return dfs[0]
    return pd.DataFrame(np.concatenate(non_empty_dfs,axis=0)).drop_duplicates()

def intersection(df1,df2,**kwargs):
    return pd.merge(df1,df2,how='inner',on=list(df1.columns))

def difference(df1,df2,**kwargs):
    return pd.concat([df1,df2]).drop_duplicates(keep=False)

def join(df1,df2,**kwargs):
    cols1 = set(df1.columns)
    cols2 = set(df2.columns)
    on = cols1 & cols2
    # get only logical variables
    on = [ col for col in on if isinstance(col,str) and col[0].isupper()]
    if len(on)==0:
        return pd.merge(df1,df2,how='cross')
    else:
        return pd.merge(df1,df2,how='inner',on=on)

def product(df1,df2,**kwargs):
    return pd.merge(df1,df2,how='cross')

# %% ../nbs/008_extended_RA_operations.ipynb 41
def assert_tuple_like(name,func,input,output):
    if not isinstance(output,(tuple,list)):
        raise ValueError(f"IEFunction {name} with underlying function {func}\n"
                         f"returned a value that is not a tuple/list\n"
                         f"for input output pair ({input},{output})"
                         f"did you remember to return the output as a tuple/list?")

def assert_ie_schema(name,func,value,expected_schema,arity,input_or_output='input'):
    if callable(expected_schema):
        expected_schema = expected_schema(arity)
    actual_schema = [type(v) for v in value]
    if actual_schema != expected_schema:
        raise ValueError(
            f"IEFunction {name} with underlying function {func}\n"
            f"received an {input_or_output} value {value}(schema={pretty(_infer_relation_schema(value))})\n"
            f"but expected {pretty(expected_schema)}")

def assert_iterable(name,func,input,output):
    try:
        out_iter = iter(output)
    except TypeError:
        raise ValueError(f"IEFunction {name} with underlying function {func}\n"
                f"returned a value that is not an iterable\n"
                f"for input {input} -> {output}")

def map_iter(df,name,func,in_schema,out_schema,in_arity,out_arity,**kwargs):
    """helper function returns an iterator that applies a function to each row of a dataframe
    """
    for _,in_row in df.iterrows():
        in_row = list(in_row)
        assert_ie_schema(name,func,in_row,in_schema,in_arity,input_or_output='input')
        output = func(*in_row)
        assert_iterable(name,func,in_row,output)
        for out_row in output:
            assert_tuple_like(name,func,in_row,out_row)
            out_row = list(out_row)
            assert_ie_schema(name,func,out_row,out_schema,out_arity,input_or_output='output')
            yield in_row + out_row

def ie_map(df,name,func,in_schema,out_schema,in_arity,out_arity,**kwargs):
    """given an indexed dataframe, apply an ie function to each row and return the output 
    such that each output relation is indexed by the same index as the input relation that generated it
    """
    # if df.empty:
    #     return df
    output_iter = map_iter(df,name,func,in_schema,out_schema,in_arity,out_arity)
    total_arity = in_arity + out_arity
    return pd.DataFrame(output_iter,columns=_col_names(total_arity))




